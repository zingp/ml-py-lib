{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras 快速开始\n",
    "- 以mnist 数据集和CNN算法为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 使用配置\n",
    "# import os\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "# set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 核心组件\n",
    "- 神经网络的核心组件是层layers, 它是一种数据处理模块。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "        18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "         0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = X_train.shape[1], X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1) # matrix\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0],\n",
       "       [  0],\n",
       "       [  0],\n",
       "       [  0],\n",
       "       [  0],\n",
       "       [  0],\n",
       "       [  0],\n",
       "       [  0],\n",
       "       [  0],\n",
       "       [  0],\n",
       "       [  0],\n",
       "       [  0],\n",
       "       [  3],\n",
       "       [ 18],\n",
       "       [ 18],\n",
       "       [ 18],\n",
       "       [126],\n",
       "       [136],\n",
       "       [175],\n",
       "       [ 26],\n",
       "       [166],\n",
       "       [255],\n",
       "       [247],\n",
       "       [127],\n",
       "       [  0],\n",
       "       [  0],\n",
       "       [  0],\n",
       "       [  0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讲数据缩放为[0, 1]之间的浮点数\n",
    "x_train = X_train/255.\n",
    "x_test = X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01176471],\n",
       "       [0.07058824],\n",
       "       [0.07058824],\n",
       "       [0.07058824],\n",
       "       [0.49411765],\n",
       "       [0.53333333],\n",
       "       [0.68627451],\n",
       "       [0.10196078],\n",
       "       [0.65098039],\n",
       "       [1.        ],\n",
       "       [0.96862745],\n",
       "       [0.49803922],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把y变成one-hot格式\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络（模型）\n",
    "- Convolution1D主要用于nlp，Convolution2D主要用于cv\n",
    "- filters = 32          使用的卷积滤波器(卷积核)的数量\n",
    "- kernel_size = (3, 3)  卷积核的尺寸\n",
    "- activation='relu'     激活函数：relu\n",
    "- padding='same'        过滤模式\n",
    "- strides=1             步长\n",
    "- input_shape  = (img_rows, img_cols, 1)  输入数据的维度\n",
    "- MaxPooling2D(2, 2)    用于 max pooling 的池化面积，降维的作用\n",
    "- Flatten()             扁平层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。Flatten不影响batch的大小。\n",
    "- Dense()               密集连接，全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Sequential()\n",
    "\n",
    "network.add(Convolution2D(filters=16, kernel_size=(5, 5), activation='relu', padding='same', strides=1,input_shape=(img_rows, img_cols, 1)))\n",
    "network.add(MaxPooling2D(2, 2))\n",
    "\n",
    "network.add(Convolution2D(32, kernel_size=(5, 5), activation='relu', padding='same',strides=1))\n",
    "network.add(MaxPooling2D(2, 2))\n",
    "\n",
    "network.add(Convolution2D(8, kernel_size=(5, 5), activation='relu', padding='same',strides=1))\n",
    "network.add(MaxPooling2D(2, 2))\n",
    "\n",
    "network.add(Flatten())\n",
    "network.add(Dense(1000, activation='relu'))\n",
    "# 最后分类的类别数 10\n",
    "network.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看模型概要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 8)           6408      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              73000     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 102,666\n",
      "Trainable params: 102,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编译\n",
    "- loss 损失函数\n",
    "- optimizer 优化器，基于训练数据和损失函数来更新网络机制\n",
    "- metrics 在训练和测试过程中需要监控的指标：本例只关心精度，即正确分类的图像所占的比例(acc)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "- batch_size = 128  batch大小代表每次更新权重时候喂入的样本数\n",
    "- epoch = 12        样本整体循环轮次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 20s 326us/step - loss: 0.2551 - acc: 0.9211 - val_loss: 0.0691 - val_acc: 0.9783\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 19s 316us/step - loss: 0.0708 - acc: 0.9772 - val_loss: 0.0503 - val_acc: 0.9838\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 20s 333us/step - loss: 0.0500 - acc: 0.9844 - val_loss: 0.0429 - val_acc: 0.9860\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 19s 322us/step - loss: 0.0388 - acc: 0.9875 - val_loss: 0.0438 - val_acc: 0.9869\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 19s 318us/step - loss: 0.0315 - acc: 0.9902 - val_loss: 0.0405 - val_acc: 0.9872\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 19s 318us/step - loss: 0.0260 - acc: 0.9917 - val_loss: 0.0496 - val_acc: 0.9839\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 0.0246 - acc: 0.9922 - val_loss: 0.0359 - val_acc: 0.9872\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0199 - acc: 0.9938 - val_loss: 0.0324 - val_acc: 0.9895\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0172 - acc: 0.9942 - val_loss: 0.0478 - val_acc: 0.9862\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0156 - acc: 0.9950 - val_loss: 0.0359 - val_acc: 0.9886\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0131 - acc: 0.9958 - val_loss: 0.0318 - val_acc: 0.9907\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0108 - acc: 0.9965 - val_loss: 0.0420 - val_acc: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb3daefd68>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(x=x_train, y=y_train, batch_size=128, epochs=12, verbose=1, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
