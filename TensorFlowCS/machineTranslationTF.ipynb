{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理\n",
    "- 英文切词：把单词和标点紧密联系的切开！\n",
    "\n",
    "- 中文： 分词，更便捷的处理是以字为单位切割。\n",
    "\n",
    "### 英文文本清洗\n",
    "- 缩略词更改\n",
    "- 拼写校正\n",
    "- 标点符号\n",
    "- 符号替换\n",
    "- 去除空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text\n",
    "    :param text: the string of text\n",
    "    :return: text string after cleaning\n",
    "    \"\"\"\n",
    "    # acronym\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"cannot\", \"can not \", text)\n",
    "    text = re.sub(r\"what\\'s\", \"what is\", text)\n",
    "    text = re.sub(r\"What\\'s\", \"what is\", text)\n",
    "    text = re.sub(r\"\\'ve \", \" have \", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not \", text)\n",
    "    text = re.sub(r\"i\\'m\", \"i am \", text)\n",
    "    text = re.sub(r\"I\\'m\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\" e mail \", \" email \", text)\n",
    "    text = re.sub(r\" e \\- mail \", \" email \", text)\n",
    "    text = re.sub(r\" e\\-mail \", \" email \", text)\n",
    "\n",
    "    # spelling correction\n",
    "    text = re.sub(r\"ph\\.d\", \"phd\", text)\n",
    "    text = re.sub(r\"PhD\", \"phd\", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" fb \", \" facebook \", text)\n",
    "    text = re.sub(r\"facebooks\", \" facebook \", text)\n",
    "    text = re.sub(r\"facebooking\", \" facebook \", text)\n",
    "#     text = re.sub(r\" usa \", \" america \", text)\n",
    "#     text = re.sub(r\" us \", \" america \", text)\n",
    "#     text = re.sub(r\" u s \", \" america \", text)\n",
    "#     text = re.sub(r\" U\\.S\\. \", \" america \", text)\n",
    "    text = re.sub(r\" US \", \" america \", text)\n",
    "    text = re.sub(r\" American \", \" america \", text)\n",
    "    text = re.sub(r\" America \", \" america \", text)\n",
    "    text = re.sub(r\" mbp \", \" macbook-pro \", text)\n",
    "    text = re.sub(r\" mac \", \" macbook \", text)\n",
    "    text = re.sub(r\"macbook pro\", \"macbook-pro\", text)\n",
    "    text = re.sub(r\"macbook-pros\", \"macbook-pro\", text)\n",
    "    text = re.sub(r\" 1 \", \" one \", text)\n",
    "    text = re.sub(r\" 2 \", \" two \", text)\n",
    "    text = re.sub(r\" 3 \", \" three \", text)\n",
    "    text = re.sub(r\" 4 \", \" four \", text)\n",
    "    text = re.sub(r\" 5 \", \" five \", text)\n",
    "    text = re.sub(r\" 6 \", \" six \", text)\n",
    "    text = re.sub(r\" 7 \", \" seven \", text)\n",
    "    text = re.sub(r\" 8 \", \" eight \", text)\n",
    "    text = re.sub(r\" 9 \", \" nine \", text)\n",
    "    text = re.sub(r\"googling\", \" google \", text)\n",
    "    text = re.sub(r\"googled\", \" google \", text)\n",
    "    text = re.sub(r\"googleable\", \" google \", text)\n",
    "    text = re.sub(r\"googles\", \" google \", text)\n",
    "    text = re.sub(r\"dollars\", \" dollar \", text)\n",
    "\n",
    "    # punctuation\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"-\", \" - \", text)\n",
    "    text = re.sub(r\"/\", \" / \", text)\n",
    "#     text = re.sub(r\"\\\\\", \" \\ \", text)\n",
    "    text = re.sub(r\"=\", \" = \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\"\\.\", \" . \", text)\n",
    "    text = re.sub(r\",\", \" , \", text)\n",
    "    text = re.sub(r\"\\?\", \" ? \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\\"\", \" \\\" \", text)\n",
    "    text = re.sub(r\"&\", \" & \", text)\n",
    "    text = re.sub(r\"\\|\", \" | \", text)\n",
    "    text = re.sub(r\";\", \" ; \", text)\n",
    "    text = re.sub(r\"\\(\", \" ( \", text)\n",
    "    text = re.sub(r\"\\)\", \" ( \", text)\n",
    "\n",
    "    # symbol replacement\n",
    "    text = re.sub(r\"&\", \" and \", text)\n",
    "    text = re.sub(r\"\\|\", \" or \", text)\n",
    "    text = re.sub(r\"=\", \" equal \", text)\n",
    "    text = re.sub(r\"\\+\", \" plus \", text)\n",
    "    text = re.sub(r\"\\$\", \" dollar \", text)\n",
    "\n",
    "    # remove extra space\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_remove(line):\n",
    "    items = [\"<url>\", \"<keywords>\", \"<speaker>\", \"<talkid>\", \"<translator\", \"<reviewer\"]\n",
    "    for part in items:\n",
    "        if line.startswith(part):\n",
    "            return True\n",
    "    return False          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_line(read_file, write_file):\n",
    "    fw = open(write_file, \"a+\")\n",
    "    with open(read_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            r = is_remove(line)\n",
    "            if r: \n",
    "                continue\n",
    "            if line.startswith(\"<title>\"):\n",
    "                text = re.sub(r\"<title>|</title>\", \"\", line)\n",
    "            elif line.startswith(\"<description>\"):\n",
    "                text = re.sub(r\"<description>|</description>\", \"\", line)\n",
    "            else:\n",
    "                text = line\n",
    "            fw.write(text)\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_file = \"./data/en-zh/train.tags.en-zh.en\"\n",
    "zh_file = \"./data/en-zh/train.tags.en-zh.zh\"\n",
    "\n",
    "en_tmp_file = \"./data/en-zh/train.trg.en-zh.en.1\"\n",
    "zh_trg_file = \"./data/en-zh/train.trg.en-zh.zh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_trg_file = \"./data/en-zh/train.trg.en-zh.en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_html_line(en_file, en_tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_html_line(zh_file, zh_trg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open(en_trg_file, \"a+\")\n",
    "with open(en_tmp_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        text = clean_text(line)+\"\\n\"\n",
    "        fw.write(text)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npt-tf-env) [dc@gz_6237_gpu en-zh]$ wc -l train.trg.en-zh.zh\\n213377 train.trg.en-zh.zh\\n(pt-tf-env) [dc@gz_6237_gpu en-zh]$ wc -l train.trg.en-zh.en\\n213377 train.trg.en-zh.en\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pt-tf-env) [dc@gz_6237_gpu en-zh]$ wc -l train.trg.en-zh.zh\n",
    "213377 train.trg.en-zh.zh\n",
    "(pt-tf-env) [dc@gz_6237_gpu en-zh]$ wc -l train.trg.en-zh.en\n",
    "213377 train.trg.en-zh.en\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理成模型需要的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "SOS_ID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(file_path):\n",
    "    dataset = tf.data.TextLineDataset(file_path)\n",
    "    dataset = dataset.map(lambda string: tf.string_split([string]).values)\n",
    "    # 将字符串形式的单词编号-> 整数\n",
    "    dataset = dataset.map(lambda string: tf.string_to_number(string, tf.int32))\n",
    "    dataset = dataset.map(lambda x: (x, tf.size(x)))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从源语言文件 src_path 和目标语言 文件 trg_path 分别读取数据，并进行填充和batching操作\n",
    "def make_src_trg_dataset(src_path, trg_path, batch_size):\n",
    "    src_data = make_dataset(src_path)\n",
    "    trg_data = make_dataset(trg_path)\n",
    "    # zip 合并后 每项ds 由4个张量组成\n",
    "    #  ds[0][0] 是源句子\n",
    "    #  ds[0][1] 是源句子长度\n",
    "    #  ds[1][0] 是目标句子\n",
    "    #  ds[1][1] 是目标句子长度\n",
    "    \n",
    "    # 处理内容为空和长度过长的句子\n",
    "    def filter_length(src_tuple, trg_tuple):\n",
    "        ((src_input, src_len), (trg_label, trg_len)) = (src_tuple, trg_tuple)\n",
    "        src_len_ok = tf.logical_and(\n",
    "            tf.greater(src_len, l), tf.less_equal(src_len, MAX_LEN))\n",
    "        trg_len_ok = tf.logical_and(\n",
    "            tf.greater(trg_len, l), tf.less_equal(trg_len, MAX_LEN))\n",
    "        return tf.logical_and(src_len_ok, trg_len_ok)\n",
    "    dataset = dataset.filter(filter_length)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
