{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类问题\n",
    "- 分类问题是是机器学习中最常见的问题之一了。如CV领域识别一张图片中的动物是猫、狗还是鸡；在NLP领域预测下一个最有可能出现的词。\n",
    "- $cross\\_entropy=-\\sum_{k=1}^{N}\\left(p_{k} * \\log q_{k}\\right)$\n",
    "```\n",
    "torch.nn\ttorch.nn.functional (F)\n",
    "CrossEntropyLoss\tcross_entropy\n",
    "LogSoftmax\tlog_softmax\n",
    "NLLLoss\tnll_loss\n",
    "```\n",
    "- softmax回归的输出值个数等于标签里的类别数。因为一共有4种特征和3种输出动物类别。\n",
    "- 既然分类问题需要得到离散的预测输出，一个简单的办法是将输出值oi当作预测类别是i的置信度，并将值最大的输出所对应的类作为预测输出，即输出 $argmax_i{O_i}$ 。例如，如果o1，o2，o3, 分别为0.1, 10, 0.1，由于o2最大，那么预测类别为2，其代表猫。\n",
    "- 直接使用输出层的输出有两个问题。一方面，由于输出层的输出值的范围不确定，我们难以直观上判断这些值的意义。例如，刚才举的例子中的输出值10表示“很置信”图像类别为猫，因为该输出值是其他两类的输出值的100倍。但如果o1=03=1000, 那么输出值10却又表示图像类别为猫的概率很低。另一方面，由于真实标签是离散值，这些离散值与不确定范围的输出值之间的误差难以衡量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([2, 0], dtype=torch.int64)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0000, -1.0000,  3.0000],\n",
       "        [ 1.0000,  0.0000, -0.5000]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =  torch.tensor([[2.0, -1.0, 3.0], [1.0, 0.0, -0.5]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3955)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3955)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3266, -4.3266, -0.3266],\n",
       "        [-0.4644, -1.4644, -1.9644]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_softmax = F.log_softmax(x)\n",
    "x_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3955)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss(x_softmax, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.nll_loss(x_softmax, y, reduction='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sparse_softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32656264 0.4643688 ]\n"
     ]
    }
   ],
   "source": [
    "# 假设词汇表的大小为3， 语料包含两个单词\"2 0\"\n",
    "word_labels = tf.constant([2, 0])\n",
    "\n",
    "# 假设模型对两个单词预测时，产生的logit分别是[2.0, -1.0, 3.0]和[1.0, 0.0, -0.5]\n",
    "predict_logits = tf.constant([[2.0, -1.0, 3.0], [1.0, 0.0, -0.5]])\n",
    "\n",
    "# 使用sparse_softmax_cross_entropy_with_logits计算交叉熵。\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=word_labels, logits=predict_logits)\n",
    "\n",
    "# 运行程序，计算loss的结果是[0.32656264, 0.46436879], 这对应两个预测的\n",
    "# perplexity损失。\n",
    "sess = tf.Session()\n",
    "print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-d72c9df1352f>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "[0.32656264 0.4643688 ]\n",
      "[0.37656265 0.48936883]\n"
     ]
    }
   ],
   "source": [
    "# softmax_cross_entropy_with_logits与上面的函数相似，但是需要将预测目标以\n",
    "# 概率分布的形式给出。\n",
    "word_prob_distribution = tf.constant([[0.0, 0.0, 1.0], [1.0, 0.0, 0.0]])\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=word_prob_distribution, logits=predict_logits)\n",
    "# 运行结果与上面相同：[ 0.32656264,  0.46436879]\n",
    "print(sess.run(loss))\n",
    "\n",
    "# label smoothing：将正确数据的概率设为一个比1.0略小的值，将错误数据的概率\n",
    "# 设为比0.0略大的值，这样可以避免模型与数据过拟合，在某些时候可以提高训练效果。\n",
    "word_prob_smooth = tf.constant([[0.01, 0.01, 0.98], [0.98, 0.01, 0.01]])\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=word_prob_smooth, logits=predict_logits)\n",
    "# 运行结果：[ 0.37656265,  0.48936883]\n",
    "print(sess.run(loss))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 = tf.nn.softmax_cross_entropy_with_logits_v2(labels=word_prob_smooth, logits=predict_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37656265 0.48936883]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(loss))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39546572"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.32656264+0.4643688)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
