{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.0\n",
      "1.9.0\n",
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n",
    "print(onnx.__version__)\n",
    "print(rt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "?AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "?get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"data/bert-base-chinese\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.json', 'pytorch_model.bin', 'vocab.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokernizer = BertTokenizer.from_pretrained(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokernizer(\"我们来试试牛逼的bert模型吧\", return_tensors=\"pt\")\n",
    "# inputs = tokernizer.tokenize(\"我们来试试牛逼的bert模型吧\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2769,  812, 3341, 6407, 6407, 4281, 6873, 4638, 8815, 8716, 3563,\n",
       "         1798, 1416,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 我 们 来 试 试 牛 逼 的 bert 模 型 吧 [SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokernizer.decode(inputs[\"input_ids\"].data.cpu().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0022,  0.3962, -0.4054,  ...,  0.3902, -0.1599,  0.0457],\n",
       "          [ 0.2589, -0.5536, -0.2424,  ..., -0.5843, -0.9316, -0.0326],\n",
       "          [ 0.5397, -1.2938, -0.9617,  ...,  0.8388,  0.2714,  0.0597],\n",
       "          ...,\n",
       "          [-0.5858,  0.4624,  0.8773,  ...,  0.5462, -0.6654,  0.1387],\n",
       "          [ 0.4450,  0.0043, -0.5730,  ...,  0.8095, -0.1073, -0.3027],\n",
       "          [-0.7771,  0.0293, -0.1939,  ..., -0.1485, -0.3096, -0.4418]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[ 0.9999,  1.0000,  0.9988,  0.8066,  0.6104,  0.9376, -0.9984,  0.5931,\n",
       "           0.9948, -0.9984,  1.0000,  0.9997,  0.7948, -0.8251,  1.0000, -0.9999,\n",
       "          -0.8589,  0.9303,  0.9632, -0.0167,  1.0000, -1.0000, -0.9846, -0.5761,\n",
       "           0.7221,  0.9991,  0.9855,  0.5958, -1.0000,  0.9981,  0.9679,  0.9998,\n",
       "           0.8287, -0.9999, -0.9998,  0.9071, -0.0574,  0.9975,  0.3821, -0.8907,\n",
       "          -0.9937, -0.3870,  0.5671, -0.9984, -0.8570,  0.7311, -1.0000, -0.9999,\n",
       "           0.7597,  1.0000, -0.8943, -0.9994,  0.3594, -0.9248, -0.9488,  0.8541,\n",
       "          -0.9993,  0.9990,  1.0000,  0.5264,  0.9998, -0.9371,  0.5107, -0.9994,\n",
       "           1.0000, -0.9955, -0.9835,  0.8118,  1.0000,  1.0000, -0.8874,  0.9885,\n",
       "           1.0000,  0.9025,  0.9812,  0.9998, -0.9998,  0.2567, -1.0000, -0.9598,\n",
       "           1.0000,  0.9823, -0.9039, -0.8733, -0.9908, -1.0000, -0.9999,  0.9999,\n",
       "           0.4049,  0.9736,  0.9991, -0.9997, -1.0000,  0.9991, -0.9995, -0.9964,\n",
       "          -0.9733,  0.9997, -0.6798, -0.8775, -0.9504,  0.8455, -0.9992, -0.9981,\n",
       "           0.9935,  0.9976, -0.1714, -0.9996,  1.0000,  0.9733, -1.0000, -0.1885,\n",
       "          -1.0000, -0.8353, -0.9919,  1.0000,  0.9037, -0.8717,  0.9990, -0.9991,\n",
       "           0.8688, -0.9862, -0.9760, -0.2887,  0.9889,  1.0000,  0.9976, -0.9983,\n",
       "           0.9996,  1.0000,  0.9907,  0.9991, -0.9993,  0.9369,  0.8475, -0.9447,\n",
       "           0.1395, -0.3761,  1.0000,  0.9959,  0.9966, -0.9034,  0.9996, -0.9953,\n",
       "           1.0000, -0.9999,  0.9974, -1.0000, -0.9853,  0.9999,  0.8365,  1.0000,\n",
       "          -0.7365,  1.0000, -0.9963, -0.9989,  0.9778,  0.1662,  0.9890, -1.0000,\n",
       "           0.9872,  0.1576, -0.9037,  0.7285, -1.0000,  1.0000, -0.6816,  1.0000,\n",
       "           0.9968, -0.8228, -0.9981, -0.9992,  0.9009, -0.9998, -0.8837,  0.9844,\n",
       "           0.2113,  0.9986, -0.9945, -0.9945,  0.8990, -0.8242, -1.0000,  0.9839,\n",
       "          -0.4675,  0.9880,  0.9364,  0.4896,  0.9681,  0.9110, -0.6377,  1.0000,\n",
       "          -0.3167,  0.9973,  0.9998, -0.5580, -0.8584, -0.9629, -1.0000, -0.6340,\n",
       "           1.0000, -0.7346, -0.9997,  0.9027, -1.0000,  0.9947, -0.8475,  0.2117,\n",
       "          -0.9560, -1.0000,  0.9992, -0.9874, -0.9989,  0.4477,  0.8209, -0.1763,\n",
       "          -0.9981,  0.7357,  0.9976,  0.0741,  0.9762, -0.9869, -0.9995,  0.9385,\n",
       "          -0.9234,  0.8601,  0.9826,  1.0000,  0.9998, -0.6108, -0.8464,  1.0000,\n",
       "           0.9111, -1.0000,  0.6142, -0.9961, -0.8713,  1.0000, -0.9979,  0.9780,\n",
       "           1.0000,  0.9087,  1.0000, -0.9926, -0.9946, -0.9998,  1.0000,  0.9982,\n",
       "           0.9999, -0.9949, -0.9998, -0.6693, -0.9364, -1.0000, -1.0000, -0.8659,\n",
       "           0.9979,  0.9995, -0.2390, -0.9973, -0.9515, -0.9987,  1.0000, -0.8745,\n",
       "           1.0000,  0.9889, -0.9275, -0.9826,  0.9835, -0.6858, -0.9996, -0.6664,\n",
       "          -1.0000, -0.9583, -1.0000,  0.9944, -0.9996, -1.0000,  0.9665,  1.0000,\n",
       "           0.8739, -1.0000,  0.9998,  0.9981,  0.3575, -0.3605,  0.9828, -1.0000,\n",
       "           1.0000, -0.9995,  0.8442, -0.9895, -0.9953, -0.6993,  0.9994,  0.9998,\n",
       "          -0.9958, -0.8418, -0.9893, -0.9968,  0.0900,  0.9849, -0.7497, -0.8006,\n",
       "          -0.8798, -0.9633,  0.9531, -0.9993, -0.9970,  0.8979,  1.0000, -0.9867,\n",
       "           1.0000,  0.9934,  1.0000,  0.9915, -0.9967,  0.9995, -0.8652, -0.9540,\n",
       "          -0.9819, -0.7553,  0.9637, -0.4221, -0.3823, -0.9992,  1.0000,  0.9865,\n",
       "           0.9366,  0.9490, -0.5328,  0.0994,  0.9946, -0.9882,  0.9991, -0.9997,\n",
       "          -0.9046,  0.9982,  1.0000,  0.9985,  0.5612, -0.3681,  0.9997, -0.9975,\n",
       "           0.9998, -0.9998,  0.9998, -0.9444,  0.3334, -0.9966, -0.9914,  1.0000,\n",
       "           0.9235, -0.9683,  0.9959, -0.6713,  0.9996,  0.9393,  0.9839,  0.9987,\n",
       "           0.9986,  1.0000, -0.9986, -0.9963, -0.9689, -0.9991, -0.9991, -1.0000,\n",
       "           0.7822, -0.9999, -0.9790, -0.9643,  0.8204,  0.9700, -0.3660,  0.7530,\n",
       "          -0.6508,  0.7212, -0.9346,  0.2718,  0.9554, -0.9979, -0.9974, -1.0000,\n",
       "          -0.9923,  0.7619,  1.0000, -0.9999,  0.9994, -1.0000, -0.8111,  0.9910,\n",
       "          -0.6992, -0.3837,  0.9998, -1.0000,  0.8450,  0.9985,  1.0000,  0.9956,\n",
       "           0.9999, -0.9395, -1.0000, -0.9995, -1.0000, -1.0000, -0.9996,  0.8234,\n",
       "           0.9304, -1.0000,  0.5443,  0.8723,  1.0000,  0.9978, -0.9996, -0.7489,\n",
       "          -0.9995, -0.4590,  0.9994, -0.9604, -1.0000,  0.9954, -0.8619,  1.0000,\n",
       "          -0.7959,  0.9925,  0.9249,  0.9256,  0.9875, -1.0000,  0.6992,  1.0000,\n",
       "           0.8885, -1.0000, -0.9929, -0.8901, -0.9995, -0.3767, -0.0369,  0.9998,\n",
       "          -1.0000, -0.0591, -0.9959,  0.5649,  0.9908,  0.9999,  0.9989,  0.9821,\n",
       "           0.9663,  0.9643,  0.8533,  1.0000,  0.1386, -0.9993,  0.9994,  0.3650,\n",
       "           0.3223, -0.9999,  0.9994, -0.6302,  1.0000,  0.9952, -0.8656, -0.9682,\n",
       "          -0.9990,  0.9980,  1.0000, -0.6687, -0.9750, -0.9986, -0.9999, -0.9939,\n",
       "          -0.9079,  0.3207, -0.9659, -0.9997,  0.7693,  0.8715,  1.0000,  1.0000,\n",
       "           0.9988, -0.8728, -0.9917,  0.9985, -0.2014,  0.9436, -0.8549, -1.0000,\n",
       "          -0.9924, -0.9990,  1.0000, -0.2618, -0.3331, -0.9797, -0.0749,  0.8859,\n",
       "          -1.0000, -0.9532, -0.9829,  0.9424,  1.0000, -0.9998,  0.9942, -0.9991,\n",
       "           0.5479,  0.2967,  0.4315,  0.9884, -0.5575, -0.8832, -0.7666, -0.6892,\n",
       "           0.9864,  0.9976, -0.9972, -0.3347,  0.9995,  0.7246,  0.9998,  0.1952,\n",
       "           0.9360,  0.9880,  1.0000,  0.9323,  1.0000,  0.9811,  1.0000,  1.0000,\n",
       "          -0.9744,  0.4239,  0.2465, -0.9904, -0.7680,  0.9860,  1.0000,  0.3261,\n",
       "          -0.9697, -0.9989,  0.9976,  1.0000,  1.0000, -0.9151,  0.9906, -0.8311,\n",
       "           0.8343,  0.5746,  0.9927, -0.7675,  0.5426,  0.9995,  0.9995, -1.0000,\n",
       "          -0.9999, -1.0000,  1.0000,  0.9986, -0.5684, -1.0000,  0.9999, -0.9179,\n",
       "           0.6578,  0.9955,  0.5450, -0.9896,  0.9115, -0.9996,  0.0088,  0.7273,\n",
       "           0.9893,  0.6707,  0.9982, -0.9996,  0.8782,  1.0000,  0.7325,  1.0000,\n",
       "           0.2030, -0.9997,  0.9998, -0.9939, -0.9998, -0.8731,  0.9999,  0.9995,\n",
       "           0.4154,  0.0531,  0.9999, -0.9999,  1.0000, -1.0000,  0.8676, -0.9980,\n",
       "           1.0000, -0.9486, -0.9993,  0.1004,  0.8851,  0.5589, -0.8721,  1.0000,\n",
       "          -0.8241, -0.9030,  0.8667, -0.8485, -0.9946, -0.9876, -0.6889, -1.0000,\n",
       "           0.9369,  0.6735, -0.9272, -0.9969, -1.0000,  1.0000, -0.8269, -0.9156,\n",
       "           1.0000, -0.9151, -1.0000,  0.9927, -0.9999,  0.9103,  0.9815, -0.8558,\n",
       "          -0.5083, -1.0000,  0.4075,  0.9999, -0.9993, -0.9586, -0.9470, -0.2875,\n",
       "           0.8465,  0.9775,  0.9965, -0.4348,  0.7436,  0.9375,  0.9919, -0.8819,\n",
       "           0.0422, -0.9999, -0.9897,  0.7300, -0.9986, -1.0000, -1.0000,  1.0000,\n",
       "           0.9999,  1.0000, -0.9888, -0.3495,  0.7709,  0.9806, -0.9999, -0.9216,\n",
       "           0.7377,  0.9936,  0.6082, -0.9995, -0.7743, -1.0000, -0.8908,  0.4082,\n",
       "          -0.9613,  0.9944,  1.0000,  0.9998, -0.9999, -0.9984, -0.9986, -0.9944,\n",
       "           0.9999,  0.9995,  0.9996, -0.9868, -0.0441,  0.9999,  0.3602, -0.0294,\n",
       "          -0.9998, -0.9948, -1.0000,  0.8987, -0.9943, -0.9999,  0.9900,  1.0000,\n",
       "           0.6290, -1.0000, -0.9360,  1.0000,  0.9981,  1.0000, -0.7912,  0.9999,\n",
       "          -0.9958,  0.9582, -0.9994,  1.0000, -1.0000,  1.0000,  1.0000,  0.9980,\n",
       "           0.9986, -0.9964,  0.9986, -0.9974, -0.2995,  0.9931, -0.5938, -0.9977,\n",
       "          -0.1744,  0.9949, -0.9894,  1.0000,  0.9449, -0.1158,  0.5914,  0.6983,\n",
       "           0.9823,  0.8337, -0.9994,  0.4508,  0.9996,  0.9965,  1.0000,  0.8009,\n",
       "           1.0000, -0.9435, -0.9996,  0.9993,  0.2189, -0.9648, -1.0000,  1.0000,\n",
       "           1.0000, -0.9999, -0.9954,  0.3830,  0.0279,  1.0000,  0.9888,  0.9935,\n",
       "           0.9925,  0.8300,  0.9988, -0.9995,  0.9766, -0.9987, -0.9927,  1.0000,\n",
       "          -0.9986,  0.9998, -0.9986,  0.9998, -0.9997,  0.9914,  0.9958,  0.9844,\n",
       "          -0.9977,  1.0000,  0.8020, -0.9933, -0.9426, -0.9963, -0.9998,  0.3008]],\n",
       "        grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  输入两个句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2 = tokernizer(\"我们来试试牛逼的BERT模型吧，哈哈哈\", \"听说BERT模型吊炸天！\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tokernizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2769,  812, 3341, 6407, 6407, 4281, 6873, 4638, 8815, 8716, 3563,\n",
       "         1798, 1416, 8024, 1506, 1506, 1506,  102, 1420, 6432, 8815, 8716, 3563,\n",
       "         1798, 1396, 4156, 1921, 8013,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 我 们 来 试 试 牛 逼 的 bert 模 型 吧 ， 哈 哈 哈 [SEP] 听 说 bert 模 型 吊 炸 天 ！ [SEP]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokernizer.decode(inputs2[\"input_ids\"].data.cpu().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_outputs, pooled_outputs = model(**inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5632, -0.2772, -0.7578,  ..., -0.4281, -0.6566,  0.0447],\n",
       "         [ 0.1452, -0.3351, -0.1041,  ..., -0.7047, -0.7250,  0.1023],\n",
       "         [ 0.4466, -1.6673, -0.9454,  ...,  0.6884,  0.2825,  0.1363],\n",
       "         ...,\n",
       "         [ 0.6694, -0.2453, -0.5614,  ..., -0.1644,  0.7202, -0.3962],\n",
       "         [-0.5863, -0.1840,  0.5368,  ..., -0.1647,  0.2451, -0.8209],\n",
       "         [ 0.1379, -0.5186, -0.7563,  ..., -0.2276, -0.3963, -0.5681]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3726e-01, -3.5510e-01, -6.3008e-01,  5.3175e-01,  6.0181e-01,\n",
       "         -6.8932e-01,  3.0354e-01, -2.3032e-01, -4.1510e-01,  4.3610e-01,\n",
       "         -1.1629e-01, -3.5269e-01, -5.8402e-02,  3.7394e-01,  5.1749e-02,\n",
       "         -1.6117e-01, -3.3302e-02,  2.0406e-01,  1.1197e-01,  2.0059e-01,\n",
       "         -2.0750e-01,  4.1024e-01,  9.0569e-02,  6.2213e-02, -1.1207e-01,\n",
       "         -3.7839e-01, -1.0782e-01, -2.9131e-01,  4.0371e-01, -6.3899e-01,\n",
       "         -4.9931e-01, -3.3856e-01, -2.7771e-01,  7.9626e-02,  2.8813e-01,\n",
       "         -4.8025e-01, -5.1427e-01, -1.7292e-01, -4.3150e-01, -3.8770e-01,\n",
       "         -4.3781e-01, -3.5913e-01, -4.9081e-01,  1.9053e-01,  6.9059e-02,\n",
       "          3.9864e-02,  3.1614e-01,  2.7560e-01,  7.8873e-02,  3.4491e-01,\n",
       "          1.2843e-01,  8.5680e+00, -1.5622e-01, -4.5469e-01, -7.6156e-01,\n",
       "          6.5412e-01,  1.0692e+00, -1.8387e-01,  4.1132e-02, -4.8158e-01,\n",
       "         -4.7975e-02,  1.5753e-01, -1.5874e-01, -2.4830e-01,  2.0331e-02,\n",
       "         -9.0839e-02, -1.3300e-01,  4.6725e-01, -7.4143e-02, -3.4213e-01,\n",
       "          5.4157e-01, -3.5839e-02, -2.1603e-01, -2.4105e-01,  6.0657e-02,\n",
       "          3.3879e-01, -3.0045e-01, -2.7041e-01, -1.7779e-01, -5.0296e-01,\n",
       "         -7.8259e-01,  3.1922e-01, -1.7638e-01,  4.6842e-02, -6.0656e-01,\n",
       "          2.8459e-01, -8.1399e-01, -3.8973e-01,  4.6743e-01, -4.4044e-01,\n",
       "         -2.1097e-01,  2.1143e-01, -1.1665e-01,  9.9402e-02,  5.9991e-01,\n",
       "          5.6963e-03,  9.6694e-02,  3.5137e-01, -1.3166e-01,  2.6707e-01,\n",
       "         -3.4709e-01, -2.2353e-01,  3.8040e-01, -2.9704e-01, -3.6342e-01,\n",
       "          4.5945e-02, -4.5071e-01,  3.1004e-01, -4.7244e-01, -2.0197e-01,\n",
       "         -4.7248e-01, -5.7503e-02, -1.7443e-02,  3.5338e-01,  5.5790e-02,\n",
       "         -3.2198e-01, -1.7514e-01,  9.5490e-01,  2.3423e-01, -5.1819e-01,\n",
       "          4.0157e-01,  3.1880e-01,  4.3937e-01, -2.7487e-02,  1.1962e-01,\n",
       "         -6.7965e-01,  2.1684e-01, -1.3824e-01, -4.7364e-01,  2.4238e-02,\n",
       "         -7.5839e-02,  4.9652e-01,  8.2607e-01, -1.3536e-01,  2.7911e-01,\n",
       "         -5.0778e-01, -3.6249e-01, -4.0423e-01, -6.7409e-01, -1.3285e-01,\n",
       "         -9.8663e-02, -2.5989e-02, -3.3193e-01,  1.7344e-01,  3.7532e-01,\n",
       "          2.1929e-01, -1.6160e-02, -3.4783e-01,  5.1373e-01,  3.4466e-01,\n",
       "         -5.9269e-01, -4.6863e-01, -1.6129e-02,  4.4581e-02, -5.2508e-01,\n",
       "          1.8935e-01,  1.8121e-02, -4.5014e-01, -2.7862e-02,  4.4240e-01,\n",
       "         -3.5725e-01,  1.2986e-01,  2.4155e-01,  9.6762e-01,  1.4592e-01,\n",
       "         -3.4876e-01,  5.2061e-02,  5.1047e-01,  2.2731e-01,  2.4807e-01,\n",
       "          2.9445e-02,  1.1243e+00,  9.3970e-02,  4.2564e-01, -1.1292e-01,\n",
       "          7.9912e-02, -4.3332e-01, -7.7745e-01,  1.0667e-01,  3.4448e-01,\n",
       "          7.5780e-02, -2.3880e-01, -3.2329e-01, -2.9530e-01,  2.0058e-01,\n",
       "          4.5487e-01,  5.9220e-02, -1.7170e-01,  2.9814e-01,  2.0537e-01,\n",
       "         -9.7275e-02, -1.3248e-02, -7.1550e-02,  4.4257e-03,  2.2561e-01,\n",
       "         -5.3454e-03,  2.6804e-01, -1.1115e-01,  7.6837e-01,  1.6988e-02,\n",
       "         -5.8556e-01,  3.0694e-01, -4.6051e-01,  1.3838e-01,  3.4300e-01,\n",
       "         -2.7906e-02, -5.0617e-01, -4.6335e-01, -6.2703e-01, -3.1390e-01,\n",
       "         -8.4206e-01,  2.8488e-01,  1.4575e-01, -4.0433e-01,  1.4473e-01,\n",
       "         -1.1070e-01,  3.2929e-01,  4.1129e-01, -4.8865e-01,  9.0453e-02,\n",
       "         -2.3819e-02, -7.1935e-02,  1.6682e-02, -2.3106e-01,  3.6376e-02,\n",
       "         -1.5170e-03, -6.4789e-02,  3.9816e-01,  1.1338e-01,  1.8666e-01,\n",
       "         -3.7908e-01, -1.1774e-01,  1.5334e-01,  6.6427e-01, -3.2392e-01,\n",
       "          8.0005e-02, -2.9267e-01,  1.6933e-01, -3.0497e-01,  1.7589e-01,\n",
       "         -3.3760e-02, -3.2567e-01, -3.8278e-01, -1.8821e-03, -5.7155e-01,\n",
       "          1.9424e-01, -1.3097e-01, -2.6342e-02, -5.2119e-02, -1.4703e-01,\n",
       "          5.6398e-02, -3.4548e-01,  1.5269e-01, -6.3759e-01, -4.5718e-01,\n",
       "          5.6544e-01,  1.1377e-01, -4.8165e-02,  1.2241e-01,  3.1446e-01,\n",
       "         -1.2099e-01,  5.5756e-02,  4.4192e-01, -6.2245e-01,  5.5643e-01,\n",
       "         -2.7045e-01,  2.0334e-01, -4.3103e-01,  5.3256e-02, -2.5453e-01,\n",
       "          3.4400e-01,  2.1296e-01,  3.2398e-03, -2.2535e-01, -4.8170e-01,\n",
       "          4.9736e-01,  1.9694e-01,  5.3603e-01, -2.2143e-01, -6.2356e-01,\n",
       "          3.6399e-01,  2.3540e-01,  4.0521e-01, -3.3714e-01, -8.0912e-01,\n",
       "         -5.6074e-01,  4.4147e-01, -1.0118e-01, -6.2379e-02, -1.8535e-01,\n",
       "          3.0657e-02, -4.2019e-01,  1.6585e-01,  3.1307e-01,  1.1358e+00,\n",
       "          4.4466e-01,  7.5931e-02, -2.9078e-01, -3.5542e-02, -4.2706e-01,\n",
       "         -6.1473e-02,  4.2915e-02, -3.3671e-01,  3.8636e-01, -3.2809e-01,\n",
       "         -5.5102e-02, -6.8207e-03,  1.5532e-01,  1.3730e-01, -4.5454e-02,\n",
       "         -6.7421e-01,  2.4071e-03, -2.7709e-01, -2.0914e-01, -1.3401e+00,\n",
       "         -1.0332e-01,  4.2788e-01,  2.6335e-01, -3.8490e-01, -2.3707e-01,\n",
       "         -3.5943e-01,  2.0272e-01,  8.1376e-02,  3.8157e-01, -4.4325e-01,\n",
       "          1.2664e-01,  2.7203e-01, -6.2165e-02, -3.3797e-01,  8.5042e-02,\n",
       "         -1.2728e-01, -9.0346e-02,  1.4253e-02,  2.6244e-01, -5.7455e-02,\n",
       "          6.8445e-03, -5.1953e-01, -2.9715e-01, -8.3439e-02, -3.2237e-01,\n",
       "          2.0540e-01, -5.9679e-01,  7.1010e-01,  2.0172e-01, -7.2252e-01,\n",
       "          2.0516e-02,  2.4095e-01, -3.8787e-01,  2.4101e-01, -1.6390e-01,\n",
       "         -6.4364e-01,  7.2993e-01, -2.0890e-01, -6.5450e-01,  6.8633e-02,\n",
       "          8.7933e-02, -5.4216e-03, -2.3812e-01, -1.0829e-01,  8.8644e-02,\n",
       "         -1.0347e-01, -3.7956e-02, -2.3676e-02, -4.9119e-01,  7.3326e-02,\n",
       "          3.1836e-01,  2.0516e-01, -5.7332e-02,  2.5604e-02, -5.9755e-02,\n",
       "          2.5084e-01, -4.3645e-02,  3.0588e-01,  5.1912e-03,  1.4316e-01,\n",
       "         -7.7189e-01,  8.8092e-02,  3.7655e-01, -1.0888e-01, -1.4136e-01,\n",
       "         -8.1655e-01,  2.8114e-01,  2.7274e-01, -4.0916e-01,  3.3979e-01,\n",
       "          2.0561e-02,  4.3668e-02, -1.8687e-01,  6.5847e-01, -2.2933e-01,\n",
       "         -1.0334e+00,  9.5072e-02, -1.6183e-01, -2.0217e-01,  3.0342e-01,\n",
       "          3.5446e-01, -3.8498e-01,  2.0150e-01, -3.5651e-01, -2.8311e-01,\n",
       "          1.3773e-01, -3.5555e-01,  3.7091e-01,  1.6538e-01, -2.6541e-02,\n",
       "         -1.1561e+00,  1.6821e-01, -5.2149e-02,  5.5654e-01, -7.3220e-03,\n",
       "         -2.3024e-01,  6.5014e-01, -1.6645e-01,  3.2562e-01, -4.6074e-01,\n",
       "         -1.0537e-01,  1.2285e-01, -2.6731e-01,  2.6725e-01, -2.4807e-02,\n",
       "         -2.3701e-01, -6.8985e-02, -6.8340e-02, -4.5441e-01,  4.5432e-01,\n",
       "         -4.6291e-01,  5.9725e-01,  2.4924e-01,  7.5511e-01, -1.8211e-01,\n",
       "         -4.5947e-01, -2.4544e-01, -2.8018e-01,  6.4680e-01, -5.6747e-01,\n",
       "          5.0420e-01,  1.2994e-01, -1.9530e-01,  6.3790e-01,  7.2927e-02,\n",
       "         -1.2672e-01, -3.3533e-01,  4.2788e-01,  4.6654e-01, -6.6191e-02,\n",
       "         -6.7726e-02,  1.0141e+00, -2.3638e-01,  2.7791e-01,  7.8645e-02,\n",
       "          1.1817e-03, -1.3153e-01, -2.5363e-01, -1.6686e-01,  2.5353e-01,\n",
       "         -1.4385e-01, -8.6061e-03,  9.3133e-01, -2.2963e-01,  4.3289e-01,\n",
       "          3.4029e-01,  3.5675e-01, -6.3736e-01,  8.3957e-02,  3.7254e-01,\n",
       "         -2.6898e-01, -3.7968e-01, -2.1675e-01, -5.7992e-02, -5.5999e-01,\n",
       "         -3.3950e-01,  1.2798e-01, -3.3280e-01,  3.3171e-01, -2.3971e-01,\n",
       "          9.6009e-02,  6.7364e-02, -1.9785e-01, -1.4183e+00, -8.2721e-01,\n",
       "         -1.7791e-01, -3.0747e-01,  3.8557e-01, -4.1252e-01,  1.1417e-01,\n",
       "          1.4165e-01,  8.1208e-01,  1.0233e-01,  5.1052e-01,  7.2621e-02,\n",
       "         -9.9826e-01, -6.0093e-01,  8.0697e-01, -5.4043e-01, -1.8478e-01,\n",
       "         -6.3885e-01,  7.2567e-01, -3.7634e-01, -8.6018e-02, -4.7104e-02,\n",
       "          1.8429e-01, -6.7766e-01, -2.8427e-01, -6.4262e-01, -4.1337e-02,\n",
       "          1.7318e-01,  2.1499e-01,  1.1193e-01, -1.5882e-01,  4.4446e-01,\n",
       "         -2.6970e-01, -7.1178e-01,  5.9631e-01, -5.7667e-01, -1.4799e-01,\n",
       "          2.0276e-01, -3.6167e-01,  7.1701e-01,  1.0234e-01,  3.0633e-02,\n",
       "         -4.4383e-01,  3.4412e-01,  2.2048e-01, -2.8399e-01,  1.3151e-01,\n",
       "          7.8576e-02,  5.0515e-02, -2.3009e-01,  8.7277e-02, -1.6198e-01,\n",
       "          3.7681e-01,  7.0038e-01, -9.3888e-02, -4.5939e-01, -2.1923e-01,\n",
       "          3.6462e-01,  6.7435e-02, -5.6881e-01,  1.8588e-01,  2.0571e-01,\n",
       "         -1.7826e-04, -3.7079e-01,  2.1588e-02, -4.5242e-01, -8.5832e-02,\n",
       "         -4.5656e-01, -3.9799e-01,  9.7184e-01, -3.8892e-01, -1.0586e-01,\n",
       "         -4.6069e-01, -1.7864e-02, -7.9811e-01,  6.9931e-02,  1.4691e-01,\n",
       "         -7.2293e-01,  2.4102e-01,  3.3352e-01,  4.4095e-01,  3.4278e-01,\n",
       "         -4.2641e-02,  6.2682e-01, -4.0884e-01, -1.8040e-01,  6.1748e-03,\n",
       "          1.5704e-01, -2.8016e-01, -1.2007e-02, -6.4719e-01,  4.6821e-01,\n",
       "         -3.8579e-01, -1.5149e-01,  2.4640e-01,  4.2466e-01, -4.2425e-01,\n",
       "          4.3892e-01, -1.8439e-01,  1.4944e-01,  3.4186e-01, -6.2071e-02,\n",
       "          4.2045e-01,  4.5098e-01,  4.1467e-01, -6.3893e-01, -2.8622e-01,\n",
       "         -3.1888e-02,  2.2646e-01,  4.7992e-01,  1.0460e-01, -1.9035e-01,\n",
       "         -5.8843e-02,  4.7671e-01,  1.4493e-01,  3.1262e-01, -2.6823e-01,\n",
       "          4.7178e-01,  2.4878e-01,  1.9018e-02,  1.1583e-01,  2.4766e-01,\n",
       "          3.3475e-01, -3.0468e-01, -3.9869e-01,  5.4369e-01,  1.8086e-01,\n",
       "         -5.2170e-01,  5.4330e-01,  1.1655e-01, -2.7966e-01,  1.2198e-01,\n",
       "         -4.4009e-02,  2.3442e-01,  5.9649e-02, -3.5557e-02, -7.8623e-01,\n",
       "         -2.3663e-01, -4.9239e-01,  4.5419e-01,  6.4584e-01, -2.4853e-01,\n",
       "         -1.3325e-02, -7.8379e-02, -1.3440e-01, -8.2897e-02,  2.2879e-01,\n",
       "         -1.9170e-01,  1.2624e+00,  1.5171e-01, -3.6898e-01,  1.6420e-01,\n",
       "         -3.2848e-01, -4.0229e-01,  1.3073e-01,  3.7707e-01,  3.5858e-01,\n",
       "         -2.4322e-01,  8.9739e-02, -2.7945e-02, -1.8568e-01, -1.6199e-02,\n",
       "          1.9739e-03, -4.7173e-01, -5.8865e-01, -1.4942e-01,  2.2166e-01,\n",
       "         -1.4061e-01, -6.8233e-02,  1.0899e-01, -4.9304e-01, -3.9701e-01,\n",
       "         -3.4269e-01,  1.5577e-01, -3.2689e-01, -2.8596e-01, -5.3914e-02,\n",
       "         -2.6600e-01,  4.9731e-01, -9.2336e-02, -6.5197e-02,  4.3505e-02,\n",
       "          5.2191e-01,  1.1459e-01,  1.0276e-01,  4.1782e-01, -4.9392e-01,\n",
       "          3.3776e-01, -4.2365e-01, -2.8955e-01,  4.5146e-01,  1.5701e-01,\n",
       "          1.4923e-01, -7.3331e-01,  1.9315e-01, -3.1216e-01, -5.7412e-01,\n",
       "         -2.2267e-01, -7.7843e-02,  2.3380e-02, -3.6332e-01,  1.7442e-01,\n",
       "          1.4989e-01, -2.3021e-01, -2.2572e-01, -1.0005e-01, -3.0806e-01,\n",
       "          5.2302e-01, -3.2700e-01, -1.9031e-01, -1.8915e-01, -8.6793e-02,\n",
       "          5.1211e-01,  7.3201e-02, -2.9173e-01, -7.5090e-01, -5.9801e-01,\n",
       "          6.8259e+00,  2.4733e-01, -2.8607e-01,  3.2208e-01, -3.8179e-02,\n",
       "         -4.8410e-01,  4.8466e-01, -7.1560e-02,  3.0436e-01, -1.5359e-01,\n",
       "         -1.0702e-01,  5.7282e-01,  1.3014e-01,  5.0989e-02,  2.3707e-01,\n",
       "         -5.3131e-02,  3.6384e-01,  6.5969e-03, -1.5384e-02,  8.1881e-02,\n",
       "          2.2213e-01, -6.2760e-01, -1.4009e-01,  2.1455e-02,  1.1794e+00,\n",
       "         -9.3175e-03, -3.1762e-01, -1.5646e-01, -3.3717e-01, -3.4177e-01,\n",
       "         -2.2319e-01, -4.0528e-01,  1.5469e-01,  2.1829e-01, -1.6630e-02,\n",
       "         -1.8469e-01, -1.5734e-01, -2.3207e-01,  5.9018e-01, -1.6187e-01,\n",
       "          8.1244e-01, -3.8847e-01, -4.4249e-01,  1.1696e-01,  7.5560e-02,\n",
       "          6.0030e-01,  1.5327e-01,  1.3214e-01, -9.7411e-02, -1.6811e-01,\n",
       "         -4.7878e-01,  2.8524e-01, -1.8937e-02, -2.2344e-01,  6.8961e-01,\n",
       "         -6.5763e-01, -8.5576e-01,  3.7576e-03, -3.6161e-01,  4.2624e-02,\n",
       "         -1.9007e-01,  3.1068e+00,  1.0406e-01,  8.4330e-01, -3.3750e-01,\n",
       "          3.5637e-01,  3.4023e-01,  3.0320e-01, -2.7130e-02, -4.7550e-01,\n",
       "          3.8937e-01,  3.5009e-01, -1.7573e-01]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_outputs.mean(1)  # 词向量平均q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5632,  0.1452,  0.4466, -0.1069, -0.5541, -0.7722,  0.1167,  0.7956,\n",
       "        -0.6453,  0.4843,  1.5340, -0.0571, -0.4845,  0.5012,  0.9630,  1.1255,\n",
       "         0.6296,  0.1824,  0.1379,  0.0819, -0.8469,  0.2036,  1.2898, -0.3107,\n",
       "        -0.8340,  0.0492], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_outputs[0, :26, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1784, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_outputs[0, :26, 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3420, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_outputs[0, :26, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 torch.Size([21128, 768])\n",
      "2 torch.Size([512, 768])\n",
      "3 torch.Size([2, 768])\n",
      "4 torch.Size([768])\n",
      "5 torch.Size([768])\n",
      "6 torch.Size([768, 768])\n",
      "7 torch.Size([768])\n",
      "8 torch.Size([768, 768])\n",
      "9 torch.Size([768])\n",
      "10 torch.Size([768, 768])\n",
      "11 torch.Size([768])\n",
      "12 torch.Size([768, 768])\n",
      "13 torch.Size([768])\n",
      "14 torch.Size([768])\n",
      "15 torch.Size([768])\n",
      "16 torch.Size([3072, 768])\n",
      "17 torch.Size([3072])\n",
      "18 torch.Size([768, 3072])\n",
      "19 torch.Size([768])\n",
      "20 torch.Size([768])\n",
      "21 torch.Size([768])\n",
      "22 torch.Size([768, 768])\n",
      "23 torch.Size([768])\n",
      "24 torch.Size([768, 768])\n",
      "25 torch.Size([768])\n",
      "26 torch.Size([768, 768])\n",
      "27 torch.Size([768])\n",
      "28 torch.Size([768, 768])\n",
      "29 torch.Size([768])\n",
      "30 torch.Size([768])\n",
      "31 torch.Size([768])\n",
      "32 torch.Size([3072, 768])\n",
      "33 torch.Size([3072])\n",
      "34 torch.Size([768, 3072])\n",
      "35 torch.Size([768])\n",
      "36 torch.Size([768])\n",
      "37 torch.Size([768])\n",
      "38 torch.Size([768, 768])\n",
      "39 torch.Size([768])\n",
      "40 torch.Size([768, 768])\n",
      "41 torch.Size([768])\n",
      "42 torch.Size([768, 768])\n",
      "43 torch.Size([768])\n",
      "44 torch.Size([768, 768])\n",
      "45 torch.Size([768])\n",
      "46 torch.Size([768])\n",
      "47 torch.Size([768])\n",
      "48 torch.Size([3072, 768])\n",
      "49 torch.Size([3072])\n",
      "50 torch.Size([768, 3072])\n",
      "51 torch.Size([768])\n",
      "52 torch.Size([768])\n",
      "53 torch.Size([768])\n",
      "54 torch.Size([768, 768])\n",
      "55 torch.Size([768])\n",
      "56 torch.Size([768, 768])\n",
      "57 torch.Size([768])\n",
      "58 torch.Size([768, 768])\n",
      "59 torch.Size([768])\n",
      "60 torch.Size([768, 768])\n",
      "61 torch.Size([768])\n",
      "62 torch.Size([768])\n",
      "63 torch.Size([768])\n",
      "64 torch.Size([3072, 768])\n",
      "65 torch.Size([3072])\n",
      "66 torch.Size([768, 3072])\n",
      "67 torch.Size([768])\n",
      "68 torch.Size([768])\n",
      "69 torch.Size([768])\n",
      "70 torch.Size([768, 768])\n",
      "71 torch.Size([768])\n",
      "72 torch.Size([768, 768])\n",
      "73 torch.Size([768])\n",
      "74 torch.Size([768, 768])\n",
      "75 torch.Size([768])\n",
      "76 torch.Size([768, 768])\n",
      "77 torch.Size([768])\n",
      "78 torch.Size([768])\n",
      "79 torch.Size([768])\n",
      "80 torch.Size([3072, 768])\n",
      "81 torch.Size([3072])\n",
      "82 torch.Size([768, 3072])\n",
      "83 torch.Size([768])\n",
      "84 torch.Size([768])\n",
      "85 torch.Size([768])\n",
      "86 torch.Size([768, 768])\n",
      "87 torch.Size([768])\n",
      "88 torch.Size([768, 768])\n",
      "89 torch.Size([768])\n",
      "90 torch.Size([768, 768])\n",
      "91 torch.Size([768])\n",
      "92 torch.Size([768, 768])\n",
      "93 torch.Size([768])\n",
      "94 torch.Size([768])\n",
      "95 torch.Size([768])\n",
      "96 torch.Size([3072, 768])\n",
      "97 torch.Size([3072])\n",
      "98 torch.Size([768, 3072])\n",
      "99 torch.Size([768])\n",
      "100 torch.Size([768])\n",
      "101 torch.Size([768])\n",
      "102 torch.Size([768, 768])\n",
      "103 torch.Size([768])\n",
      "104 torch.Size([768, 768])\n",
      "105 torch.Size([768])\n",
      "106 torch.Size([768, 768])\n",
      "107 torch.Size([768])\n",
      "108 torch.Size([768, 768])\n",
      "109 torch.Size([768])\n",
      "110 torch.Size([768])\n",
      "111 torch.Size([768])\n",
      "112 torch.Size([3072, 768])\n",
      "113 torch.Size([3072])\n",
      "114 torch.Size([768, 3072])\n",
      "115 torch.Size([768])\n",
      "116 torch.Size([768])\n",
      "117 torch.Size([768])\n",
      "118 torch.Size([768, 768])\n",
      "119 torch.Size([768])\n",
      "120 torch.Size([768, 768])\n",
      "121 torch.Size([768])\n",
      "122 torch.Size([768, 768])\n",
      "123 torch.Size([768])\n",
      "124 torch.Size([768, 768])\n",
      "125 torch.Size([768])\n",
      "126 torch.Size([768])\n",
      "127 torch.Size([768])\n",
      "128 torch.Size([3072, 768])\n",
      "129 torch.Size([3072])\n",
      "130 torch.Size([768, 3072])\n",
      "131 torch.Size([768])\n",
      "132 torch.Size([768])\n",
      "133 torch.Size([768])\n",
      "134 torch.Size([768, 768])\n",
      "135 torch.Size([768])\n",
      "136 torch.Size([768, 768])\n",
      "137 torch.Size([768])\n",
      "138 torch.Size([768, 768])\n",
      "139 torch.Size([768])\n",
      "140 torch.Size([768, 768])\n",
      "141 torch.Size([768])\n",
      "142 torch.Size([768])\n",
      "143 torch.Size([768])\n",
      "144 torch.Size([3072, 768])\n",
      "145 torch.Size([3072])\n",
      "146 torch.Size([768, 3072])\n",
      "147 torch.Size([768])\n",
      "148 torch.Size([768])\n",
      "149 torch.Size([768])\n",
      "150 torch.Size([768, 768])\n",
      "151 torch.Size([768])\n",
      "152 torch.Size([768, 768])\n",
      "153 torch.Size([768])\n",
      "154 torch.Size([768, 768])\n",
      "155 torch.Size([768])\n",
      "156 torch.Size([768, 768])\n",
      "157 torch.Size([768])\n",
      "158 torch.Size([768])\n",
      "159 torch.Size([768])\n",
      "160 torch.Size([3072, 768])\n",
      "161 torch.Size([3072])\n",
      "162 torch.Size([768, 3072])\n",
      "163 torch.Size([768])\n",
      "164 torch.Size([768])\n",
      "165 torch.Size([768])\n",
      "166 torch.Size([768, 768])\n",
      "167 torch.Size([768])\n",
      "168 torch.Size([768, 768])\n",
      "169 torch.Size([768])\n",
      "170 torch.Size([768, 768])\n",
      "171 torch.Size([768])\n",
      "172 torch.Size([768, 768])\n",
      "173 torch.Size([768])\n",
      "174 torch.Size([768])\n",
      "175 torch.Size([768])\n",
      "176 torch.Size([3072, 768])\n",
      "177 torch.Size([3072])\n",
      "178 torch.Size([768, 3072])\n",
      "179 torch.Size([768])\n",
      "180 torch.Size([768])\n",
      "181 torch.Size([768])\n",
      "182 torch.Size([768, 768])\n",
      "183 torch.Size([768])\n",
      "184 torch.Size([768, 768])\n",
      "185 torch.Size([768])\n",
      "186 torch.Size([768, 768])\n",
      "187 torch.Size([768])\n",
      "188 torch.Size([768, 768])\n",
      "189 torch.Size([768])\n",
      "190 torch.Size([768])\n",
      "191 torch.Size([768])\n",
      "192 torch.Size([3072, 768])\n",
      "193 torch.Size([3072])\n",
      "194 torch.Size([768, 3072])\n",
      "195 torch.Size([768])\n",
      "196 torch.Size([768])\n",
      "197 torch.Size([768])\n",
      "198 torch.Size([768, 768])\n",
      "199 torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for idx, x in enumerate(model.parameters(),1):\n",
    "    print(idx, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.position_ids\n",
      "embeddings.word_embeddings.weight\n",
      "embeddings.position_embeddings.weight\n",
      "embeddings.token_type_embeddings.weight\n",
      "embeddings.LayerNorm.weight\n",
      "embeddings.LayerNorm.bias\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "encoder.layer.4.attention.self.query.weight\n",
      "encoder.layer.4.attention.self.query.bias\n",
      "encoder.layer.4.attention.self.key.weight\n",
      "encoder.layer.4.attention.self.key.bias\n",
      "encoder.layer.4.attention.self.value.weight\n",
      "encoder.layer.4.attention.self.value.bias\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "encoder.layer.5.attention.self.query.weight\n",
      "encoder.layer.5.attention.self.query.bias\n",
      "encoder.layer.5.attention.self.key.weight\n",
      "encoder.layer.5.attention.self.key.bias\n",
      "encoder.layer.5.attention.self.value.weight\n",
      "encoder.layer.5.attention.self.value.bias\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "encoder.layer.6.attention.self.query.weight\n",
      "encoder.layer.6.attention.self.query.bias\n",
      "encoder.layer.6.attention.self.key.weight\n",
      "encoder.layer.6.attention.self.key.bias\n",
      "encoder.layer.6.attention.self.value.weight\n",
      "encoder.layer.6.attention.self.value.bias\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "encoder.layer.7.attention.self.query.weight\n",
      "encoder.layer.7.attention.self.query.bias\n",
      "encoder.layer.7.attention.self.key.weight\n",
      "encoder.layer.7.attention.self.key.bias\n",
      "encoder.layer.7.attention.self.value.weight\n",
      "encoder.layer.7.attention.self.value.bias\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "encoder.layer.8.attention.self.query.weight\n",
      "encoder.layer.8.attention.self.query.bias\n",
      "encoder.layer.8.attention.self.key.weight\n",
      "encoder.layer.8.attention.self.key.bias\n",
      "encoder.layer.8.attention.self.value.weight\n",
      "encoder.layer.8.attention.self.value.bias\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "encoder.layer.9.attention.self.query.weight\n",
      "encoder.layer.9.attention.self.query.bias\n",
      "encoder.layer.9.attention.self.key.weight\n",
      "encoder.layer.9.attention.self.key.bias\n",
      "encoder.layer.9.attention.self.value.weight\n",
      "encoder.layer.9.attention.self.value.bias\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "encoder.layer.10.attention.self.query.weight\n",
      "encoder.layer.10.attention.self.query.bias\n",
      "encoder.layer.10.attention.self.key.weight\n",
      "encoder.layer.10.attention.self.key.bias\n",
      "encoder.layer.10.attention.self.value.weight\n",
      "encoder.layer.10.attention.self.value.bias\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "encoder.layer.11.attention.self.query.weight\n",
      "encoder.layer.11.attention.self.query.bias\n",
      "encoder.layer.11.attention.self.key.weight\n",
      "encoder.layer.11.attention.self.key.bias\n",
      "encoder.layer.11.attention.self.value.weight\n",
      "encoder.layer.11.attention.self.value.bias\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "pooler.dense.weight\n",
      "pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for x in model.state_dict():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers==3.1.0 -i https://mirrors.aliyun.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch 转onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"data/bert-base-chinese\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokernizer = BertTokenizer.from_pretrained(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2769,  812, 3341, 6407, 6407, 4281, 6873, 4638, 8815, 8716, 3563,\n",
       "         1798, 1416,  117, 1420, 6432, 2124, 7478, 2382, 1326, 2154, 1557,  102,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokernizer(\"我们来试试牛逼的bert模型吧, 听说它非常厉害啊\",\n",
    "                    max_length = 64,  # maximum length of a sentence\n",
    "                    pad_to_max_length=True,  # Add [PAD]s\n",
    "                    return_attention_mask = True,\n",
    "                    return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2769,  812, 3341, 6407, 6407, 4281, 6873, 4638, 8815, 8716, 3563,\n",
       "         1798, 1416,  117, 1420, 6432, 2124, 7478, 2382, 1326, 2154, 1557,  102,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp2 = tokernizer.encode_plus(\"我们来试试牛逼的bert模型吧, 听说它非常厉害啊\",\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    max_length = 64,  # maximum length of a sentence\n",
    "                    pad_to_max_length=True,  # Add [PAD]s\n",
    "                    return_attention_mask = True,\n",
    "                    return_tensors=\"pt\")\n",
    "inp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 101, 2769,  812, 3341, 6407, 6407, 4281, 6873, 4638, 8815, 8716,\n",
       "       3563, 1798, 1416,  117, 1420, 6432, 2124, 7478, 2382, 1326, 2154,\n",
       "       1557,  102])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = inp2[\"input_ids\"].data.cpu().numpy().reshape(-1)\n",
    "ids[ids!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokernizer.decode(inp2[\"input_ids\"].data.cpu().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tokernizer.encode_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2769,  812, 3341, 6407, 6407, 4281, 6873, 4638, 8815, 8716, 3563,\n",
       "         1798, 1416,  117, 1420, 6432, 2124, 7478, 2382, 1326, 2154, 1557,  102]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = inputs['input_ids']\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_ids = inputs['token_type_ids']\n",
    "token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = inputs['attention_mask']\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (input_ids, token_type_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:201: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  position_ids = self.position_ids[:, :seq_length]\n",
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_utils.py:1570: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  input_tensor.shape == tensor_shape for input_tensor in input_tensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Long(1, 15),\n",
      "      %attention_mask : Long(1, 15),\n",
      "      %input.3 : Long(1, 15),\n",
      "      %embeddings.position_ids : Long(1, 512),\n",
      "      %embeddings.word_embeddings.weight : Float(21128, 768),\n",
      "      %embeddings.position_embeddings.weight : Float(512, 768),\n",
      "      %embeddings.token_type_embeddings.weight : Float(2, 768),\n",
      "      %embeddings.LayerNorm.weight : Float(768),\n",
      "      %embeddings.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.0.attention.self.query.weight : Float(768, 768),\n",
      "      %encoder.layer.0.attention.self.query.bias : Float(768),\n",
      "      %encoder.layer.0.attention.self.key.weight : Float(768, 768),\n",
      "      %encoder.layer.0.attention.self.key.bias : Float(768),\n",
      "      %encoder.layer.0.attention.self.value.weight : Float(768, 768),\n",
      "      %encoder.layer.0.attention.self.value.bias : Float(768),\n",
      "      %encoder.layer.0.attention.output.dense.weight : Float(768, 768),\n",
      "      %encoder.layer.0.attention.output.dense.bias : Float(768),\n",
      "      %encoder.layer.0.attention.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.0.attention.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.0.intermediate.dense.weight : Float(3072, 768),\n",
      "      %encoder.layer.0.intermediate.dense.bias : Float(3072),\n",
      "      %encoder.layer.0.output.dense.weight : Float(768, 3072),\n",
      "      %encoder.layer.0.output.dense.bias : Float(768),\n",
      "      %encoder.layer.0.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.0.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.1.attention.self.query.weight : Float(768, 768),\n",
      "      %encoder.layer.1.attention.self.query.bias : Float(768),\n",
      "      %encoder.layer.1.attention.self.key.weight : Float(768, 768),\n",
      "      %encoder.layer.1.attention.self.key.bias : Float(768),\n",
      "      %encoder.layer.1.attention.self.value.weight : Float(768, 768),\n",
      "      %encoder.layer.1.attention.self.value.bias : Float(768),\n",
      "      %encoder.layer.1.attention.output.dense.weight : Float(768, 768),\n",
      "      %encoder.layer.1.attention.output.dense.bias : Float(768),\n",
      "      %encoder.layer.1.attention.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.1.attention.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.1.intermediate.dense.weight : Float(3072, 768),\n",
      "      %encoder.layer.1.intermediate.dense.bias : Float(3072),\n",
      "      %encoder.layer.1.output.dense.weight : Float(768, 3072),\n",
      "      %encoder.layer.1.output.dense.bias : Float(768),\n",
      "      %encoder.layer.1.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.1.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.2.attention.self.query.weight : Float(768, 768),\n",
      "      %encoder.layer.2.attention.self.query.bias : Float(768),\n",
      "      %encoder.layer.2.attention.self.key.weight : Float(768, 768),\n",
      "      %encoder.layer.2.attention.self.key.bias : Float(768),\n",
      "      %encoder.layer.2.attention.self.value.weight : Float(768, 768),\n",
      "      %encoder.layer.2.attention.self.value.bias : Float(768),\n",
      "      %encoder.layer.2.attention.output.dense.weight : Float(768, 768),\n",
      "      %encoder.layer.2.attention.output.dense.bias : Float(768),\n",
      "      %encoder.layer.2.attention.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.2.attention.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.2.intermediate.dense.weight : Float(3072, 768),\n",
      "      %encoder.layer.2.intermediate.dense.bias : Float(3072),\n",
      "      %encoder.layer.2.output.dense.weight : Float(768, 3072),\n",
      "      %encoder.layer.2.output.dense.bias : Float(768),\n",
      "      %encoder.layer.2.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.2.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.3.attention.self.query.weight : Float(768, 768),\n",
      "      %encoder.layer.3.attention.self.query.bias : Float(768),\n",
      "      %encoder.layer.3.attention.self.key.weight : Float(768, 768),\n",
      "      %encoder.layer.3.attention.self.key.bias : Float(768),\n",
      "      %encoder.layer.3.attention.self.value.weight : Float(768, 768),\n",
      "      %encoder.layer.3.attention.self.value.bias : Float(768),\n",
      "      %encoder.layer.3.attention.output.dense.weight : Float(768, 768),\n",
      "      %encoder.layer.3.attention.output.dense.bias : Float(768),\n",
      "      %encoder.layer.3.attention.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.3.attention.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.3.intermediate.dense.weight : Float(3072, 768),\n",
      "      %encoder.layer.3.intermediate.dense.bias : Float(3072),\n",
      "      %encoder.layer.3.output.dense.weight : Float(768, 3072),\n",
      "      %encoder.layer.3.output.dense.bias : Float(768),\n",
      "      %encoder.layer.3.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.3.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.4.attention.self.query.weight : Float(768, 768),\n",
      "      %encoder.layer.4.attention.self.query.bias : Float(768),\n",
      "      %encoder.layer.4.attention.self.key.weight : Float(768, 768),\n",
      "      %encoder.layer.4.attention.self.key.bias : Float(768),\n",
      "      %encoder.layer.4.attention.self.value.weight : Float(768, 768),\n",
      "      %encoder.layer.4.attention.self.value.bias : Float(768),\n",
      "      %encoder.layer.4.attention.output.dense.weight : Float(768, 768),\n",
      "      %encoder.layer.4.attention.output.dense.bias : Float(768),\n",
      "      %encoder.layer.4.attention.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.4.attention.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.4.intermediate.dense.weight : Float(3072, 768),\n",
      "      %encoder.layer.4.intermediate.dense.bias : Float(3072),\n",
      "      %encoder.layer.4.output.dense.weight : Float(768, 3072),\n",
      "      %encoder.layer.4.output.dense.bias : Float(768),\n",
      "      %encoder.layer.4.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.4.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.5.attention.self.query.weight : Float(768, 768),\n",
      "      %encoder.layer.5.attention.self.query.bias : Float(768),\n",
      "      %encoder.layer.5.attention.self.key.weight : Float(768, 768),\n",
      "      %encoder.layer.5.attention.self.key.bias : Float(768),\n",
      "      %encoder.layer.5.attention.self.value.weight : Float(768, 768),\n",
      "      %encoder.layer.5.attention.self.value.bias : Float(768),\n",
      "      %encoder.layer.5.attention.output.dense.weight : Float(768, 768),\n",
      "      %encoder.layer.5.attention.output.dense.bias : Float(768),\n",
      "      %encoder.layer.5.attention.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.5.attention.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.5.intermediate.dense.weight : Float(3072, 768),\n",
      "      %encoder.layer.5.intermediate.dense.bias : Float(3072),\n",
      "      %encoder.layer.5.output.dense.weight : Float(768, 3072),\n",
      "      %encoder.layer.5.output.dense.bias : Float(768),\n",
      "      %encoder.layer.5.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.5.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.6.attention.self.query.weight : Float(768, 768),\n",
      "      %encoder.layer.6.attention.self.query.bias : Float(768),\n",
      "      %encoder.layer.6.attention.self.key.weight : Float(768, 768),\n",
      "      %encoder.layer.6.attention.self.key.bias : Float(768),\n",
      "      %encoder.layer.6.attention.self.value.weight : Float(768, 768),\n",
      "      %encoder.layer.6.attention.self.value.bias : Float(768),\n",
      "      %encoder.layer.6.attention.output.dense.weight : Float(768, 768),\n",
      "      %encoder.layer.6.attention.output.dense.bias : Float(768),\n",
      "      %encoder.layer.6.attention.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.6.attention.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.6.intermediate.dense.weight : Float(3072, 768),\n",
      "      %encoder.layer.6.intermediate.dense.bias : Float(3072),\n",
      "      %encoder.layer.6.output.dense.weight : Float(768, 3072),\n",
      "      %encoder.layer.6.output.dense.bias : Float(768),\n",
      "      %encoder.layer.6.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.6.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.7.attention.self.query.weight : Float(768, 768),\n",
      "      %encoder.layer.7.attention.self.query.bias : Float(768),\n",
      "      %encoder.layer.7.attention.self.key.weight : Float(768, 768),\n",
      "      %encoder.layer.7.attention.self.key.bias : Float(768),\n",
      "      %encoder.layer.7.attention.self.value.weight : Float(768, 768),\n",
      "      %encoder.layer.7.attention.self.value.bias : Float(768),\n",
      "      %encoder.layer.7.attention.output.dense.weight : Float(768, 768),\n",
      "      %encoder.layer.7.attention.output.dense.bias : Float(768),\n",
      "      %encoder.layer.7.attention.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.7.attention.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.7.intermediate.dense.weight : Float(3072, 768),\n",
      "      %encoder.layer.7.intermediate.dense.bias : Float(3072),\n",
      "      %encoder.layer.7.output.dense.weight : Float(768, 3072),\n",
      "      %encoder.layer.7.output.dense.bias : Float(768),\n",
      "      %encoder.layer.7.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.7.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.8.attention.self.query.weight : Float(768, 768),\n",
      "      %encoder.layer.8.attention.self.query.bias : Float(768),\n",
      "      %encoder.layer.8.attention.self.key.weight : Float(768, 768),\n",
      "      %encoder.layer.8.attention.self.key.bias : Float(768),\n",
      "      %encoder.layer.8.attention.self.value.weight : Float(768, 768),\n",
      "      %encoder.layer.8.attention.self.value.bias : Float(768),\n",
      "      %encoder.layer.8.attention.output.dense.weight : Float(768, 768),\n",
      "      %encoder.layer.8.attention.output.dense.bias : Float(768),\n",
      "      %encoder.layer.8.attention.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.8.attention.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.8.intermediate.dense.weight : Float(3072, 768),\n",
      "      %encoder.layer.8.intermediate.dense.bias : Float(3072),\n",
      "      %encoder.layer.8.output.dense.weight : Float(768, 3072),\n",
      "      %encoder.layer.8.output.dense.bias : Float(768),\n",
      "      %encoder.layer.8.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.8.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.9.attention.self.query.weight : Float(768, 768),\n",
      "      %encoder.layer.9.attention.self.query.bias : Float(768),\n",
      "      %encoder.layer.9.attention.self.key.weight : Float(768, 768),\n",
      "      %encoder.layer.9.attention.self.key.bias : Float(768),\n",
      "      %encoder.layer.9.attention.self.value.weight : Float(768, 768),\n",
      "      %encoder.layer.9.attention.self.value.bias : Float(768),\n",
      "      %encoder.layer.9.attention.output.dense.weight : Float(768, 768),\n",
      "      %encoder.layer.9.attention.output.dense.bias : Float(768),\n",
      "      %encoder.layer.9.attention.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.9.attention.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.9.intermediate.dense.weight : Float(3072, 768),\n",
      "      %encoder.layer.9.intermediate.dense.bias : Float(3072),\n",
      "      %encoder.layer.9.output.dense.weight : Float(768, 3072),\n",
      "      %encoder.layer.9.output.dense.bias : Float(768),\n",
      "      %encoder.layer.9.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.9.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.10.attention.self.query.weight : Float(768, 768),\n",
      "      %encoder.layer.10.attention.self.query.bias : Float(768),\n",
      "      %encoder.layer.10.attention.self.key.weight : Float(768, 768),\n",
      "      %encoder.layer.10.attention.self.key.bias : Float(768),\n",
      "      %encoder.layer.10.attention.self.value.weight : Float(768, 768),\n",
      "      %encoder.layer.10.attention.self.value.bias : Float(768),\n",
      "      %encoder.layer.10.attention.output.dense.weight : Float(768, 768),\n",
      "      %encoder.layer.10.attention.output.dense.bias : Float(768),\n",
      "      %encoder.layer.10.attention.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.10.attention.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.10.intermediate.dense.weight : Float(3072, 768),\n",
      "      %encoder.layer.10.intermediate.dense.bias : Float(3072),\n",
      "      %encoder.layer.10.output.dense.weight : Float(768, 3072),\n",
      "      %encoder.layer.10.output.dense.bias : Float(768),\n",
      "      %encoder.layer.10.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.10.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.11.attention.self.query.weight : Float(768, 768),\n",
      "      %encoder.layer.11.attention.self.query.bias : Float(768),\n",
      "      %encoder.layer.11.attention.self.key.weight : Float(768, 768),\n",
      "      %encoder.layer.11.attention.self.key.bias : Float(768),\n",
      "      %encoder.layer.11.attention.self.value.weight : Float(768, 768),\n",
      "      %encoder.layer.11.attention.self.value.bias : Float(768),\n",
      "      %encoder.layer.11.attention.output.dense.weight : Float(768, 768),\n",
      "      %encoder.layer.11.attention.output.dense.bias : Float(768),\n",
      "      %encoder.layer.11.attention.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.11.attention.output.LayerNorm.bias : Float(768),\n",
      "      %encoder.layer.11.intermediate.dense.weight : Float(3072, 768),\n",
      "      %encoder.layer.11.intermediate.dense.bias : Float(3072),\n",
      "      %encoder.layer.11.output.dense.weight : Float(768, 3072),\n",
      "      %encoder.layer.11.output.dense.bias : Float(768),\n",
      "      %encoder.layer.11.output.LayerNorm.weight : Float(768),\n",
      "      %encoder.layer.11.output.LayerNorm.bias : Float(768),\n",
      "      %pooler.dense.weight : Float(768, 768),\n",
      "      %pooler.dense.bias : Float(768)):\n",
      "  %203 : Long(1, 1, 15) = onnx::Unsqueeze[axes=[1]](%attention_mask), scope: BertModel # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_utils.py:258:0\n",
      "  %204 : Long(1, 1, 1, 15) = onnx::Unsqueeze[axes=[2]](%203), scope: BertModel # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_utils.py:258:0\n",
      "  %205 : Float(1, 1, 1, 15) = onnx::Cast[to=1](%204), scope: BertModel # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_utils.py:271:0\n",
      "  %206 : Float() = onnx::Constant[value={1}]()\n",
      "  %207 : Float(1, 1, 1, 15) = onnx::Sub(%206, %205), scope: BertModel # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/tensor.py:346:0\n",
      "  %208 : Float() = onnx::Constant[value={-10000}]()\n",
      "  %209 : Float(1, 1, 1, 15) = onnx::Mul(%207, %208)\n",
      "  %210 : Tensor = onnx::Constant[value={1}](), scope: BertModel/BertEmbeddings[embeddings]\n",
      "  %211 : Tensor = onnx::Constant[value={0}](), scope: BertModel/BertEmbeddings[embeddings]\n",
      "  %212 : Tensor = onnx::Constant[value={15}](), scope: BertModel/BertEmbeddings[embeddings]\n",
      "  %213 : Tensor = onnx::Constant[value={1}](), scope: BertModel/BertEmbeddings[embeddings]\n",
      "  %214 : Long(1, 15) = onnx::Slice(%embeddings.position_ids, %211, %212, %210, %213), scope: BertModel/BertEmbeddings[embeddings] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:201:0\n",
      "  %215 : Float(1, 15, 768) = onnx::Gather(%embeddings.word_embeddings.weight, %input.1), scope: BertModel/BertEmbeddings[embeddings]/Embedding[word_embeddings] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1484:0\n",
      "  %216 : Float(1, 15, 768) = onnx::Gather(%embeddings.position_embeddings.weight, %214), scope: BertModel/BertEmbeddings[embeddings]/Embedding[position_embeddings] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1484:0\n",
      "  %217 : Float(1, 15, 768) = onnx::Gather(%embeddings.token_type_embeddings.weight, %input.3), scope: BertModel/BertEmbeddings[embeddings]/Embedding[token_type_embeddings] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1484:0\n",
      "  %218 : Float(1, 15, 768) = onnx::Add(%215, %216), scope: BertModel/BertEmbeddings[embeddings] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:211:0\n",
      "  %219 : Float(1, 15, 768) = onnx::Add(%218, %217), scope: BertModel/BertEmbeddings[embeddings] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:211:0\n",
      "  %220 : Tensor = onnx::ReduceMean[axes=[-1]](%219), scope: BertModel/BertEmbeddings[embeddings]/LayerNorm[LayerNorm]\n",
      "  %221 : FloatTensor = onnx::Sub(%219, %220), scope: BertModel/BertEmbeddings[embeddings]/LayerNorm[LayerNorm]\n",
      "  %222 : Float() = onnx::Constant[value={2}]()\n",
      "  %223 : FloatTensor = onnx::Pow(%221, %222), scope: BertModel/BertEmbeddings[embeddings]/LayerNorm[LayerNorm]\n",
      "  %224 : Tensor = onnx::ReduceMean[axes=[-1]](%223), scope: BertModel/BertEmbeddings[embeddings]/LayerNorm[LayerNorm]\n",
      "  %225 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %226 : FloatTensor = onnx::Add(%224, %225), scope: BertModel/BertEmbeddings[embeddings]/LayerNorm[LayerNorm]\n",
      "  %227 : Tensor = onnx::Sqrt(%226), scope: BertModel/BertEmbeddings[embeddings]/LayerNorm[LayerNorm]\n",
      "  %228 : FloatTensor = onnx::Div(%221, %227), scope: BertModel/BertEmbeddings[embeddings]/LayerNorm[LayerNorm]\n",
      "  %229 : FloatTensor = onnx::Mul(%228, %embeddings.LayerNorm.weight), scope: BertModel/BertEmbeddings[embeddings]/LayerNorm[LayerNorm]\n",
      "  %230 : Float(1, 15, 768) = onnx::Add(%229, %embeddings.LayerNorm.bias), scope: BertModel/BertEmbeddings[embeddings]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %231 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.0.attention.self.query.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %232 : Float(1, 15, 768) = onnx::MatMul(%230, %231), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %233 : Float(1, 15, 768) = onnx::Add(%232, %encoder.layer.0.attention.self.query.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %234 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.0.attention.self.key.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %235 : Float(1, 15, 768) = onnx::MatMul(%230, %234), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %236 : Float(1, 15, 768) = onnx::Add(%235, %encoder.layer.0.attention.self.key.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %237 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.0.attention.self.value.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %238 : Float(1, 15, 768) = onnx::MatMul(%230, %237), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %239 : Float(1, 15, 768) = onnx::Add(%238, %encoder.layer.0.attention.self.value.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %240 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %241 : Tensor = onnx::Shape(%233), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %242 : Long() = onnx::Gather[axis=0](%241, %240), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %243 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %244 : Tensor = onnx::Shape(%233), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %245 : Long() = onnx::Gather[axis=0](%244, %243), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %246 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %247 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %248 : Tensor = onnx::Unsqueeze[axes=[0]](%242)\n",
      "  %249 : Tensor = onnx::Unsqueeze[axes=[0]](%245)\n",
      "  %250 : Tensor = onnx::Unsqueeze[axes=[0]](%246)\n",
      "  %251 : Tensor = onnx::Unsqueeze[axes=[0]](%247)\n",
      "  %252 : Tensor = onnx::Concat[axis=0](%248, %249, %250, %251)\n",
      "  %253 : Float(1, 15, 12, 64) = onnx::Reshape(%233, %252), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %254 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%253), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %255 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %256 : Tensor = onnx::Shape(%236), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %257 : Long() = onnx::Gather[axis=0](%256, %255), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %258 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %259 : Tensor = onnx::Shape(%236), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %260 : Long() = onnx::Gather[axis=0](%259, %258), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %261 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %262 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %263 : Tensor = onnx::Unsqueeze[axes=[0]](%257)\n",
      "  %264 : Tensor = onnx::Unsqueeze[axes=[0]](%260)\n",
      "  %265 : Tensor = onnx::Unsqueeze[axes=[0]](%261)\n",
      "  %266 : Tensor = onnx::Unsqueeze[axes=[0]](%262)\n",
      "  %267 : Tensor = onnx::Concat[axis=0](%263, %264, %265, %266)\n",
      "  %268 : Float(1, 15, 12, 64) = onnx::Reshape(%236, %267), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %269 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %270 : Tensor = onnx::Shape(%239), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %271 : Long() = onnx::Gather[axis=0](%270, %269), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %272 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %273 : Tensor = onnx::Shape(%239), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %274 : Long() = onnx::Gather[axis=0](%273, %272), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %275 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %276 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %277 : Tensor = onnx::Unsqueeze[axes=[0]](%271)\n",
      "  %278 : Tensor = onnx::Unsqueeze[axes=[0]](%274)\n",
      "  %279 : Tensor = onnx::Unsqueeze[axes=[0]](%275)\n",
      "  %280 : Tensor = onnx::Unsqueeze[axes=[0]](%276)\n",
      "  %281 : Tensor = onnx::Concat[axis=0](%277, %278, %279, %280)\n",
      "  %282 : Float(1, 15, 12, 64) = onnx::Reshape(%239, %281), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %283 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%282), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %284 : Float(1, 12, 64, 15) = onnx::Transpose[perm=[0, 2, 3, 1]](%268), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %285 : Float(1, 12, 15, 15) = onnx::MatMul(%254, %284), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %286 : Float() = onnx::Constant[value={8}]()\n",
      "  %287 : Float(1, 12, 15, 15) = onnx::Div(%285, %286)\n",
      "  %288 : Float(1, 12, 15, 15) = onnx::Add(%287, %209), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:272:0\n",
      "  %289 : Float(1, 12, 15, 15) = onnx::Softmax[axis=3](%288), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %290 : Float(1, 12, 15, 64) = onnx::MatMul(%289, %283), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:285:0\n",
      "  %291 : Float(1, 15, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%290), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:287:0\n",
      "  %292 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %293 : Tensor = onnx::Shape(%291), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %294 : Long() = onnx::Gather[axis=0](%293, %292), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %295 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %296 : Tensor = onnx::Shape(%291), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %297 : Long() = onnx::Gather[axis=0](%296, %295), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %298 : Long() = onnx::Constant[value={768}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %299 : Tensor = onnx::Unsqueeze[axes=[0]](%294)\n",
      "  %300 : Tensor = onnx::Unsqueeze[axes=[0]](%297)\n",
      "  %301 : Tensor = onnx::Unsqueeze[axes=[0]](%298)\n",
      "  %302 : Tensor = onnx::Concat[axis=0](%299, %300, %301)\n",
      "  %303 : Float(1, 15, 768) = onnx::Reshape(%291, %302), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:289:0\n",
      "  %304 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.0.attention.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %305 : Float(1, 15, 768) = onnx::MatMul(%303, %304), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %306 : Float(1, 15, 768) = onnx::Add(%305, %encoder.layer.0.attention.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %307 : Float(1, 15, 768) = onnx::Add(%306, %230), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:305:0\n",
      "  %308 : Tensor = onnx::ReduceMean[axes=[-1]](%307), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %309 : FloatTensor = onnx::Sub(%307, %308), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %310 : Float() = onnx::Constant[value={2}]()\n",
      "  %311 : FloatTensor = onnx::Pow(%309, %310), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %312 : Tensor = onnx::ReduceMean[axes=[-1]](%311), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %313 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %314 : FloatTensor = onnx::Add(%312, %313), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %315 : Tensor = onnx::Sqrt(%314), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %316 : FloatTensor = onnx::Div(%309, %315), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %317 : FloatTensor = onnx::Mul(%316, %encoder.layer.0.attention.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %318 : Float(1, 15, 768) = onnx::Add(%317, %encoder.layer.0.attention.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %319 : Float(768, 3072) = onnx::Transpose[perm=[1, 0]](%encoder.layer.0.intermediate.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %320 : Float(1, 15, 3072) = onnx::MatMul(%318, %319), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %321 : Float(1, 15, 3072) = onnx::Add(%320, %encoder.layer.0.intermediate.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %322 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %323 : Float(1, 15, 3072) = onnx::Mul(%321, %322)\n",
      "  %324 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %325 : Float(1, 15, 3072) = onnx::Div(%321, %324)\n",
      "  %326 : Float(1, 15, 3072) = onnx::Erf(%325), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %327 : Float() = onnx::Constant[value={1}]()\n",
      "  %328 : Float(1, 15, 3072) = onnx::Add(%326, %327)\n",
      "  %329 : Float(1, 15, 3072) = onnx::Mul(%323, %328), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %330 : Float(3072, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.0.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %331 : Float(1, 15, 768) = onnx::MatMul(%329, %330), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %332 : Float(1, 15, 768) = onnx::Add(%331, %encoder.layer.0.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %333 : Float(1, 15, 768) = onnx::Add(%332, %318), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:381:0\n",
      "  %334 : Tensor = onnx::ReduceMean[axes=[-1]](%333), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %335 : FloatTensor = onnx::Sub(%333, %334), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %336 : Float() = onnx::Constant[value={2}]()\n",
      "  %337 : FloatTensor = onnx::Pow(%335, %336), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %338 : Tensor = onnx::ReduceMean[axes=[-1]](%337), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %339 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %340 : FloatTensor = onnx::Add(%338, %339), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %341 : Tensor = onnx::Sqrt(%340), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %342 : FloatTensor = onnx::Div(%335, %341), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %343 : FloatTensor = onnx::Mul(%342, %encoder.layer.0.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %344 : Float(1, 15, 768) = onnx::Add(%343, %encoder.layer.0.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %345 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.1.attention.self.query.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %346 : Float(1, 15, 768) = onnx::MatMul(%344, %345), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %347 : Float(1, 15, 768) = onnx::Add(%346, %encoder.layer.1.attention.self.query.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %348 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.1.attention.self.key.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %349 : Float(1, 15, 768) = onnx::MatMul(%344, %348), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %350 : Float(1, 15, 768) = onnx::Add(%349, %encoder.layer.1.attention.self.key.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %351 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.1.attention.self.value.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %352 : Float(1, 15, 768) = onnx::MatMul(%344, %351), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %353 : Float(1, 15, 768) = onnx::Add(%352, %encoder.layer.1.attention.self.value.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %354 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %355 : Tensor = onnx::Shape(%347), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %356 : Long() = onnx::Gather[axis=0](%355, %354), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %357 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %358 : Tensor = onnx::Shape(%347), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %359 : Long() = onnx::Gather[axis=0](%358, %357), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %360 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %361 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %362 : Tensor = onnx::Unsqueeze[axes=[0]](%356)\n",
      "  %363 : Tensor = onnx::Unsqueeze[axes=[0]](%359)\n",
      "  %364 : Tensor = onnx::Unsqueeze[axes=[0]](%360)\n",
      "  %365 : Tensor = onnx::Unsqueeze[axes=[0]](%361)\n",
      "  %366 : Tensor = onnx::Concat[axis=0](%362, %363, %364, %365)\n",
      "  %367 : Float(1, 15, 12, 64) = onnx::Reshape(%347, %366), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %368 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%367), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %369 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %370 : Tensor = onnx::Shape(%350), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %371 : Long() = onnx::Gather[axis=0](%370, %369), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %372 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %373 : Tensor = onnx::Shape(%350), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %374 : Long() = onnx::Gather[axis=0](%373, %372), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %375 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %376 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %377 : Tensor = onnx::Unsqueeze[axes=[0]](%371)\n",
      "  %378 : Tensor = onnx::Unsqueeze[axes=[0]](%374)\n",
      "  %379 : Tensor = onnx::Unsqueeze[axes=[0]](%375)\n",
      "  %380 : Tensor = onnx::Unsqueeze[axes=[0]](%376)\n",
      "  %381 : Tensor = onnx::Concat[axis=0](%377, %378, %379, %380)\n",
      "  %382 : Float(1, 15, 12, 64) = onnx::Reshape(%350, %381), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %383 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %384 : Tensor = onnx::Shape(%353), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %385 : Long() = onnx::Gather[axis=0](%384, %383), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %386 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %387 : Tensor = onnx::Shape(%353), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %388 : Long() = onnx::Gather[axis=0](%387, %386), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %389 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %390 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %391 : Tensor = onnx::Unsqueeze[axes=[0]](%385)\n",
      "  %392 : Tensor = onnx::Unsqueeze[axes=[0]](%388)\n",
      "  %393 : Tensor = onnx::Unsqueeze[axes=[0]](%389)\n",
      "  %394 : Tensor = onnx::Unsqueeze[axes=[0]](%390)\n",
      "  %395 : Tensor = onnx::Concat[axis=0](%391, %392, %393, %394)\n",
      "  %396 : Float(1, 15, 12, 64) = onnx::Reshape(%353, %395), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %397 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%396), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %398 : Float(1, 12, 64, 15) = onnx::Transpose[perm=[0, 2, 3, 1]](%382), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %399 : Float(1, 12, 15, 15) = onnx::MatMul(%368, %398), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %400 : Float() = onnx::Constant[value={8}]()\n",
      "  %401 : Float(1, 12, 15, 15) = onnx::Div(%399, %400)\n",
      "  %402 : Float(1, 12, 15, 15) = onnx::Add(%401, %209), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:272:0\n",
      "  %403 : Float(1, 12, 15, 15) = onnx::Softmax[axis=3](%402), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %404 : Float(1, 12, 15, 64) = onnx::MatMul(%403, %397), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:285:0\n",
      "  %405 : Float(1, 15, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%404), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:287:0\n",
      "  %406 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %407 : Tensor = onnx::Shape(%405), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %408 : Long() = onnx::Gather[axis=0](%407, %406), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %409 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %410 : Tensor = onnx::Shape(%405), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %411 : Long() = onnx::Gather[axis=0](%410, %409), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %412 : Long() = onnx::Constant[value={768}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %413 : Tensor = onnx::Unsqueeze[axes=[0]](%408)\n",
      "  %414 : Tensor = onnx::Unsqueeze[axes=[0]](%411)\n",
      "  %415 : Tensor = onnx::Unsqueeze[axes=[0]](%412)\n",
      "  %416 : Tensor = onnx::Concat[axis=0](%413, %414, %415)\n",
      "  %417 : Float(1, 15, 768) = onnx::Reshape(%405, %416), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:289:0\n",
      "  %418 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.1.attention.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %419 : Float(1, 15, 768) = onnx::MatMul(%417, %418), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %420 : Float(1, 15, 768) = onnx::Add(%419, %encoder.layer.1.attention.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %421 : Float(1, 15, 768) = onnx::Add(%420, %344), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:305:0\n",
      "  %422 : Tensor = onnx::ReduceMean[axes=[-1]](%421), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %423 : FloatTensor = onnx::Sub(%421, %422), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %424 : Float() = onnx::Constant[value={2}]()\n",
      "  %425 : FloatTensor = onnx::Pow(%423, %424), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %426 : Tensor = onnx::ReduceMean[axes=[-1]](%425), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %427 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %428 : FloatTensor = onnx::Add(%426, %427), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %429 : Tensor = onnx::Sqrt(%428), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %430 : FloatTensor = onnx::Div(%423, %429), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %431 : FloatTensor = onnx::Mul(%430, %encoder.layer.1.attention.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %432 : Float(1, 15, 768) = onnx::Add(%431, %encoder.layer.1.attention.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %433 : Float(768, 3072) = onnx::Transpose[perm=[1, 0]](%encoder.layer.1.intermediate.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %434 : Float(1, 15, 3072) = onnx::MatMul(%432, %433), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %435 : Float(1, 15, 3072) = onnx::Add(%434, %encoder.layer.1.intermediate.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %436 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %437 : Float(1, 15, 3072) = onnx::Mul(%435, %436)\n",
      "  %438 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %439 : Float(1, 15, 3072) = onnx::Div(%435, %438)\n",
      "  %440 : Float(1, 15, 3072) = onnx::Erf(%439), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %441 : Float() = onnx::Constant[value={1}]()\n",
      "  %442 : Float(1, 15, 3072) = onnx::Add(%440, %441)\n",
      "  %443 : Float(1, 15, 3072) = onnx::Mul(%437, %442), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %444 : Float(3072, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.1.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %445 : Float(1, 15, 768) = onnx::MatMul(%443, %444), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %446 : Float(1, 15, 768) = onnx::Add(%445, %encoder.layer.1.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %447 : Float(1, 15, 768) = onnx::Add(%446, %432), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:381:0\n",
      "  %448 : Tensor = onnx::ReduceMean[axes=[-1]](%447), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %449 : FloatTensor = onnx::Sub(%447, %448), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %450 : Float() = onnx::Constant[value={2}]()\n",
      "  %451 : FloatTensor = onnx::Pow(%449, %450), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %452 : Tensor = onnx::ReduceMean[axes=[-1]](%451), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %453 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %454 : FloatTensor = onnx::Add(%452, %453), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %455 : Tensor = onnx::Sqrt(%454), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %456 : FloatTensor = onnx::Div(%449, %455), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %457 : FloatTensor = onnx::Mul(%456, %encoder.layer.1.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %458 : Float(1, 15, 768) = onnx::Add(%457, %encoder.layer.1.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %459 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.2.attention.self.query.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %460 : Float(1, 15, 768) = onnx::MatMul(%458, %459), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %461 : Float(1, 15, 768) = onnx::Add(%460, %encoder.layer.2.attention.self.query.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %462 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.2.attention.self.key.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %463 : Float(1, 15, 768) = onnx::MatMul(%458, %462), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %464 : Float(1, 15, 768) = onnx::Add(%463, %encoder.layer.2.attention.self.key.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %465 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.2.attention.self.value.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %466 : Float(1, 15, 768) = onnx::MatMul(%458, %465), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %467 : Float(1, 15, 768) = onnx::Add(%466, %encoder.layer.2.attention.self.value.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %468 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %469 : Tensor = onnx::Shape(%461), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %470 : Long() = onnx::Gather[axis=0](%469, %468), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %471 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %472 : Tensor = onnx::Shape(%461), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %473 : Long() = onnx::Gather[axis=0](%472, %471), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %474 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %475 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %476 : Tensor = onnx::Unsqueeze[axes=[0]](%470)\n",
      "  %477 : Tensor = onnx::Unsqueeze[axes=[0]](%473)\n",
      "  %478 : Tensor = onnx::Unsqueeze[axes=[0]](%474)\n",
      "  %479 : Tensor = onnx::Unsqueeze[axes=[0]](%475)\n",
      "  %480 : Tensor = onnx::Concat[axis=0](%476, %477, %478, %479)\n",
      "  %481 : Float(1, 15, 12, 64) = onnx::Reshape(%461, %480), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %482 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%481), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %483 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %484 : Tensor = onnx::Shape(%464), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %485 : Long() = onnx::Gather[axis=0](%484, %483), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %486 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %487 : Tensor = onnx::Shape(%464), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %488 : Long() = onnx::Gather[axis=0](%487, %486), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %489 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %490 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %491 : Tensor = onnx::Unsqueeze[axes=[0]](%485)\n",
      "  %492 : Tensor = onnx::Unsqueeze[axes=[0]](%488)\n",
      "  %493 : Tensor = onnx::Unsqueeze[axes=[0]](%489)\n",
      "  %494 : Tensor = onnx::Unsqueeze[axes=[0]](%490)\n",
      "  %495 : Tensor = onnx::Concat[axis=0](%491, %492, %493, %494)\n",
      "  %496 : Float(1, 15, 12, 64) = onnx::Reshape(%464, %495), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %497 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %498 : Tensor = onnx::Shape(%467), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %499 : Long() = onnx::Gather[axis=0](%498, %497), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %500 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %501 : Tensor = onnx::Shape(%467), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %502 : Long() = onnx::Gather[axis=0](%501, %500), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %503 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %504 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %505 : Tensor = onnx::Unsqueeze[axes=[0]](%499)\n",
      "  %506 : Tensor = onnx::Unsqueeze[axes=[0]](%502)\n",
      "  %507 : Tensor = onnx::Unsqueeze[axes=[0]](%503)\n",
      "  %508 : Tensor = onnx::Unsqueeze[axes=[0]](%504)\n",
      "  %509 : Tensor = onnx::Concat[axis=0](%505, %506, %507, %508)\n",
      "  %510 : Float(1, 15, 12, 64) = onnx::Reshape(%467, %509), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %511 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%510), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %512 : Float(1, 12, 64, 15) = onnx::Transpose[perm=[0, 2, 3, 1]](%496), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %513 : Float(1, 12, 15, 15) = onnx::MatMul(%482, %512), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %514 : Float() = onnx::Constant[value={8}]()\n",
      "  %515 : Float(1, 12, 15, 15) = onnx::Div(%513, %514)\n",
      "  %516 : Float(1, 12, 15, 15) = onnx::Add(%515, %209), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:272:0\n",
      "  %517 : Float(1, 12, 15, 15) = onnx::Softmax[axis=3](%516), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %518 : Float(1, 12, 15, 64) = onnx::MatMul(%517, %511), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:285:0\n",
      "  %519 : Float(1, 15, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%518), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:287:0\n",
      "  %520 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %521 : Tensor = onnx::Shape(%519), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %522 : Long() = onnx::Gather[axis=0](%521, %520), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %523 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %524 : Tensor = onnx::Shape(%519), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %525 : Long() = onnx::Gather[axis=0](%524, %523), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %526 : Long() = onnx::Constant[value={768}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %527 : Tensor = onnx::Unsqueeze[axes=[0]](%522)\n",
      "  %528 : Tensor = onnx::Unsqueeze[axes=[0]](%525)\n",
      "  %529 : Tensor = onnx::Unsqueeze[axes=[0]](%526)\n",
      "  %530 : Tensor = onnx::Concat[axis=0](%527, %528, %529)\n",
      "  %531 : Float(1, 15, 768) = onnx::Reshape(%519, %530), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:289:0\n",
      "  %532 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.2.attention.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %533 : Float(1, 15, 768) = onnx::MatMul(%531, %532), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %534 : Float(1, 15, 768) = onnx::Add(%533, %encoder.layer.2.attention.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %535 : Float(1, 15, 768) = onnx::Add(%534, %458), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:305:0\n",
      "  %536 : Tensor = onnx::ReduceMean[axes=[-1]](%535), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %537 : FloatTensor = onnx::Sub(%535, %536), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %538 : Float() = onnx::Constant[value={2}]()\n",
      "  %539 : FloatTensor = onnx::Pow(%537, %538), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %540 : Tensor = onnx::ReduceMean[axes=[-1]](%539), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %541 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %542 : FloatTensor = onnx::Add(%540, %541), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %543 : Tensor = onnx::Sqrt(%542), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %544 : FloatTensor = onnx::Div(%537, %543), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %545 : FloatTensor = onnx::Mul(%544, %encoder.layer.2.attention.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %546 : Float(1, 15, 768) = onnx::Add(%545, %encoder.layer.2.attention.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %547 : Float(768, 3072) = onnx::Transpose[perm=[1, 0]](%encoder.layer.2.intermediate.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %548 : Float(1, 15, 3072) = onnx::MatMul(%546, %547), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %549 : Float(1, 15, 3072) = onnx::Add(%548, %encoder.layer.2.intermediate.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %550 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %551 : Float(1, 15, 3072) = onnx::Mul(%549, %550)\n",
      "  %552 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %553 : Float(1, 15, 3072) = onnx::Div(%549, %552)\n",
      "  %554 : Float(1, 15, 3072) = onnx::Erf(%553), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %555 : Float() = onnx::Constant[value={1}]()\n",
      "  %556 : Float(1, 15, 3072) = onnx::Add(%554, %555)\n",
      "  %557 : Float(1, 15, 3072) = onnx::Mul(%551, %556), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %558 : Float(3072, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.2.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %559 : Float(1, 15, 768) = onnx::MatMul(%557, %558), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %560 : Float(1, 15, 768) = onnx::Add(%559, %encoder.layer.2.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %561 : Float(1, 15, 768) = onnx::Add(%560, %546), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:381:0\n",
      "  %562 : Tensor = onnx::ReduceMean[axes=[-1]](%561), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %563 : FloatTensor = onnx::Sub(%561, %562), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %564 : Float() = onnx::Constant[value={2}]()\n",
      "  %565 : FloatTensor = onnx::Pow(%563, %564), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %566 : Tensor = onnx::ReduceMean[axes=[-1]](%565), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %567 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %568 : FloatTensor = onnx::Add(%566, %567), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %569 : Tensor = onnx::Sqrt(%568), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %570 : FloatTensor = onnx::Div(%563, %569), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %571 : FloatTensor = onnx::Mul(%570, %encoder.layer.2.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %572 : Float(1, 15, 768) = onnx::Add(%571, %encoder.layer.2.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %573 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.3.attention.self.query.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %574 : Float(1, 15, 768) = onnx::MatMul(%572, %573), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %575 : Float(1, 15, 768) = onnx::Add(%574, %encoder.layer.3.attention.self.query.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %576 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.3.attention.self.key.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %577 : Float(1, 15, 768) = onnx::MatMul(%572, %576), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %578 : Float(1, 15, 768) = onnx::Add(%577, %encoder.layer.3.attention.self.key.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %579 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.3.attention.self.value.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %580 : Float(1, 15, 768) = onnx::MatMul(%572, %579), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %581 : Float(1, 15, 768) = onnx::Add(%580, %encoder.layer.3.attention.self.value.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %582 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %583 : Tensor = onnx::Shape(%575), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %584 : Long() = onnx::Gather[axis=0](%583, %582), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %585 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %586 : Tensor = onnx::Shape(%575), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %587 : Long() = onnx::Gather[axis=0](%586, %585), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %588 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %589 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %590 : Tensor = onnx::Unsqueeze[axes=[0]](%584)\n",
      "  %591 : Tensor = onnx::Unsqueeze[axes=[0]](%587)\n",
      "  %592 : Tensor = onnx::Unsqueeze[axes=[0]](%588)\n",
      "  %593 : Tensor = onnx::Unsqueeze[axes=[0]](%589)\n",
      "  %594 : Tensor = onnx::Concat[axis=0](%590, %591, %592, %593)\n",
      "  %595 : Float(1, 15, 12, 64) = onnx::Reshape(%575, %594), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %596 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%595), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %597 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %598 : Tensor = onnx::Shape(%578), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %599 : Long() = onnx::Gather[axis=0](%598, %597), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %600 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %601 : Tensor = onnx::Shape(%578), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %602 : Long() = onnx::Gather[axis=0](%601, %600), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %603 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %604 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %605 : Tensor = onnx::Unsqueeze[axes=[0]](%599)\n",
      "  %606 : Tensor = onnx::Unsqueeze[axes=[0]](%602)\n",
      "  %607 : Tensor = onnx::Unsqueeze[axes=[0]](%603)\n",
      "  %608 : Tensor = onnx::Unsqueeze[axes=[0]](%604)\n",
      "  %609 : Tensor = onnx::Concat[axis=0](%605, %606, %607, %608)\n",
      "  %610 : Float(1, 15, 12, 64) = onnx::Reshape(%578, %609), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %611 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %612 : Tensor = onnx::Shape(%581), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %613 : Long() = onnx::Gather[axis=0](%612, %611), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %614 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %615 : Tensor = onnx::Shape(%581), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %616 : Long() = onnx::Gather[axis=0](%615, %614), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %617 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %618 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %619 : Tensor = onnx::Unsqueeze[axes=[0]](%613)\n",
      "  %620 : Tensor = onnx::Unsqueeze[axes=[0]](%616)\n",
      "  %621 : Tensor = onnx::Unsqueeze[axes=[0]](%617)\n",
      "  %622 : Tensor = onnx::Unsqueeze[axes=[0]](%618)\n",
      "  %623 : Tensor = onnx::Concat[axis=0](%619, %620, %621, %622)\n",
      "  %624 : Float(1, 15, 12, 64) = onnx::Reshape(%581, %623), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %625 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%624), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %626 : Float(1, 12, 64, 15) = onnx::Transpose[perm=[0, 2, 3, 1]](%610), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %627 : Float(1, 12, 15, 15) = onnx::MatMul(%596, %626), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %628 : Float() = onnx::Constant[value={8}]()\n",
      "  %629 : Float(1, 12, 15, 15) = onnx::Div(%627, %628)\n",
      "  %630 : Float(1, 12, 15, 15) = onnx::Add(%629, %209), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:272:0\n",
      "  %631 : Float(1, 12, 15, 15) = onnx::Softmax[axis=3](%630), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %632 : Float(1, 12, 15, 64) = onnx::MatMul(%631, %625), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:285:0\n",
      "  %633 : Float(1, 15, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%632), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:287:0\n",
      "  %634 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %635 : Tensor = onnx::Shape(%633), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %636 : Long() = onnx::Gather[axis=0](%635, %634), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %637 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %638 : Tensor = onnx::Shape(%633), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %639 : Long() = onnx::Gather[axis=0](%638, %637), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %640 : Long() = onnx::Constant[value={768}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %641 : Tensor = onnx::Unsqueeze[axes=[0]](%636)\n",
      "  %642 : Tensor = onnx::Unsqueeze[axes=[0]](%639)\n",
      "  %643 : Tensor = onnx::Unsqueeze[axes=[0]](%640)\n",
      "  %644 : Tensor = onnx::Concat[axis=0](%641, %642, %643)\n",
      "  %645 : Float(1, 15, 768) = onnx::Reshape(%633, %644), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:289:0\n",
      "  %646 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.3.attention.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %647 : Float(1, 15, 768) = onnx::MatMul(%645, %646), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %648 : Float(1, 15, 768) = onnx::Add(%647, %encoder.layer.3.attention.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %649 : Float(1, 15, 768) = onnx::Add(%648, %572), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:305:0\n",
      "  %650 : Tensor = onnx::ReduceMean[axes=[-1]](%649), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %651 : FloatTensor = onnx::Sub(%649, %650), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %652 : Float() = onnx::Constant[value={2}]()\n",
      "  %653 : FloatTensor = onnx::Pow(%651, %652), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %654 : Tensor = onnx::ReduceMean[axes=[-1]](%653), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %655 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %656 : FloatTensor = onnx::Add(%654, %655), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %657 : Tensor = onnx::Sqrt(%656), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %658 : FloatTensor = onnx::Div(%651, %657), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %659 : FloatTensor = onnx::Mul(%658, %encoder.layer.3.attention.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %660 : Float(1, 15, 768) = onnx::Add(%659, %encoder.layer.3.attention.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %661 : Float(768, 3072) = onnx::Transpose[perm=[1, 0]](%encoder.layer.3.intermediate.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %662 : Float(1, 15, 3072) = onnx::MatMul(%660, %661), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %663 : Float(1, 15, 3072) = onnx::Add(%662, %encoder.layer.3.intermediate.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %664 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %665 : Float(1, 15, 3072) = onnx::Mul(%663, %664)\n",
      "  %666 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %667 : Float(1, 15, 3072) = onnx::Div(%663, %666)\n",
      "  %668 : Float(1, 15, 3072) = onnx::Erf(%667), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %669 : Float() = onnx::Constant[value={1}]()\n",
      "  %670 : Float(1, 15, 3072) = onnx::Add(%668, %669)\n",
      "  %671 : Float(1, 15, 3072) = onnx::Mul(%665, %670), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %672 : Float(3072, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.3.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %673 : Float(1, 15, 768) = onnx::MatMul(%671, %672), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %674 : Float(1, 15, 768) = onnx::Add(%673, %encoder.layer.3.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %675 : Float(1, 15, 768) = onnx::Add(%674, %660), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:381:0\n",
      "  %676 : Tensor = onnx::ReduceMean[axes=[-1]](%675), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %677 : FloatTensor = onnx::Sub(%675, %676), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %678 : Float() = onnx::Constant[value={2}]()\n",
      "  %679 : FloatTensor = onnx::Pow(%677, %678), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %680 : Tensor = onnx::ReduceMean[axes=[-1]](%679), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %681 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %682 : FloatTensor = onnx::Add(%680, %681), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %683 : Tensor = onnx::Sqrt(%682), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %684 : FloatTensor = onnx::Div(%677, %683), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %685 : FloatTensor = onnx::Mul(%684, %encoder.layer.3.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %686 : Float(1, 15, 768) = onnx::Add(%685, %encoder.layer.3.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %687 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.4.attention.self.query.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %688 : Float(1, 15, 768) = onnx::MatMul(%686, %687), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %689 : Float(1, 15, 768) = onnx::Add(%688, %encoder.layer.4.attention.self.query.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %690 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.4.attention.self.key.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %691 : Float(1, 15, 768) = onnx::MatMul(%686, %690), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %692 : Float(1, 15, 768) = onnx::Add(%691, %encoder.layer.4.attention.self.key.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %693 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.4.attention.self.value.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %694 : Float(1, 15, 768) = onnx::MatMul(%686, %693), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %695 : Float(1, 15, 768) = onnx::Add(%694, %encoder.layer.4.attention.self.value.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %696 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %697 : Tensor = onnx::Shape(%689), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %698 : Long() = onnx::Gather[axis=0](%697, %696), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %699 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %700 : Tensor = onnx::Shape(%689), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %701 : Long() = onnx::Gather[axis=0](%700, %699), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %702 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %703 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %704 : Tensor = onnx::Unsqueeze[axes=[0]](%698)\n",
      "  %705 : Tensor = onnx::Unsqueeze[axes=[0]](%701)\n",
      "  %706 : Tensor = onnx::Unsqueeze[axes=[0]](%702)\n",
      "  %707 : Tensor = onnx::Unsqueeze[axes=[0]](%703)\n",
      "  %708 : Tensor = onnx::Concat[axis=0](%704, %705, %706, %707)\n",
      "  %709 : Float(1, 15, 12, 64) = onnx::Reshape(%689, %708), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %710 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%709), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %711 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %712 : Tensor = onnx::Shape(%692), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %713 : Long() = onnx::Gather[axis=0](%712, %711), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %714 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %715 : Tensor = onnx::Shape(%692), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %716 : Long() = onnx::Gather[axis=0](%715, %714), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %717 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %718 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %719 : Tensor = onnx::Unsqueeze[axes=[0]](%713)\n",
      "  %720 : Tensor = onnx::Unsqueeze[axes=[0]](%716)\n",
      "  %721 : Tensor = onnx::Unsqueeze[axes=[0]](%717)\n",
      "  %722 : Tensor = onnx::Unsqueeze[axes=[0]](%718)\n",
      "  %723 : Tensor = onnx::Concat[axis=0](%719, %720, %721, %722)\n",
      "  %724 : Float(1, 15, 12, 64) = onnx::Reshape(%692, %723), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %725 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %726 : Tensor = onnx::Shape(%695), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %727 : Long() = onnx::Gather[axis=0](%726, %725), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %728 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %729 : Tensor = onnx::Shape(%695), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %730 : Long() = onnx::Gather[axis=0](%729, %728), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %731 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %732 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %733 : Tensor = onnx::Unsqueeze[axes=[0]](%727)\n",
      "  %734 : Tensor = onnx::Unsqueeze[axes=[0]](%730)\n",
      "  %735 : Tensor = onnx::Unsqueeze[axes=[0]](%731)\n",
      "  %736 : Tensor = onnx::Unsqueeze[axes=[0]](%732)\n",
      "  %737 : Tensor = onnx::Concat[axis=0](%733, %734, %735, %736)\n",
      "  %738 : Float(1, 15, 12, 64) = onnx::Reshape(%695, %737), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %739 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%738), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %740 : Float(1, 12, 64, 15) = onnx::Transpose[perm=[0, 2, 3, 1]](%724), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %741 : Float(1, 12, 15, 15) = onnx::MatMul(%710, %740), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %742 : Float() = onnx::Constant[value={8}]()\n",
      "  %743 : Float(1, 12, 15, 15) = onnx::Div(%741, %742)\n",
      "  %744 : Float(1, 12, 15, 15) = onnx::Add(%743, %209), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:272:0\n",
      "  %745 : Float(1, 12, 15, 15) = onnx::Softmax[axis=3](%744), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %746 : Float(1, 12, 15, 64) = onnx::MatMul(%745, %739), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:285:0\n",
      "  %747 : Float(1, 15, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%746), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:287:0\n",
      "  %748 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %749 : Tensor = onnx::Shape(%747), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %750 : Long() = onnx::Gather[axis=0](%749, %748), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %751 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %752 : Tensor = onnx::Shape(%747), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %753 : Long() = onnx::Gather[axis=0](%752, %751), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %754 : Long() = onnx::Constant[value={768}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %755 : Tensor = onnx::Unsqueeze[axes=[0]](%750)\n",
      "  %756 : Tensor = onnx::Unsqueeze[axes=[0]](%753)\n",
      "  %757 : Tensor = onnx::Unsqueeze[axes=[0]](%754)\n",
      "  %758 : Tensor = onnx::Concat[axis=0](%755, %756, %757)\n",
      "  %759 : Float(1, 15, 768) = onnx::Reshape(%747, %758), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:289:0\n",
      "  %760 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.4.attention.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %761 : Float(1, 15, 768) = onnx::MatMul(%759, %760), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %762 : Float(1, 15, 768) = onnx::Add(%761, %encoder.layer.4.attention.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %763 : Float(1, 15, 768) = onnx::Add(%762, %686), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:305:0\n",
      "  %764 : Tensor = onnx::ReduceMean[axes=[-1]](%763), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %765 : FloatTensor = onnx::Sub(%763, %764), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %766 : Float() = onnx::Constant[value={2}]()\n",
      "  %767 : FloatTensor = onnx::Pow(%765, %766), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %768 : Tensor = onnx::ReduceMean[axes=[-1]](%767), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %769 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %770 : FloatTensor = onnx::Add(%768, %769), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %771 : Tensor = onnx::Sqrt(%770), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %772 : FloatTensor = onnx::Div(%765, %771), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %773 : FloatTensor = onnx::Mul(%772, %encoder.layer.4.attention.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %774 : Float(1, 15, 768) = onnx::Add(%773, %encoder.layer.4.attention.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %775 : Float(768, 3072) = onnx::Transpose[perm=[1, 0]](%encoder.layer.4.intermediate.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %776 : Float(1, 15, 3072) = onnx::MatMul(%774, %775), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %777 : Float(1, 15, 3072) = onnx::Add(%776, %encoder.layer.4.intermediate.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %778 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %779 : Float(1, 15, 3072) = onnx::Mul(%777, %778)\n",
      "  %780 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %781 : Float(1, 15, 3072) = onnx::Div(%777, %780)\n",
      "  %782 : Float(1, 15, 3072) = onnx::Erf(%781), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %783 : Float() = onnx::Constant[value={1}]()\n",
      "  %784 : Float(1, 15, 3072) = onnx::Add(%782, %783)\n",
      "  %785 : Float(1, 15, 3072) = onnx::Mul(%779, %784), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %786 : Float(3072, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.4.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %787 : Float(1, 15, 768) = onnx::MatMul(%785, %786), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %788 : Float(1, 15, 768) = onnx::Add(%787, %encoder.layer.4.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %789 : Float(1, 15, 768) = onnx::Add(%788, %774), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:381:0\n",
      "  %790 : Tensor = onnx::ReduceMean[axes=[-1]](%789), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %791 : FloatTensor = onnx::Sub(%789, %790), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %792 : Float() = onnx::Constant[value={2}]()\n",
      "  %793 : FloatTensor = onnx::Pow(%791, %792), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %794 : Tensor = onnx::ReduceMean[axes=[-1]](%793), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %795 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %796 : FloatTensor = onnx::Add(%794, %795), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %797 : Tensor = onnx::Sqrt(%796), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %798 : FloatTensor = onnx::Div(%791, %797), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %799 : FloatTensor = onnx::Mul(%798, %encoder.layer.4.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %800 : Float(1, 15, 768) = onnx::Add(%799, %encoder.layer.4.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %801 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.5.attention.self.query.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %802 : Float(1, 15, 768) = onnx::MatMul(%800, %801), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %803 : Float(1, 15, 768) = onnx::Add(%802, %encoder.layer.5.attention.self.query.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %804 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.5.attention.self.key.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %805 : Float(1, 15, 768) = onnx::MatMul(%800, %804), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %806 : Float(1, 15, 768) = onnx::Add(%805, %encoder.layer.5.attention.self.key.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %807 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.5.attention.self.value.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %808 : Float(1, 15, 768) = onnx::MatMul(%800, %807), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %809 : Float(1, 15, 768) = onnx::Add(%808, %encoder.layer.5.attention.self.value.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %810 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %811 : Tensor = onnx::Shape(%803), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %812 : Long() = onnx::Gather[axis=0](%811, %810), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %813 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %814 : Tensor = onnx::Shape(%803), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %815 : Long() = onnx::Gather[axis=0](%814, %813), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %816 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %817 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %818 : Tensor = onnx::Unsqueeze[axes=[0]](%812)\n",
      "  %819 : Tensor = onnx::Unsqueeze[axes=[0]](%815)\n",
      "  %820 : Tensor = onnx::Unsqueeze[axes=[0]](%816)\n",
      "  %821 : Tensor = onnx::Unsqueeze[axes=[0]](%817)\n",
      "  %822 : Tensor = onnx::Concat[axis=0](%818, %819, %820, %821)\n",
      "  %823 : Float(1, 15, 12, 64) = onnx::Reshape(%803, %822), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %824 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%823), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %825 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %826 : Tensor = onnx::Shape(%806), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %827 : Long() = onnx::Gather[axis=0](%826, %825), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %828 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %829 : Tensor = onnx::Shape(%806), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %830 : Long() = onnx::Gather[axis=0](%829, %828), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %831 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %832 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %833 : Tensor = onnx::Unsqueeze[axes=[0]](%827)\n",
      "  %834 : Tensor = onnx::Unsqueeze[axes=[0]](%830)\n",
      "  %835 : Tensor = onnx::Unsqueeze[axes=[0]](%831)\n",
      "  %836 : Tensor = onnx::Unsqueeze[axes=[0]](%832)\n",
      "  %837 : Tensor = onnx::Concat[axis=0](%833, %834, %835, %836)\n",
      "  %838 : Float(1, 15, 12, 64) = onnx::Reshape(%806, %837), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %839 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %840 : Tensor = onnx::Shape(%809), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %841 : Long() = onnx::Gather[axis=0](%840, %839), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %842 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %843 : Tensor = onnx::Shape(%809), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %844 : Long() = onnx::Gather[axis=0](%843, %842), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %845 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %846 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %847 : Tensor = onnx::Unsqueeze[axes=[0]](%841)\n",
      "  %848 : Tensor = onnx::Unsqueeze[axes=[0]](%844)\n",
      "  %849 : Tensor = onnx::Unsqueeze[axes=[0]](%845)\n",
      "  %850 : Tensor = onnx::Unsqueeze[axes=[0]](%846)\n",
      "  %851 : Tensor = onnx::Concat[axis=0](%847, %848, %849, %850)\n",
      "  %852 : Float(1, 15, 12, 64) = onnx::Reshape(%809, %851), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %853 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%852), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %854 : Float(1, 12, 64, 15) = onnx::Transpose[perm=[0, 2, 3, 1]](%838), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %855 : Float(1, 12, 15, 15) = onnx::MatMul(%824, %854), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %856 : Float() = onnx::Constant[value={8}]()\n",
      "  %857 : Float(1, 12, 15, 15) = onnx::Div(%855, %856)\n",
      "  %858 : Float(1, 12, 15, 15) = onnx::Add(%857, %209), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:272:0\n",
      "  %859 : Float(1, 12, 15, 15) = onnx::Softmax[axis=3](%858), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %860 : Float(1, 12, 15, 64) = onnx::MatMul(%859, %853), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:285:0\n",
      "  %861 : Float(1, 15, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%860), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:287:0\n",
      "  %862 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %863 : Tensor = onnx::Shape(%861), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %864 : Long() = onnx::Gather[axis=0](%863, %862), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %865 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %866 : Tensor = onnx::Shape(%861), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %867 : Long() = onnx::Gather[axis=0](%866, %865), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %868 : Long() = onnx::Constant[value={768}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %869 : Tensor = onnx::Unsqueeze[axes=[0]](%864)\n",
      "  %870 : Tensor = onnx::Unsqueeze[axes=[0]](%867)\n",
      "  %871 : Tensor = onnx::Unsqueeze[axes=[0]](%868)\n",
      "  %872 : Tensor = onnx::Concat[axis=0](%869, %870, %871)\n",
      "  %873 : Float(1, 15, 768) = onnx::Reshape(%861, %872), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:289:0\n",
      "  %874 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.5.attention.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %875 : Float(1, 15, 768) = onnx::MatMul(%873, %874), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %876 : Float(1, 15, 768) = onnx::Add(%875, %encoder.layer.5.attention.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %877 : Float(1, 15, 768) = onnx::Add(%876, %800), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:305:0\n",
      "  %878 : Tensor = onnx::ReduceMean[axes=[-1]](%877), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %879 : FloatTensor = onnx::Sub(%877, %878), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %880 : Float() = onnx::Constant[value={2}]()\n",
      "  %881 : FloatTensor = onnx::Pow(%879, %880), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %882 : Tensor = onnx::ReduceMean[axes=[-1]](%881), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %883 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %884 : FloatTensor = onnx::Add(%882, %883), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %885 : Tensor = onnx::Sqrt(%884), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %886 : FloatTensor = onnx::Div(%879, %885), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %887 : FloatTensor = onnx::Mul(%886, %encoder.layer.5.attention.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %888 : Float(1, 15, 768) = onnx::Add(%887, %encoder.layer.5.attention.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %889 : Float(768, 3072) = onnx::Transpose[perm=[1, 0]](%encoder.layer.5.intermediate.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %890 : Float(1, 15, 3072) = onnx::MatMul(%888, %889), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %891 : Float(1, 15, 3072) = onnx::Add(%890, %encoder.layer.5.intermediate.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %892 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %893 : Float(1, 15, 3072) = onnx::Mul(%891, %892)\n",
      "  %894 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %895 : Float(1, 15, 3072) = onnx::Div(%891, %894)\n",
      "  %896 : Float(1, 15, 3072) = onnx::Erf(%895), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %897 : Float() = onnx::Constant[value={1}]()\n",
      "  %898 : Float(1, 15, 3072) = onnx::Add(%896, %897)\n",
      "  %899 : Float(1, 15, 3072) = onnx::Mul(%893, %898), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %900 : Float(3072, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.5.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %901 : Float(1, 15, 768) = onnx::MatMul(%899, %900), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %902 : Float(1, 15, 768) = onnx::Add(%901, %encoder.layer.5.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %903 : Float(1, 15, 768) = onnx::Add(%902, %888), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:381:0\n",
      "  %904 : Tensor = onnx::ReduceMean[axes=[-1]](%903), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %905 : FloatTensor = onnx::Sub(%903, %904), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %906 : Float() = onnx::Constant[value={2}]()\n",
      "  %907 : FloatTensor = onnx::Pow(%905, %906), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %908 : Tensor = onnx::ReduceMean[axes=[-1]](%907), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %909 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %910 : FloatTensor = onnx::Add(%908, %909), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %911 : Tensor = onnx::Sqrt(%910), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %912 : FloatTensor = onnx::Div(%905, %911), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %913 : FloatTensor = onnx::Mul(%912, %encoder.layer.5.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %914 : Float(1, 15, 768) = onnx::Add(%913, %encoder.layer.5.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %915 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.6.attention.self.query.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %916 : Float(1, 15, 768) = onnx::MatMul(%914, %915), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %917 : Float(1, 15, 768) = onnx::Add(%916, %encoder.layer.6.attention.self.query.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %918 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.6.attention.self.key.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %919 : Float(1, 15, 768) = onnx::MatMul(%914, %918), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %920 : Float(1, 15, 768) = onnx::Add(%919, %encoder.layer.6.attention.self.key.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %921 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.6.attention.self.value.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %922 : Float(1, 15, 768) = onnx::MatMul(%914, %921), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %923 : Float(1, 15, 768) = onnx::Add(%922, %encoder.layer.6.attention.self.value.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %924 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %925 : Tensor = onnx::Shape(%917), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %926 : Long() = onnx::Gather[axis=0](%925, %924), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %927 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %928 : Tensor = onnx::Shape(%917), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %929 : Long() = onnx::Gather[axis=0](%928, %927), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %930 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %931 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %932 : Tensor = onnx::Unsqueeze[axes=[0]](%926)\n",
      "  %933 : Tensor = onnx::Unsqueeze[axes=[0]](%929)\n",
      "  %934 : Tensor = onnx::Unsqueeze[axes=[0]](%930)\n",
      "  %935 : Tensor = onnx::Unsqueeze[axes=[0]](%931)\n",
      "  %936 : Tensor = onnx::Concat[axis=0](%932, %933, %934, %935)\n",
      "  %937 : Float(1, 15, 12, 64) = onnx::Reshape(%917, %936), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %938 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%937), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %939 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %940 : Tensor = onnx::Shape(%920), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %941 : Long() = onnx::Gather[axis=0](%940, %939), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %942 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %943 : Tensor = onnx::Shape(%920), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %944 : Long() = onnx::Gather[axis=0](%943, %942), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %945 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %946 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %947 : Tensor = onnx::Unsqueeze[axes=[0]](%941)\n",
      "  %948 : Tensor = onnx::Unsqueeze[axes=[0]](%944)\n",
      "  %949 : Tensor = onnx::Unsqueeze[axes=[0]](%945)\n",
      "  %950 : Tensor = onnx::Unsqueeze[axes=[0]](%946)\n",
      "  %951 : Tensor = onnx::Concat[axis=0](%947, %948, %949, %950)\n",
      "  %952 : Float(1, 15, 12, 64) = onnx::Reshape(%920, %951), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %953 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %954 : Tensor = onnx::Shape(%923), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %955 : Long() = onnx::Gather[axis=0](%954, %953), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %956 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %957 : Tensor = onnx::Shape(%923), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %958 : Long() = onnx::Gather[axis=0](%957, %956), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %959 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %960 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %961 : Tensor = onnx::Unsqueeze[axes=[0]](%955)\n",
      "  %962 : Tensor = onnx::Unsqueeze[axes=[0]](%958)\n",
      "  %963 : Tensor = onnx::Unsqueeze[axes=[0]](%959)\n",
      "  %964 : Tensor = onnx::Unsqueeze[axes=[0]](%960)\n",
      "  %965 : Tensor = onnx::Concat[axis=0](%961, %962, %963, %964)\n",
      "  %966 : Float(1, 15, 12, 64) = onnx::Reshape(%923, %965), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %967 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%966), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %968 : Float(1, 12, 64, 15) = onnx::Transpose[perm=[0, 2, 3, 1]](%952), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %969 : Float(1, 12, 15, 15) = onnx::MatMul(%938, %968), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %970 : Float() = onnx::Constant[value={8}]()\n",
      "  %971 : Float(1, 12, 15, 15) = onnx::Div(%969, %970)\n",
      "  %972 : Float(1, 12, 15, 15) = onnx::Add(%971, %209), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:272:0\n",
      "  %973 : Float(1, 12, 15, 15) = onnx::Softmax[axis=3](%972), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %974 : Float(1, 12, 15, 64) = onnx::MatMul(%973, %967), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:285:0\n",
      "  %975 : Float(1, 15, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%974), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:287:0\n",
      "  %976 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %977 : Tensor = onnx::Shape(%975), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %978 : Long() = onnx::Gather[axis=0](%977, %976), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %979 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %980 : Tensor = onnx::Shape(%975), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %981 : Long() = onnx::Gather[axis=0](%980, %979), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %982 : Long() = onnx::Constant[value={768}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %983 : Tensor = onnx::Unsqueeze[axes=[0]](%978)\n",
      "  %984 : Tensor = onnx::Unsqueeze[axes=[0]](%981)\n",
      "  %985 : Tensor = onnx::Unsqueeze[axes=[0]](%982)\n",
      "  %986 : Tensor = onnx::Concat[axis=0](%983, %984, %985)\n",
      "  %987 : Float(1, 15, 768) = onnx::Reshape(%975, %986), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:289:0\n",
      "  %988 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.6.attention.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %989 : Float(1, 15, 768) = onnx::MatMul(%987, %988), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %990 : Float(1, 15, 768) = onnx::Add(%989, %encoder.layer.6.attention.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %991 : Float(1, 15, 768) = onnx::Add(%990, %914), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:305:0\n",
      "  %992 : Tensor = onnx::ReduceMean[axes=[-1]](%991), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %993 : FloatTensor = onnx::Sub(%991, %992), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %994 : Float() = onnx::Constant[value={2}]()\n",
      "  %995 : FloatTensor = onnx::Pow(%993, %994), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %996 : Tensor = onnx::ReduceMean[axes=[-1]](%995), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %997 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %998 : FloatTensor = onnx::Add(%996, %997), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %999 : Tensor = onnx::Sqrt(%998), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1000 : FloatTensor = onnx::Div(%993, %999), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1001 : FloatTensor = onnx::Mul(%1000, %encoder.layer.6.attention.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1002 : Float(1, 15, 768) = onnx::Add(%1001, %encoder.layer.6.attention.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %1003 : Float(768, 3072) = onnx::Transpose[perm=[1, 0]](%encoder.layer.6.intermediate.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1004 : Float(1, 15, 3072) = onnx::MatMul(%1002, %1003), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1005 : Float(1, 15, 3072) = onnx::Add(%1004, %encoder.layer.6.intermediate.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1006 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %1007 : Float(1, 15, 3072) = onnx::Mul(%1005, %1006)\n",
      "  %1008 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %1009 : Float(1, 15, 3072) = onnx::Div(%1005, %1008)\n",
      "  %1010 : Float(1, 15, 3072) = onnx::Erf(%1009), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %1011 : Float() = onnx::Constant[value={1}]()\n",
      "  %1012 : Float(1, 15, 3072) = onnx::Add(%1010, %1011)\n",
      "  %1013 : Float(1, 15, 3072) = onnx::Mul(%1007, %1012), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %1014 : Float(3072, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.6.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1015 : Float(1, 15, 768) = onnx::MatMul(%1013, %1014), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1016 : Float(1, 15, 768) = onnx::Add(%1015, %encoder.layer.6.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1017 : Float(1, 15, 768) = onnx::Add(%1016, %1002), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:381:0\n",
      "  %1018 : Tensor = onnx::ReduceMean[axes=[-1]](%1017), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1019 : FloatTensor = onnx::Sub(%1017, %1018), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1020 : Float() = onnx::Constant[value={2}]()\n",
      "  %1021 : FloatTensor = onnx::Pow(%1019, %1020), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1022 : Tensor = onnx::ReduceMean[axes=[-1]](%1021), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1023 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %1024 : FloatTensor = onnx::Add(%1022, %1023), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1025 : Tensor = onnx::Sqrt(%1024), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1026 : FloatTensor = onnx::Div(%1019, %1025), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1027 : FloatTensor = onnx::Mul(%1026, %encoder.layer.6.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1028 : Float(1, 15, 768) = onnx::Add(%1027, %encoder.layer.6.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %1029 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.7.attention.self.query.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1030 : Float(1, 15, 768) = onnx::MatMul(%1028, %1029), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1031 : Float(1, 15, 768) = onnx::Add(%1030, %encoder.layer.7.attention.self.query.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1032 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.7.attention.self.key.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1033 : Float(1, 15, 768) = onnx::MatMul(%1028, %1032), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1034 : Float(1, 15, 768) = onnx::Add(%1033, %encoder.layer.7.attention.self.key.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1035 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.7.attention.self.value.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1036 : Float(1, 15, 768) = onnx::MatMul(%1028, %1035), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1037 : Float(1, 15, 768) = onnx::Add(%1036, %encoder.layer.7.attention.self.value.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1038 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1039 : Tensor = onnx::Shape(%1031), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1040 : Long() = onnx::Gather[axis=0](%1039, %1038), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1041 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1042 : Tensor = onnx::Shape(%1031), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1043 : Long() = onnx::Gather[axis=0](%1042, %1041), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1044 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1045 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1046 : Tensor = onnx::Unsqueeze[axes=[0]](%1040)\n",
      "  %1047 : Tensor = onnx::Unsqueeze[axes=[0]](%1043)\n",
      "  %1048 : Tensor = onnx::Unsqueeze[axes=[0]](%1044)\n",
      "  %1049 : Tensor = onnx::Unsqueeze[axes=[0]](%1045)\n",
      "  %1050 : Tensor = onnx::Concat[axis=0](%1046, %1047, %1048, %1049)\n",
      "  %1051 : Float(1, 15, 12, 64) = onnx::Reshape(%1031, %1050), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1052 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1051), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %1053 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1054 : Tensor = onnx::Shape(%1034), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1055 : Long() = onnx::Gather[axis=0](%1054, %1053), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1056 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1057 : Tensor = onnx::Shape(%1034), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1058 : Long() = onnx::Gather[axis=0](%1057, %1056), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1059 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1060 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1061 : Tensor = onnx::Unsqueeze[axes=[0]](%1055)\n",
      "  %1062 : Tensor = onnx::Unsqueeze[axes=[0]](%1058)\n",
      "  %1063 : Tensor = onnx::Unsqueeze[axes=[0]](%1059)\n",
      "  %1064 : Tensor = onnx::Unsqueeze[axes=[0]](%1060)\n",
      "  %1065 : Tensor = onnx::Concat[axis=0](%1061, %1062, %1063, %1064)\n",
      "  %1066 : Float(1, 15, 12, 64) = onnx::Reshape(%1034, %1065), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1067 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1068 : Tensor = onnx::Shape(%1037), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1069 : Long() = onnx::Gather[axis=0](%1068, %1067), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1070 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1071 : Tensor = onnx::Shape(%1037), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1072 : Long() = onnx::Gather[axis=0](%1071, %1070), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1073 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1074 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1075 : Tensor = onnx::Unsqueeze[axes=[0]](%1069)\n",
      "  %1076 : Tensor = onnx::Unsqueeze[axes=[0]](%1072)\n",
      "  %1077 : Tensor = onnx::Unsqueeze[axes=[0]](%1073)\n",
      "  %1078 : Tensor = onnx::Unsqueeze[axes=[0]](%1074)\n",
      "  %1079 : Tensor = onnx::Concat[axis=0](%1075, %1076, %1077, %1078)\n",
      "  %1080 : Float(1, 15, 12, 64) = onnx::Reshape(%1037, %1079), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1081 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1080), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %1082 : Float(1, 12, 64, 15) = onnx::Transpose[perm=[0, 2, 3, 1]](%1066), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %1083 : Float(1, 12, 15, 15) = onnx::MatMul(%1052, %1082), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %1084 : Float() = onnx::Constant[value={8}]()\n",
      "  %1085 : Float(1, 12, 15, 15) = onnx::Div(%1083, %1084)\n",
      "  %1086 : Float(1, 12, 15, 15) = onnx::Add(%1085, %209), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:272:0\n",
      "  %1087 : Float(1, 12, 15, 15) = onnx::Softmax[axis=3](%1086), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1088 : Float(1, 12, 15, 64) = onnx::MatMul(%1087, %1081), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:285:0\n",
      "  %1089 : Float(1, 15, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1088), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:287:0\n",
      "  %1090 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1091 : Tensor = onnx::Shape(%1089), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1092 : Long() = onnx::Gather[axis=0](%1091, %1090), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %1093 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1094 : Tensor = onnx::Shape(%1089), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1095 : Long() = onnx::Gather[axis=0](%1094, %1093), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %1096 : Long() = onnx::Constant[value={768}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1097 : Tensor = onnx::Unsqueeze[axes=[0]](%1092)\n",
      "  %1098 : Tensor = onnx::Unsqueeze[axes=[0]](%1095)\n",
      "  %1099 : Tensor = onnx::Unsqueeze[axes=[0]](%1096)\n",
      "  %1100 : Tensor = onnx::Concat[axis=0](%1097, %1098, %1099)\n",
      "  %1101 : Float(1, 15, 768) = onnx::Reshape(%1089, %1100), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:289:0\n",
      "  %1102 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.7.attention.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1103 : Float(1, 15, 768) = onnx::MatMul(%1101, %1102), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1104 : Float(1, 15, 768) = onnx::Add(%1103, %encoder.layer.7.attention.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1105 : Float(1, 15, 768) = onnx::Add(%1104, %1028), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:305:0\n",
      "  %1106 : Tensor = onnx::ReduceMean[axes=[-1]](%1105), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1107 : FloatTensor = onnx::Sub(%1105, %1106), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1108 : Float() = onnx::Constant[value={2}]()\n",
      "  %1109 : FloatTensor = onnx::Pow(%1107, %1108), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1110 : Tensor = onnx::ReduceMean[axes=[-1]](%1109), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1111 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %1112 : FloatTensor = onnx::Add(%1110, %1111), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1113 : Tensor = onnx::Sqrt(%1112), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1114 : FloatTensor = onnx::Div(%1107, %1113), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1115 : FloatTensor = onnx::Mul(%1114, %encoder.layer.7.attention.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1116 : Float(1, 15, 768) = onnx::Add(%1115, %encoder.layer.7.attention.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %1117 : Float(768, 3072) = onnx::Transpose[perm=[1, 0]](%encoder.layer.7.intermediate.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1118 : Float(1, 15, 3072) = onnx::MatMul(%1116, %1117), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1119 : Float(1, 15, 3072) = onnx::Add(%1118, %encoder.layer.7.intermediate.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1120 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %1121 : Float(1, 15, 3072) = onnx::Mul(%1119, %1120)\n",
      "  %1122 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %1123 : Float(1, 15, 3072) = onnx::Div(%1119, %1122)\n",
      "  %1124 : Float(1, 15, 3072) = onnx::Erf(%1123), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %1125 : Float() = onnx::Constant[value={1}]()\n",
      "  %1126 : Float(1, 15, 3072) = onnx::Add(%1124, %1125)\n",
      "  %1127 : Float(1, 15, 3072) = onnx::Mul(%1121, %1126), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %1128 : Float(3072, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.7.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1129 : Float(1, 15, 768) = onnx::MatMul(%1127, %1128), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1130 : Float(1, 15, 768) = onnx::Add(%1129, %encoder.layer.7.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1131 : Float(1, 15, 768) = onnx::Add(%1130, %1116), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:381:0\n",
      "  %1132 : Tensor = onnx::ReduceMean[axes=[-1]](%1131), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1133 : FloatTensor = onnx::Sub(%1131, %1132), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1134 : Float() = onnx::Constant[value={2}]()\n",
      "  %1135 : FloatTensor = onnx::Pow(%1133, %1134), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1136 : Tensor = onnx::ReduceMean[axes=[-1]](%1135), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1137 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %1138 : FloatTensor = onnx::Add(%1136, %1137), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1139 : Tensor = onnx::Sqrt(%1138), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1140 : FloatTensor = onnx::Div(%1133, %1139), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1141 : FloatTensor = onnx::Mul(%1140, %encoder.layer.7.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1142 : Float(1, 15, 768) = onnx::Add(%1141, %encoder.layer.7.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %1143 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.8.attention.self.query.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1144 : Float(1, 15, 768) = onnx::MatMul(%1142, %1143), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1145 : Float(1, 15, 768) = onnx::Add(%1144, %encoder.layer.8.attention.self.query.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1146 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.8.attention.self.key.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1147 : Float(1, 15, 768) = onnx::MatMul(%1142, %1146), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1148 : Float(1, 15, 768) = onnx::Add(%1147, %encoder.layer.8.attention.self.key.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1149 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.8.attention.self.value.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1150 : Float(1, 15, 768) = onnx::MatMul(%1142, %1149), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1151 : Float(1, 15, 768) = onnx::Add(%1150, %encoder.layer.8.attention.self.value.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1152 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1153 : Tensor = onnx::Shape(%1145), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1154 : Long() = onnx::Gather[axis=0](%1153, %1152), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1155 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1156 : Tensor = onnx::Shape(%1145), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1157 : Long() = onnx::Gather[axis=0](%1156, %1155), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1158 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1159 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1160 : Tensor = onnx::Unsqueeze[axes=[0]](%1154)\n",
      "  %1161 : Tensor = onnx::Unsqueeze[axes=[0]](%1157)\n",
      "  %1162 : Tensor = onnx::Unsqueeze[axes=[0]](%1158)\n",
      "  %1163 : Tensor = onnx::Unsqueeze[axes=[0]](%1159)\n",
      "  %1164 : Tensor = onnx::Concat[axis=0](%1160, %1161, %1162, %1163)\n",
      "  %1165 : Float(1, 15, 12, 64) = onnx::Reshape(%1145, %1164), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1166 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1165), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %1167 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1168 : Tensor = onnx::Shape(%1148), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1169 : Long() = onnx::Gather[axis=0](%1168, %1167), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1170 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1171 : Tensor = onnx::Shape(%1148), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1172 : Long() = onnx::Gather[axis=0](%1171, %1170), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1173 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1174 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1175 : Tensor = onnx::Unsqueeze[axes=[0]](%1169)\n",
      "  %1176 : Tensor = onnx::Unsqueeze[axes=[0]](%1172)\n",
      "  %1177 : Tensor = onnx::Unsqueeze[axes=[0]](%1173)\n",
      "  %1178 : Tensor = onnx::Unsqueeze[axes=[0]](%1174)\n",
      "  %1179 : Tensor = onnx::Concat[axis=0](%1175, %1176, %1177, %1178)\n",
      "  %1180 : Float(1, 15, 12, 64) = onnx::Reshape(%1148, %1179), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1181 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1182 : Tensor = onnx::Shape(%1151), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1183 : Long() = onnx::Gather[axis=0](%1182, %1181), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1184 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1185 : Tensor = onnx::Shape(%1151), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1186 : Long() = onnx::Gather[axis=0](%1185, %1184), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1187 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1188 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1189 : Tensor = onnx::Unsqueeze[axes=[0]](%1183)\n",
      "  %1190 : Tensor = onnx::Unsqueeze[axes=[0]](%1186)\n",
      "  %1191 : Tensor = onnx::Unsqueeze[axes=[0]](%1187)\n",
      "  %1192 : Tensor = onnx::Unsqueeze[axes=[0]](%1188)\n",
      "  %1193 : Tensor = onnx::Concat[axis=0](%1189, %1190, %1191, %1192)\n",
      "  %1194 : Float(1, 15, 12, 64) = onnx::Reshape(%1151, %1193), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1195 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1194), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %1196 : Float(1, 12, 64, 15) = onnx::Transpose[perm=[0, 2, 3, 1]](%1180), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %1197 : Float(1, 12, 15, 15) = onnx::MatMul(%1166, %1196), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %1198 : Float() = onnx::Constant[value={8}]()\n",
      "  %1199 : Float(1, 12, 15, 15) = onnx::Div(%1197, %1198)\n",
      "  %1200 : Float(1, 12, 15, 15) = onnx::Add(%1199, %209), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:272:0\n",
      "  %1201 : Float(1, 12, 15, 15) = onnx::Softmax[axis=3](%1200), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1202 : Float(1, 12, 15, 64) = onnx::MatMul(%1201, %1195), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:285:0\n",
      "  %1203 : Float(1, 15, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1202), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:287:0\n",
      "  %1204 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1205 : Tensor = onnx::Shape(%1203), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1206 : Long() = onnx::Gather[axis=0](%1205, %1204), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %1207 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1208 : Tensor = onnx::Shape(%1203), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1209 : Long() = onnx::Gather[axis=0](%1208, %1207), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %1210 : Long() = onnx::Constant[value={768}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1211 : Tensor = onnx::Unsqueeze[axes=[0]](%1206)\n",
      "  %1212 : Tensor = onnx::Unsqueeze[axes=[0]](%1209)\n",
      "  %1213 : Tensor = onnx::Unsqueeze[axes=[0]](%1210)\n",
      "  %1214 : Tensor = onnx::Concat[axis=0](%1211, %1212, %1213)\n",
      "  %1215 : Float(1, 15, 768) = onnx::Reshape(%1203, %1214), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:289:0\n",
      "  %1216 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.8.attention.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1217 : Float(1, 15, 768) = onnx::MatMul(%1215, %1216), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1218 : Float(1, 15, 768) = onnx::Add(%1217, %encoder.layer.8.attention.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1219 : Float(1, 15, 768) = onnx::Add(%1218, %1142), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:305:0\n",
      "  %1220 : Tensor = onnx::ReduceMean[axes=[-1]](%1219), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1221 : FloatTensor = onnx::Sub(%1219, %1220), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1222 : Float() = onnx::Constant[value={2}]()\n",
      "  %1223 : FloatTensor = onnx::Pow(%1221, %1222), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1224 : Tensor = onnx::ReduceMean[axes=[-1]](%1223), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1225 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %1226 : FloatTensor = onnx::Add(%1224, %1225), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1227 : Tensor = onnx::Sqrt(%1226), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1228 : FloatTensor = onnx::Div(%1221, %1227), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1229 : FloatTensor = onnx::Mul(%1228, %encoder.layer.8.attention.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1230 : Float(1, 15, 768) = onnx::Add(%1229, %encoder.layer.8.attention.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %1231 : Float(768, 3072) = onnx::Transpose[perm=[1, 0]](%encoder.layer.8.intermediate.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1232 : Float(1, 15, 3072) = onnx::MatMul(%1230, %1231), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1233 : Float(1, 15, 3072) = onnx::Add(%1232, %encoder.layer.8.intermediate.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1234 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %1235 : Float(1, 15, 3072) = onnx::Mul(%1233, %1234)\n",
      "  %1236 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %1237 : Float(1, 15, 3072) = onnx::Div(%1233, %1236)\n",
      "  %1238 : Float(1, 15, 3072) = onnx::Erf(%1237), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %1239 : Float() = onnx::Constant[value={1}]()\n",
      "  %1240 : Float(1, 15, 3072) = onnx::Add(%1238, %1239)\n",
      "  %1241 : Float(1, 15, 3072) = onnx::Mul(%1235, %1240), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %1242 : Float(3072, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.8.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1243 : Float(1, 15, 768) = onnx::MatMul(%1241, %1242), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1244 : Float(1, 15, 768) = onnx::Add(%1243, %encoder.layer.8.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1245 : Float(1, 15, 768) = onnx::Add(%1244, %1230), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:381:0\n",
      "  %1246 : Tensor = onnx::ReduceMean[axes=[-1]](%1245), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1247 : FloatTensor = onnx::Sub(%1245, %1246), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1248 : Float() = onnx::Constant[value={2}]()\n",
      "  %1249 : FloatTensor = onnx::Pow(%1247, %1248), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1250 : Tensor = onnx::ReduceMean[axes=[-1]](%1249), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1251 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %1252 : FloatTensor = onnx::Add(%1250, %1251), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1253 : Tensor = onnx::Sqrt(%1252), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1254 : FloatTensor = onnx::Div(%1247, %1253), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1255 : FloatTensor = onnx::Mul(%1254, %encoder.layer.8.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1256 : Float(1, 15, 768) = onnx::Add(%1255, %encoder.layer.8.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %1257 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.9.attention.self.query.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1258 : Float(1, 15, 768) = onnx::MatMul(%1256, %1257), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1259 : Float(1, 15, 768) = onnx::Add(%1258, %encoder.layer.9.attention.self.query.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1260 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.9.attention.self.key.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1261 : Float(1, 15, 768) = onnx::MatMul(%1256, %1260), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1262 : Float(1, 15, 768) = onnx::Add(%1261, %encoder.layer.9.attention.self.key.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1263 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.9.attention.self.value.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1264 : Float(1, 15, 768) = onnx::MatMul(%1256, %1263), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1265 : Float(1, 15, 768) = onnx::Add(%1264, %encoder.layer.9.attention.self.value.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1266 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1267 : Tensor = onnx::Shape(%1259), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1268 : Long() = onnx::Gather[axis=0](%1267, %1266), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1269 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1270 : Tensor = onnx::Shape(%1259), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1271 : Long() = onnx::Gather[axis=0](%1270, %1269), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1272 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1273 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1274 : Tensor = onnx::Unsqueeze[axes=[0]](%1268)\n",
      "  %1275 : Tensor = onnx::Unsqueeze[axes=[0]](%1271)\n",
      "  %1276 : Tensor = onnx::Unsqueeze[axes=[0]](%1272)\n",
      "  %1277 : Tensor = onnx::Unsqueeze[axes=[0]](%1273)\n",
      "  %1278 : Tensor = onnx::Concat[axis=0](%1274, %1275, %1276, %1277)\n",
      "  %1279 : Float(1, 15, 12, 64) = onnx::Reshape(%1259, %1278), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1280 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1279), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %1281 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1282 : Tensor = onnx::Shape(%1262), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1283 : Long() = onnx::Gather[axis=0](%1282, %1281), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1284 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1285 : Tensor = onnx::Shape(%1262), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1286 : Long() = onnx::Gather[axis=0](%1285, %1284), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1287 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1288 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1289 : Tensor = onnx::Unsqueeze[axes=[0]](%1283)\n",
      "  %1290 : Tensor = onnx::Unsqueeze[axes=[0]](%1286)\n",
      "  %1291 : Tensor = onnx::Unsqueeze[axes=[0]](%1287)\n",
      "  %1292 : Tensor = onnx::Unsqueeze[axes=[0]](%1288)\n",
      "  %1293 : Tensor = onnx::Concat[axis=0](%1289, %1290, %1291, %1292)\n",
      "  %1294 : Float(1, 15, 12, 64) = onnx::Reshape(%1262, %1293), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1295 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1296 : Tensor = onnx::Shape(%1265), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1297 : Long() = onnx::Gather[axis=0](%1296, %1295), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1298 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1299 : Tensor = onnx::Shape(%1265), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1300 : Long() = onnx::Gather[axis=0](%1299, %1298), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1301 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1302 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1303 : Tensor = onnx::Unsqueeze[axes=[0]](%1297)\n",
      "  %1304 : Tensor = onnx::Unsqueeze[axes=[0]](%1300)\n",
      "  %1305 : Tensor = onnx::Unsqueeze[axes=[0]](%1301)\n",
      "  %1306 : Tensor = onnx::Unsqueeze[axes=[0]](%1302)\n",
      "  %1307 : Tensor = onnx::Concat[axis=0](%1303, %1304, %1305, %1306)\n",
      "  %1308 : Float(1, 15, 12, 64) = onnx::Reshape(%1265, %1307), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1309 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1308), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %1310 : Float(1, 12, 64, 15) = onnx::Transpose[perm=[0, 2, 3, 1]](%1294), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %1311 : Float(1, 12, 15, 15) = onnx::MatMul(%1280, %1310), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %1312 : Float() = onnx::Constant[value={8}]()\n",
      "  %1313 : Float(1, 12, 15, 15) = onnx::Div(%1311, %1312)\n",
      "  %1314 : Float(1, 12, 15, 15) = onnx::Add(%1313, %209), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:272:0\n",
      "  %1315 : Float(1, 12, 15, 15) = onnx::Softmax[axis=3](%1314), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1316 : Float(1, 12, 15, 64) = onnx::MatMul(%1315, %1309), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:285:0\n",
      "  %1317 : Float(1, 15, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1316), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:287:0\n",
      "  %1318 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1319 : Tensor = onnx::Shape(%1317), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1320 : Long() = onnx::Gather[axis=0](%1319, %1318), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %1321 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1322 : Tensor = onnx::Shape(%1317), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1323 : Long() = onnx::Gather[axis=0](%1322, %1321), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %1324 : Long() = onnx::Constant[value={768}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1325 : Tensor = onnx::Unsqueeze[axes=[0]](%1320)\n",
      "  %1326 : Tensor = onnx::Unsqueeze[axes=[0]](%1323)\n",
      "  %1327 : Tensor = onnx::Unsqueeze[axes=[0]](%1324)\n",
      "  %1328 : Tensor = onnx::Concat[axis=0](%1325, %1326, %1327)\n",
      "  %1329 : Float(1, 15, 768) = onnx::Reshape(%1317, %1328), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:289:0\n",
      "  %1330 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.9.attention.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1331 : Float(1, 15, 768) = onnx::MatMul(%1329, %1330), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1332 : Float(1, 15, 768) = onnx::Add(%1331, %encoder.layer.9.attention.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1333 : Float(1, 15, 768) = onnx::Add(%1332, %1256), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:305:0\n",
      "  %1334 : Tensor = onnx::ReduceMean[axes=[-1]](%1333), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1335 : FloatTensor = onnx::Sub(%1333, %1334), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1336 : Float() = onnx::Constant[value={2}]()\n",
      "  %1337 : FloatTensor = onnx::Pow(%1335, %1336), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1338 : Tensor = onnx::ReduceMean[axes=[-1]](%1337), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1339 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %1340 : FloatTensor = onnx::Add(%1338, %1339), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1341 : Tensor = onnx::Sqrt(%1340), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1342 : FloatTensor = onnx::Div(%1335, %1341), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1343 : FloatTensor = onnx::Mul(%1342, %encoder.layer.9.attention.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1344 : Float(1, 15, 768) = onnx::Add(%1343, %encoder.layer.9.attention.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %1345 : Float(768, 3072) = onnx::Transpose[perm=[1, 0]](%encoder.layer.9.intermediate.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1346 : Float(1, 15, 3072) = onnx::MatMul(%1344, %1345), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1347 : Float(1, 15, 3072) = onnx::Add(%1346, %encoder.layer.9.intermediate.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1348 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %1349 : Float(1, 15, 3072) = onnx::Mul(%1347, %1348)\n",
      "  %1350 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %1351 : Float(1, 15, 3072) = onnx::Div(%1347, %1350)\n",
      "  %1352 : Float(1, 15, 3072) = onnx::Erf(%1351), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %1353 : Float() = onnx::Constant[value={1}]()\n",
      "  %1354 : Float(1, 15, 3072) = onnx::Add(%1352, %1353)\n",
      "  %1355 : Float(1, 15, 3072) = onnx::Mul(%1349, %1354), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %1356 : Float(3072, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.9.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1357 : Float(1, 15, 768) = onnx::MatMul(%1355, %1356), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1358 : Float(1, 15, 768) = onnx::Add(%1357, %encoder.layer.9.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1359 : Float(1, 15, 768) = onnx::Add(%1358, %1344), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:381:0\n",
      "  %1360 : Tensor = onnx::ReduceMean[axes=[-1]](%1359), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1361 : FloatTensor = onnx::Sub(%1359, %1360), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1362 : Float() = onnx::Constant[value={2}]()\n",
      "  %1363 : FloatTensor = onnx::Pow(%1361, %1362), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1364 : Tensor = onnx::ReduceMean[axes=[-1]](%1363), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1365 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %1366 : FloatTensor = onnx::Add(%1364, %1365), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1367 : Tensor = onnx::Sqrt(%1366), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1368 : FloatTensor = onnx::Div(%1361, %1367), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1369 : FloatTensor = onnx::Mul(%1368, %encoder.layer.9.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1370 : Float(1, 15, 768) = onnx::Add(%1369, %encoder.layer.9.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %1371 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.10.attention.self.query.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1372 : Float(1, 15, 768) = onnx::MatMul(%1370, %1371), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1373 : Float(1, 15, 768) = onnx::Add(%1372, %encoder.layer.10.attention.self.query.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1374 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.10.attention.self.key.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1375 : Float(1, 15, 768) = onnx::MatMul(%1370, %1374), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1376 : Float(1, 15, 768) = onnx::Add(%1375, %encoder.layer.10.attention.self.key.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1377 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.10.attention.self.value.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1378 : Float(1, 15, 768) = onnx::MatMul(%1370, %1377), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1379 : Float(1, 15, 768) = onnx::Add(%1378, %encoder.layer.10.attention.self.value.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1380 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1381 : Tensor = onnx::Shape(%1373), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1382 : Long() = onnx::Gather[axis=0](%1381, %1380), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1383 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1384 : Tensor = onnx::Shape(%1373), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1385 : Long() = onnx::Gather[axis=0](%1384, %1383), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1386 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1387 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1388 : Tensor = onnx::Unsqueeze[axes=[0]](%1382)\n",
      "  %1389 : Tensor = onnx::Unsqueeze[axes=[0]](%1385)\n",
      "  %1390 : Tensor = onnx::Unsqueeze[axes=[0]](%1386)\n",
      "  %1391 : Tensor = onnx::Unsqueeze[axes=[0]](%1387)\n",
      "  %1392 : Tensor = onnx::Concat[axis=0](%1388, %1389, %1390, %1391)\n",
      "  %1393 : Float(1, 15, 12, 64) = onnx::Reshape(%1373, %1392), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1394 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1393), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %1395 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1396 : Tensor = onnx::Shape(%1376), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1397 : Long() = onnx::Gather[axis=0](%1396, %1395), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1398 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1399 : Tensor = onnx::Shape(%1376), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1400 : Long() = onnx::Gather[axis=0](%1399, %1398), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1401 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1402 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1403 : Tensor = onnx::Unsqueeze[axes=[0]](%1397)\n",
      "  %1404 : Tensor = onnx::Unsqueeze[axes=[0]](%1400)\n",
      "  %1405 : Tensor = onnx::Unsqueeze[axes=[0]](%1401)\n",
      "  %1406 : Tensor = onnx::Unsqueeze[axes=[0]](%1402)\n",
      "  %1407 : Tensor = onnx::Concat[axis=0](%1403, %1404, %1405, %1406)\n",
      "  %1408 : Float(1, 15, 12, 64) = onnx::Reshape(%1376, %1407), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1409 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1410 : Tensor = onnx::Shape(%1379), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1411 : Long() = onnx::Gather[axis=0](%1410, %1409), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1412 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1413 : Tensor = onnx::Shape(%1379), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1414 : Long() = onnx::Gather[axis=0](%1413, %1412), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1415 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1416 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1417 : Tensor = onnx::Unsqueeze[axes=[0]](%1411)\n",
      "  %1418 : Tensor = onnx::Unsqueeze[axes=[0]](%1414)\n",
      "  %1419 : Tensor = onnx::Unsqueeze[axes=[0]](%1415)\n",
      "  %1420 : Tensor = onnx::Unsqueeze[axes=[0]](%1416)\n",
      "  %1421 : Tensor = onnx::Concat[axis=0](%1417, %1418, %1419, %1420)\n",
      "  %1422 : Float(1, 15, 12, 64) = onnx::Reshape(%1379, %1421), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1423 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1422), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %1424 : Float(1, 12, 64, 15) = onnx::Transpose[perm=[0, 2, 3, 1]](%1408), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %1425 : Float(1, 12, 15, 15) = onnx::MatMul(%1394, %1424), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %1426 : Float() = onnx::Constant[value={8}]()\n",
      "  %1427 : Float(1, 12, 15, 15) = onnx::Div(%1425, %1426)\n",
      "  %1428 : Float(1, 12, 15, 15) = onnx::Add(%1427, %209), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:272:0\n",
      "  %1429 : Float(1, 12, 15, 15) = onnx::Softmax[axis=3](%1428), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1430 : Float(1, 12, 15, 64) = onnx::MatMul(%1429, %1423), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:285:0\n",
      "  %1431 : Float(1, 15, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1430), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:287:0\n",
      "  %1432 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1433 : Tensor = onnx::Shape(%1431), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1434 : Long() = onnx::Gather[axis=0](%1433, %1432), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %1435 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1436 : Tensor = onnx::Shape(%1431), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1437 : Long() = onnx::Gather[axis=0](%1436, %1435), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %1438 : Long() = onnx::Constant[value={768}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1439 : Tensor = onnx::Unsqueeze[axes=[0]](%1434)\n",
      "  %1440 : Tensor = onnx::Unsqueeze[axes=[0]](%1437)\n",
      "  %1441 : Tensor = onnx::Unsqueeze[axes=[0]](%1438)\n",
      "  %1442 : Tensor = onnx::Concat[axis=0](%1439, %1440, %1441)\n",
      "  %1443 : Float(1, 15, 768) = onnx::Reshape(%1431, %1442), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:289:0\n",
      "  %1444 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.10.attention.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1445 : Float(1, 15, 768) = onnx::MatMul(%1443, %1444), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1446 : Float(1, 15, 768) = onnx::Add(%1445, %encoder.layer.10.attention.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1447 : Float(1, 15, 768) = onnx::Add(%1446, %1370), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:305:0\n",
      "  %1448 : Tensor = onnx::ReduceMean[axes=[-1]](%1447), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1449 : FloatTensor = onnx::Sub(%1447, %1448), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1450 : Float() = onnx::Constant[value={2}]()\n",
      "  %1451 : FloatTensor = onnx::Pow(%1449, %1450), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1452 : Tensor = onnx::ReduceMean[axes=[-1]](%1451), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1453 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %1454 : FloatTensor = onnx::Add(%1452, %1453), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1455 : Tensor = onnx::Sqrt(%1454), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1456 : FloatTensor = onnx::Div(%1449, %1455), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1457 : FloatTensor = onnx::Mul(%1456, %encoder.layer.10.attention.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1458 : Float(1, 15, 768) = onnx::Add(%1457, %encoder.layer.10.attention.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %1459 : Float(768, 3072) = onnx::Transpose[perm=[1, 0]](%encoder.layer.10.intermediate.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1460 : Float(1, 15, 3072) = onnx::MatMul(%1458, %1459), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1461 : Float(1, 15, 3072) = onnx::Add(%1460, %encoder.layer.10.intermediate.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1462 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %1463 : Float(1, 15, 3072) = onnx::Mul(%1461, %1462)\n",
      "  %1464 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %1465 : Float(1, 15, 3072) = onnx::Div(%1461, %1464)\n",
      "  %1466 : Float(1, 15, 3072) = onnx::Erf(%1465), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %1467 : Float() = onnx::Constant[value={1}]()\n",
      "  %1468 : Float(1, 15, 3072) = onnx::Add(%1466, %1467)\n",
      "  %1469 : Float(1, 15, 3072) = onnx::Mul(%1463, %1468), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %1470 : Float(3072, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.10.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1471 : Float(1, 15, 768) = onnx::MatMul(%1469, %1470), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1472 : Float(1, 15, 768) = onnx::Add(%1471, %encoder.layer.10.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1473 : Float(1, 15, 768) = onnx::Add(%1472, %1458), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:381:0\n",
      "  %1474 : Tensor = onnx::ReduceMean[axes=[-1]](%1473), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1475 : FloatTensor = onnx::Sub(%1473, %1474), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1476 : Float() = onnx::Constant[value={2}]()\n",
      "  %1477 : FloatTensor = onnx::Pow(%1475, %1476), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1478 : Tensor = onnx::ReduceMean[axes=[-1]](%1477), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1479 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %1480 : FloatTensor = onnx::Add(%1478, %1479), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1481 : Tensor = onnx::Sqrt(%1480), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1482 : FloatTensor = onnx::Div(%1475, %1481), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1483 : FloatTensor = onnx::Mul(%1482, %encoder.layer.10.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1484 : Float(1, 15, 768) = onnx::Add(%1483, %encoder.layer.10.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %1485 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.11.attention.self.query.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1486 : Float(1, 15, 768) = onnx::MatMul(%1484, %1485), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1487 : Float(1, 15, 768) = onnx::Add(%1486, %encoder.layer.11.attention.self.query.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[query] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1488 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.11.attention.self.key.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1489 : Float(1, 15, 768) = onnx::MatMul(%1484, %1488), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1490 : Float(1, 15, 768) = onnx::Add(%1489, %encoder.layer.11.attention.self.key.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[key] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1491 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.11.attention.self.value.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1492 : Float(1, 15, 768) = onnx::MatMul(%1484, %1491), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1493 : Float(1, 15, 768) = onnx::Add(%1492, %encoder.layer.11.attention.self.value.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Linear[value] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1494 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1495 : Tensor = onnx::Shape(%1487), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1496 : Long() = onnx::Gather[axis=0](%1495, %1494), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1497 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1498 : Tensor = onnx::Shape(%1487), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1499 : Long() = onnx::Gather[axis=0](%1498, %1497), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1500 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1501 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1502 : Tensor = onnx::Unsqueeze[axes=[0]](%1496)\n",
      "  %1503 : Tensor = onnx::Unsqueeze[axes=[0]](%1499)\n",
      "  %1504 : Tensor = onnx::Unsqueeze[axes=[0]](%1500)\n",
      "  %1505 : Tensor = onnx::Unsqueeze[axes=[0]](%1501)\n",
      "  %1506 : Tensor = onnx::Concat[axis=0](%1502, %1503, %1504, %1505)\n",
      "  %1507 : Float(1, 15, 12, 64) = onnx::Reshape(%1487, %1506), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1508 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1507), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %1509 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1510 : Tensor = onnx::Shape(%1490), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1511 : Long() = onnx::Gather[axis=0](%1510, %1509), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1512 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1513 : Tensor = onnx::Shape(%1490), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1514 : Long() = onnx::Gather[axis=0](%1513, %1512), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1515 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1516 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1517 : Tensor = onnx::Unsqueeze[axes=[0]](%1511)\n",
      "  %1518 : Tensor = onnx::Unsqueeze[axes=[0]](%1514)\n",
      "  %1519 : Tensor = onnx::Unsqueeze[axes=[0]](%1515)\n",
      "  %1520 : Tensor = onnx::Unsqueeze[axes=[0]](%1516)\n",
      "  %1521 : Tensor = onnx::Concat[axis=0](%1517, %1518, %1519, %1520)\n",
      "  %1522 : Float(1, 15, 12, 64) = onnx::Reshape(%1490, %1521), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1523 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1524 : Tensor = onnx::Shape(%1493), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1525 : Long() = onnx::Gather[axis=0](%1524, %1523), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1526 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1527 : Tensor = onnx::Shape(%1493), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1528 : Long() = onnx::Gather[axis=0](%1527, %1526), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:237:0\n",
      "  %1529 : Long() = onnx::Constant[value={12}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1530 : Long() = onnx::Constant[value={64}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1531 : Tensor = onnx::Unsqueeze[axes=[0]](%1525)\n",
      "  %1532 : Tensor = onnx::Unsqueeze[axes=[0]](%1528)\n",
      "  %1533 : Tensor = onnx::Unsqueeze[axes=[0]](%1529)\n",
      "  %1534 : Tensor = onnx::Unsqueeze[axes=[0]](%1530)\n",
      "  %1535 : Tensor = onnx::Concat[axis=0](%1531, %1532, %1533, %1534)\n",
      "  %1536 : Float(1, 15, 12, 64) = onnx::Reshape(%1493, %1535), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:238:0\n",
      "  %1537 : Float(1, 12, 15, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1536), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:239:0\n",
      "  %1538 : Float(1, 12, 64, 15) = onnx::Transpose[perm=[0, 2, 3, 1]](%1522), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %1539 : Float(1, 12, 15, 15) = onnx::MatMul(%1508, %1538), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:268:0\n",
      "  %1540 : Float() = onnx::Constant[value={8}]()\n",
      "  %1541 : Float(1, 12, 15, 15) = onnx::Div(%1539, %1540)\n",
      "  %1542 : Float(1, 12, 15, 15) = onnx::Add(%1541, %209), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:272:0\n",
      "  %1543 : Float(1, 12, 15, 15) = onnx::Softmax[axis=3](%1542), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1544 : Float(1, 12, 15, 64) = onnx::MatMul(%1543, %1537), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:285:0\n",
      "  %1545 : Float(1, 15, 12, 64) = onnx::Transpose[perm=[0, 2, 1, 3]](%1544), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:287:0\n",
      "  %1546 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1547 : Tensor = onnx::Shape(%1545), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1548 : Long() = onnx::Gather[axis=0](%1547, %1546), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %1549 : Long() = onnx::Constant[value={1}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1550 : Tensor = onnx::Shape(%1545), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1551 : Long() = onnx::Gather[axis=0](%1550, %1549), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:288:0\n",
      "  %1552 : Long() = onnx::Constant[value={768}](), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self]\n",
      "  %1553 : Tensor = onnx::Unsqueeze[axes=[0]](%1548)\n",
      "  %1554 : Tensor = onnx::Unsqueeze[axes=[0]](%1551)\n",
      "  %1555 : Tensor = onnx::Unsqueeze[axes=[0]](%1552)\n",
      "  %1556 : Tensor = onnx::Concat[axis=0](%1553, %1554, %1555)\n",
      "  %1557 : Float(1, 15, 768) = onnx::Reshape(%1545, %1556), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfAttention[self] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:289:0\n",
      "  %1558 : Float(768, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.11.attention.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1559 : Float(1, 15, 768) = onnx::MatMul(%1557, %1558), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1560 : Float(1, 15, 768) = onnx::Add(%1559, %encoder.layer.11.attention.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1561 : Float(1, 15, 768) = onnx::Add(%1560, %1484), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:305:0\n",
      "  %1562 : Tensor = onnx::ReduceMean[axes=[-1]](%1561), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1563 : FloatTensor = onnx::Sub(%1561, %1562), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1564 : Float() = onnx::Constant[value={2}]()\n",
      "  %1565 : FloatTensor = onnx::Pow(%1563, %1564), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1566 : Tensor = onnx::ReduceMean[axes=[-1]](%1565), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1567 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %1568 : FloatTensor = onnx::Add(%1566, %1567), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1569 : Tensor = onnx::Sqrt(%1568), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1570 : FloatTensor = onnx::Div(%1563, %1569), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1571 : FloatTensor = onnx::Mul(%1570, %encoder.layer.11.attention.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1572 : Float(1, 15, 768) = onnx::Add(%1571, %encoder.layer.11.attention.output.LayerNorm.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertAttention[attention]/BertSelfOutput[output]/LayerNorm[LayerNorm] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1696:0\n",
      "  %1573 : Float(768, 3072) = onnx::Transpose[perm=[1, 0]](%encoder.layer.11.intermediate.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1574 : Float(1, 15, 3072) = onnx::MatMul(%1572, %1573), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1575 : Float(1, 15, 3072) = onnx::Add(%1574, %encoder.layer.11.intermediate.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1374:0\n",
      "  %1576 : Float() = onnx::Constant[value={0.5}]()\n",
      "  %1577 : Float(1, 15, 3072) = onnx::Mul(%1575, %1576)\n",
      "  %1578 : Float() = onnx::Constant[value={1.41421}]()\n",
      "  %1579 : Float(1, 15, 3072) = onnx::Div(%1575, %1578)\n",
      "  %1580 : Float(1, 15, 3072) = onnx::Erf(%1579), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %1581 : Float() = onnx::Constant[value={1}]()\n",
      "  %1582 : Float(1, 15, 3072) = onnx::Add(%1580, %1581)\n",
      "  %1583 : Float(1, 15, 3072) = onnx::Mul(%1577, %1582), scope: BertModel/BertEncoder[encoder]/BertLayer/BertIntermediate[intermediate] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/activations.py:23:0\n",
      "  %1584 : Float(3072, 768) = onnx::Transpose[perm=[1, 0]](%encoder.layer.11.output.dense.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1585 : Float(1, 15, 768) = onnx::MatMul(%1583, %1584), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1372:0\n",
      "  %1586 : Float(1, 15, 768) = onnx::Add(%1585, %encoder.layer.11.output.dense.bias), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/Dropout[dropout] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %1587 : Float(1, 15, 768) = onnx::Add(%1586, %1572), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:381:0\n",
      "  %1588 : Tensor = onnx::ReduceMean[axes=[-1]](%1587), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1589 : FloatTensor = onnx::Sub(%1587, %1588), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1590 : Float() = onnx::Constant[value={2}]()\n",
      "  %1591 : FloatTensor = onnx::Pow(%1589, %1590), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1592 : Tensor = onnx::ReduceMean[axes=[-1]](%1591), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1593 : Float() = onnx::Constant[value={1e-12}]()\n",
      "  %1594 : FloatTensor = onnx::Add(%1592, %1593), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1595 : Tensor = onnx::Sqrt(%1594), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1596 : FloatTensor = onnx::Div(%1589, %1595), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1597 : FloatTensor = onnx::Mul(%1596, %encoder.layer.11.output.LayerNorm.weight), scope: BertModel/BertEncoder[encoder]/BertLayer/BertOutput[output]/LayerNorm[LayerNorm]\n",
      "  %1598 : Float(1, 15, 768) = onnx::Add(%1597, %encoder.layer.11.output.LayerNorm.bias), scope: BertModel/BertPooler[pooler] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:515:0\n",
      "  %1599 : Long() = onnx::Constant[value={0}](), scope: BertModel/BertPooler[pooler]\n",
      "  %1600 : Float(1, 768) = onnx::Gather[axis=1](%1598, %1599), scope: BertModel/BertPooler[pooler] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/transformers/modeling_bert.py:515:0\n",
      "  %1601 : Float(1, 768) = onnx::Gemm[alpha=1, beta=1, transB=1](%1600, %pooler.dense.weight, %pooler.dense.bias), scope: BertModel/BertPooler[pooler]/Linear[dense] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/functional.py:1370:0\n",
      "  %1602 : Float(1, 768) = onnx::Tanh(%1601), scope: BertModel/BertPooler[pooler]/Tanh[activation] # /usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/modules/activation.py:295:0\n",
      "  return (%1598, %1602)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, x, \"roberta.onnx\", opset_version=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch-jit-export (\n",
      "  %input.1[INT64, 1x15]\n",
      "  %attention_mask[INT64, 1x15]\n",
      "  %input.3[INT64, 1x15]\n",
      ") initializers (\n",
      "  %embeddings.LayerNorm.bias[FLOAT, 768]\n",
      "  %embeddings.LayerNorm.weight[FLOAT, 768]\n",
      "  %embeddings.position_embeddings.weight[FLOAT, 512x768]\n",
      "  %embeddings.position_ids[INT64, 1x512]\n",
      "  %embeddings.token_type_embeddings.weight[FLOAT, 2x768]\n",
      "  %embeddings.word_embeddings.weight[FLOAT, 21128x768]\n",
      "  %encoder.layer.0.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.0.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.0.attention.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.0.attention.output.dense.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.0.attention.self.key.bias[FLOAT, 768]\n",
      "  %encoder.layer.0.attention.self.key.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.0.attention.self.query.bias[FLOAT, 768]\n",
      "  %encoder.layer.0.attention.self.query.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.0.attention.self.value.bias[FLOAT, 768]\n",
      "  %encoder.layer.0.attention.self.value.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.0.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %encoder.layer.0.intermediate.dense.weight[FLOAT, 3072x768]\n",
      "  %encoder.layer.0.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.0.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.0.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.0.output.dense.weight[FLOAT, 768x3072]\n",
      "  %encoder.layer.1.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.1.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.1.attention.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.1.attention.output.dense.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.1.attention.self.key.bias[FLOAT, 768]\n",
      "  %encoder.layer.1.attention.self.key.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.1.attention.self.query.bias[FLOAT, 768]\n",
      "  %encoder.layer.1.attention.self.query.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.1.attention.self.value.bias[FLOAT, 768]\n",
      "  %encoder.layer.1.attention.self.value.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.1.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %encoder.layer.1.intermediate.dense.weight[FLOAT, 3072x768]\n",
      "  %encoder.layer.1.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.1.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.1.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.1.output.dense.weight[FLOAT, 768x3072]\n",
      "  %encoder.layer.10.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.10.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.10.attention.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.10.attention.output.dense.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.10.attention.self.key.bias[FLOAT, 768]\n",
      "  %encoder.layer.10.attention.self.key.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.10.attention.self.query.bias[FLOAT, 768]\n",
      "  %encoder.layer.10.attention.self.query.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.10.attention.self.value.bias[FLOAT, 768]\n",
      "  %encoder.layer.10.attention.self.value.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.10.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %encoder.layer.10.intermediate.dense.weight[FLOAT, 3072x768]\n",
      "  %encoder.layer.10.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.10.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.10.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.10.output.dense.weight[FLOAT, 768x3072]\n",
      "  %encoder.layer.11.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.11.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.11.attention.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.11.attention.output.dense.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.11.attention.self.key.bias[FLOAT, 768]\n",
      "  %encoder.layer.11.attention.self.key.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.11.attention.self.query.bias[FLOAT, 768]\n",
      "  %encoder.layer.11.attention.self.query.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.11.attention.self.value.bias[FLOAT, 768]\n",
      "  %encoder.layer.11.attention.self.value.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.11.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %encoder.layer.11.intermediate.dense.weight[FLOAT, 3072x768]\n",
      "  %encoder.layer.11.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.11.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.11.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.11.output.dense.weight[FLOAT, 768x3072]\n",
      "  %encoder.layer.2.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.2.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.2.attention.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.2.attention.output.dense.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.2.attention.self.key.bias[FLOAT, 768]\n",
      "  %encoder.layer.2.attention.self.key.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.2.attention.self.query.bias[FLOAT, 768]\n",
      "  %encoder.layer.2.attention.self.query.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.2.attention.self.value.bias[FLOAT, 768]\n",
      "  %encoder.layer.2.attention.self.value.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.2.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %encoder.layer.2.intermediate.dense.weight[FLOAT, 3072x768]\n",
      "  %encoder.layer.2.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.2.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.2.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.2.output.dense.weight[FLOAT, 768x3072]\n",
      "  %encoder.layer.3.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.3.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.3.attention.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.3.attention.output.dense.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.3.attention.self.key.bias[FLOAT, 768]\n",
      "  %encoder.layer.3.attention.self.key.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.3.attention.self.query.bias[FLOAT, 768]\n",
      "  %encoder.layer.3.attention.self.query.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.3.attention.self.value.bias[FLOAT, 768]\n",
      "  %encoder.layer.3.attention.self.value.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.3.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %encoder.layer.3.intermediate.dense.weight[FLOAT, 3072x768]\n",
      "  %encoder.layer.3.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.3.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.3.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.3.output.dense.weight[FLOAT, 768x3072]\n",
      "  %encoder.layer.4.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.4.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.4.attention.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.4.attention.output.dense.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.4.attention.self.key.bias[FLOAT, 768]\n",
      "  %encoder.layer.4.attention.self.key.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.4.attention.self.query.bias[FLOAT, 768]\n",
      "  %encoder.layer.4.attention.self.query.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.4.attention.self.value.bias[FLOAT, 768]\n",
      "  %encoder.layer.4.attention.self.value.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.4.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %encoder.layer.4.intermediate.dense.weight[FLOAT, 3072x768]\n",
      "  %encoder.layer.4.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.4.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.4.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.4.output.dense.weight[FLOAT, 768x3072]\n",
      "  %encoder.layer.5.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.5.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.5.attention.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.5.attention.output.dense.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.5.attention.self.key.bias[FLOAT, 768]\n",
      "  %encoder.layer.5.attention.self.key.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.5.attention.self.query.bias[FLOAT, 768]\n",
      "  %encoder.layer.5.attention.self.query.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.5.attention.self.value.bias[FLOAT, 768]\n",
      "  %encoder.layer.5.attention.self.value.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.5.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %encoder.layer.5.intermediate.dense.weight[FLOAT, 3072x768]\n",
      "  %encoder.layer.5.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.5.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.5.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.5.output.dense.weight[FLOAT, 768x3072]\n",
      "  %encoder.layer.6.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.6.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.6.attention.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.6.attention.output.dense.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.6.attention.self.key.bias[FLOAT, 768]\n",
      "  %encoder.layer.6.attention.self.key.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.6.attention.self.query.bias[FLOAT, 768]\n",
      "  %encoder.layer.6.attention.self.query.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.6.attention.self.value.bias[FLOAT, 768]\n",
      "  %encoder.layer.6.attention.self.value.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.6.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %encoder.layer.6.intermediate.dense.weight[FLOAT, 3072x768]\n",
      "  %encoder.layer.6.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.6.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.6.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.6.output.dense.weight[FLOAT, 768x3072]\n",
      "  %encoder.layer.7.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.7.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.7.attention.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.7.attention.output.dense.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.7.attention.self.key.bias[FLOAT, 768]\n",
      "  %encoder.layer.7.attention.self.key.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.7.attention.self.query.bias[FLOAT, 768]\n",
      "  %encoder.layer.7.attention.self.query.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.7.attention.self.value.bias[FLOAT, 768]\n",
      "  %encoder.layer.7.attention.self.value.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.7.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %encoder.layer.7.intermediate.dense.weight[FLOAT, 3072x768]\n",
      "  %encoder.layer.7.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.7.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.7.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.7.output.dense.weight[FLOAT, 768x3072]\n",
      "  %encoder.layer.8.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.8.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.8.attention.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.8.attention.output.dense.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.8.attention.self.key.bias[FLOAT, 768]\n",
      "  %encoder.layer.8.attention.self.key.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.8.attention.self.query.bias[FLOAT, 768]\n",
      "  %encoder.layer.8.attention.self.query.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.8.attention.self.value.bias[FLOAT, 768]\n",
      "  %encoder.layer.8.attention.self.value.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.8.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %encoder.layer.8.intermediate.dense.weight[FLOAT, 3072x768]\n",
      "  %encoder.layer.8.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.8.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.8.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.8.output.dense.weight[FLOAT, 768x3072]\n",
      "  %encoder.layer.9.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.9.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.9.attention.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.9.attention.output.dense.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.9.attention.self.key.bias[FLOAT, 768]\n",
      "  %encoder.layer.9.attention.self.key.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.9.attention.self.query.bias[FLOAT, 768]\n",
      "  %encoder.layer.9.attention.self.query.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.9.attention.self.value.bias[FLOAT, 768]\n",
      "  %encoder.layer.9.attention.self.value.weight[FLOAT, 768x768]\n",
      "  %encoder.layer.9.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %encoder.layer.9.intermediate.dense.weight[FLOAT, 3072x768]\n",
      "  %encoder.layer.9.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %encoder.layer.9.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %encoder.layer.9.output.dense.bias[FLOAT, 768]\n",
      "  %encoder.layer.9.output.dense.weight[FLOAT, 768x3072]\n",
      "  %pooler.dense.bias[FLOAT, 768]\n",
      "  %pooler.dense.weight[FLOAT, 768x768]\n",
      ") {\n",
      "  %203 = Unsqueeze[axes = [1]](%attention_mask)\n",
      "  %204 = Unsqueeze[axes = [2]](%203)\n",
      "  %205 = Cast[to = 1](%204)\n",
      "  %206 = Constant[value = <Scalar Tensor []>]()\n",
      "  %207 = Sub(%206, %205)\n",
      "  %208 = Constant[value = <Scalar Tensor []>]()\n",
      "  %209 = Mul(%207, %208)\n",
      "  %210 = Constant[value = <Tensor>]()\n",
      "  %211 = Constant[value = <Tensor>]()\n",
      "  %212 = Constant[value = <Tensor>]()\n",
      "  %213 = Constant[value = <Tensor>]()\n",
      "  %214 = Slice(%embeddings.position_ids, %211, %212, %210, %213)\n",
      "  %215 = Gather(%embeddings.word_embeddings.weight, %input.1)\n",
      "  %216 = Gather(%embeddings.position_embeddings.weight, %214)\n",
      "  %217 = Gather(%embeddings.token_type_embeddings.weight, %input.3)\n",
      "  %218 = Add(%215, %216)\n",
      "  %219 = Add(%218, %217)\n",
      "  %220 = ReduceMean[axes = [-1]](%219)\n",
      "  %221 = Sub(%219, %220)\n",
      "  %222 = Constant[value = <Scalar Tensor []>]()\n",
      "  %223 = Pow(%221, %222)\n",
      "  %224 = ReduceMean[axes = [-1]](%223)\n",
      "  %225 = Constant[value = <Scalar Tensor []>]()\n",
      "  %226 = Add(%224, %225)\n",
      "  %227 = Sqrt(%226)\n",
      "  %228 = Div(%221, %227)\n",
      "  %229 = Mul(%228, %embeddings.LayerNorm.weight)\n",
      "  %230 = Add(%229, %embeddings.LayerNorm.bias)\n",
      "  %231 = Transpose[perm = [1, 0]](%encoder.layer.0.attention.self.query.weight)\n",
      "  %232 = MatMul(%230, %231)\n",
      "  %233 = Add(%232, %encoder.layer.0.attention.self.query.bias)\n",
      "  %234 = Transpose[perm = [1, 0]](%encoder.layer.0.attention.self.key.weight)\n",
      "  %235 = MatMul(%230, %234)\n",
      "  %236 = Add(%235, %encoder.layer.0.attention.self.key.bias)\n",
      "  %237 = Transpose[perm = [1, 0]](%encoder.layer.0.attention.self.value.weight)\n",
      "  %238 = MatMul(%230, %237)\n",
      "  %239 = Add(%238, %encoder.layer.0.attention.self.value.bias)\n",
      "  %240 = Constant[value = <Scalar Tensor []>]()\n",
      "  %241 = Shape(%233)\n",
      "  %242 = Gather[axis = 0](%241, %240)\n",
      "  %243 = Constant[value = <Scalar Tensor []>]()\n",
      "  %244 = Shape(%233)\n",
      "  %245 = Gather[axis = 0](%244, %243)\n",
      "  %246 = Constant[value = <Scalar Tensor []>]()\n",
      "  %247 = Constant[value = <Scalar Tensor []>]()\n",
      "  %248 = Unsqueeze[axes = [0]](%242)\n",
      "  %249 = Unsqueeze[axes = [0]](%245)\n",
      "  %250 = Unsqueeze[axes = [0]](%246)\n",
      "  %251 = Unsqueeze[axes = [0]](%247)\n",
      "  %252 = Concat[axis = 0](%248, %249, %250, %251)\n",
      "  %253 = Reshape(%233, %252)\n",
      "  %254 = Transpose[perm = [0, 2, 1, 3]](%253)\n",
      "  %255 = Constant[value = <Scalar Tensor []>]()\n",
      "  %256 = Shape(%236)\n",
      "  %257 = Gather[axis = 0](%256, %255)\n",
      "  %258 = Constant[value = <Scalar Tensor []>]()\n",
      "  %259 = Shape(%236)\n",
      "  %260 = Gather[axis = 0](%259, %258)\n",
      "  %261 = Constant[value = <Scalar Tensor []>]()\n",
      "  %262 = Constant[value = <Scalar Tensor []>]()\n",
      "  %263 = Unsqueeze[axes = [0]](%257)\n",
      "  %264 = Unsqueeze[axes = [0]](%260)\n",
      "  %265 = Unsqueeze[axes = [0]](%261)\n",
      "  %266 = Unsqueeze[axes = [0]](%262)\n",
      "  %267 = Concat[axis = 0](%263, %264, %265, %266)\n",
      "  %268 = Reshape(%236, %267)\n",
      "  %269 = Constant[value = <Scalar Tensor []>]()\n",
      "  %270 = Shape(%239)\n",
      "  %271 = Gather[axis = 0](%270, %269)\n",
      "  %272 = Constant[value = <Scalar Tensor []>]()\n",
      "  %273 = Shape(%239)\n",
      "  %274 = Gather[axis = 0](%273, %272)\n",
      "  %275 = Constant[value = <Scalar Tensor []>]()\n",
      "  %276 = Constant[value = <Scalar Tensor []>]()\n",
      "  %277 = Unsqueeze[axes = [0]](%271)\n",
      "  %278 = Unsqueeze[axes = [0]](%274)\n",
      "  %279 = Unsqueeze[axes = [0]](%275)\n",
      "  %280 = Unsqueeze[axes = [0]](%276)\n",
      "  %281 = Concat[axis = 0](%277, %278, %279, %280)\n",
      "  %282 = Reshape(%239, %281)\n",
      "  %283 = Transpose[perm = [0, 2, 1, 3]](%282)\n",
      "  %284 = Transpose[perm = [0, 2, 3, 1]](%268)\n",
      "  %285 = MatMul(%254, %284)\n",
      "  %286 = Constant[value = <Scalar Tensor []>]()\n",
      "  %287 = Div(%285, %286)\n",
      "  %288 = Add(%287, %209)\n",
      "  %289 = Softmax[axis = 3](%288)\n",
      "  %290 = MatMul(%289, %283)\n",
      "  %291 = Transpose[perm = [0, 2, 1, 3]](%290)\n",
      "  %292 = Constant[value = <Scalar Tensor []>]()\n",
      "  %293 = Shape(%291)\n",
      "  %294 = Gather[axis = 0](%293, %292)\n",
      "  %295 = Constant[value = <Scalar Tensor []>]()\n",
      "  %296 = Shape(%291)\n",
      "  %297 = Gather[axis = 0](%296, %295)\n",
      "  %298 = Constant[value = <Scalar Tensor []>]()\n",
      "  %299 = Unsqueeze[axes = [0]](%294)\n",
      "  %300 = Unsqueeze[axes = [0]](%297)\n",
      "  %301 = Unsqueeze[axes = [0]](%298)\n",
      "  %302 = Concat[axis = 0](%299, %300, %301)\n",
      "  %303 = Reshape(%291, %302)\n",
      "  %304 = Transpose[perm = [1, 0]](%encoder.layer.0.attention.output.dense.weight)\n",
      "  %305 = MatMul(%303, %304)\n",
      "  %306 = Add(%305, %encoder.layer.0.attention.output.dense.bias)\n",
      "  %307 = Add(%306, %230)\n",
      "  %308 = ReduceMean[axes = [-1]](%307)\n",
      "  %309 = Sub(%307, %308)\n",
      "  %310 = Constant[value = <Scalar Tensor []>]()\n",
      "  %311 = Pow(%309, %310)\n",
      "  %312 = ReduceMean[axes = [-1]](%311)\n",
      "  %313 = Constant[value = <Scalar Tensor []>]()\n",
      "  %314 = Add(%312, %313)\n",
      "  %315 = Sqrt(%314)\n",
      "  %316 = Div(%309, %315)\n",
      "  %317 = Mul(%316, %encoder.layer.0.attention.output.LayerNorm.weight)\n",
      "  %318 = Add(%317, %encoder.layer.0.attention.output.LayerNorm.bias)\n",
      "  %319 = Transpose[perm = [1, 0]](%encoder.layer.0.intermediate.dense.weight)\n",
      "  %320 = MatMul(%318, %319)\n",
      "  %321 = Add(%320, %encoder.layer.0.intermediate.dense.bias)\n",
      "  %322 = Constant[value = <Scalar Tensor []>]()\n",
      "  %323 = Mul(%321, %322)\n",
      "  %324 = Constant[value = <Scalar Tensor []>]()\n",
      "  %325 = Div(%321, %324)\n",
      "  %326 = Erf(%325)\n",
      "  %327 = Constant[value = <Scalar Tensor []>]()\n",
      "  %328 = Add(%326, %327)\n",
      "  %329 = Mul(%323, %328)\n",
      "  %330 = Transpose[perm = [1, 0]](%encoder.layer.0.output.dense.weight)\n",
      "  %331 = MatMul(%329, %330)\n",
      "  %332 = Add(%331, %encoder.layer.0.output.dense.bias)\n",
      "  %333 = Add(%332, %318)\n",
      "  %334 = ReduceMean[axes = [-1]](%333)\n",
      "  %335 = Sub(%333, %334)\n",
      "  %336 = Constant[value = <Scalar Tensor []>]()\n",
      "  %337 = Pow(%335, %336)\n",
      "  %338 = ReduceMean[axes = [-1]](%337)\n",
      "  %339 = Constant[value = <Scalar Tensor []>]()\n",
      "  %340 = Add(%338, %339)\n",
      "  %341 = Sqrt(%340)\n",
      "  %342 = Div(%335, %341)\n",
      "  %343 = Mul(%342, %encoder.layer.0.output.LayerNorm.weight)\n",
      "  %344 = Add(%343, %encoder.layer.0.output.LayerNorm.bias)\n",
      "  %345 = Transpose[perm = [1, 0]](%encoder.layer.1.attention.self.query.weight)\n",
      "  %346 = MatMul(%344, %345)\n",
      "  %347 = Add(%346, %encoder.layer.1.attention.self.query.bias)\n",
      "  %348 = Transpose[perm = [1, 0]](%encoder.layer.1.attention.self.key.weight)\n",
      "  %349 = MatMul(%344, %348)\n",
      "  %350 = Add(%349, %encoder.layer.1.attention.self.key.bias)\n",
      "  %351 = Transpose[perm = [1, 0]](%encoder.layer.1.attention.self.value.weight)\n",
      "  %352 = MatMul(%344, %351)\n",
      "  %353 = Add(%352, %encoder.layer.1.attention.self.value.bias)\n",
      "  %354 = Constant[value = <Scalar Tensor []>]()\n",
      "  %355 = Shape(%347)\n",
      "  %356 = Gather[axis = 0](%355, %354)\n",
      "  %357 = Constant[value = <Scalar Tensor []>]()\n",
      "  %358 = Shape(%347)\n",
      "  %359 = Gather[axis = 0](%358, %357)\n",
      "  %360 = Constant[value = <Scalar Tensor []>]()\n",
      "  %361 = Constant[value = <Scalar Tensor []>]()\n",
      "  %362 = Unsqueeze[axes = [0]](%356)\n",
      "  %363 = Unsqueeze[axes = [0]](%359)\n",
      "  %364 = Unsqueeze[axes = [0]](%360)\n",
      "  %365 = Unsqueeze[axes = [0]](%361)\n",
      "  %366 = Concat[axis = 0](%362, %363, %364, %365)\n",
      "  %367 = Reshape(%347, %366)\n",
      "  %368 = Transpose[perm = [0, 2, 1, 3]](%367)\n",
      "  %369 = Constant[value = <Scalar Tensor []>]()\n",
      "  %370 = Shape(%350)\n",
      "  %371 = Gather[axis = 0](%370, %369)\n",
      "  %372 = Constant[value = <Scalar Tensor []>]()\n",
      "  %373 = Shape(%350)\n",
      "  %374 = Gather[axis = 0](%373, %372)\n",
      "  %375 = Constant[value = <Scalar Tensor []>]()\n",
      "  %376 = Constant[value = <Scalar Tensor []>]()\n",
      "  %377 = Unsqueeze[axes = [0]](%371)\n",
      "  %378 = Unsqueeze[axes = [0]](%374)\n",
      "  %379 = Unsqueeze[axes = [0]](%375)\n",
      "  %380 = Unsqueeze[axes = [0]](%376)\n",
      "  %381 = Concat[axis = 0](%377, %378, %379, %380)\n",
      "  %382 = Reshape(%350, %381)\n",
      "  %383 = Constant[value = <Scalar Tensor []>]()\n",
      "  %384 = Shape(%353)\n",
      "  %385 = Gather[axis = 0](%384, %383)\n",
      "  %386 = Constant[value = <Scalar Tensor []>]()\n",
      "  %387 = Shape(%353)\n",
      "  %388 = Gather[axis = 0](%387, %386)\n",
      "  %389 = Constant[value = <Scalar Tensor []>]()\n",
      "  %390 = Constant[value = <Scalar Tensor []>]()\n",
      "  %391 = Unsqueeze[axes = [0]](%385)\n",
      "  %392 = Unsqueeze[axes = [0]](%388)\n",
      "  %393 = Unsqueeze[axes = [0]](%389)\n",
      "  %394 = Unsqueeze[axes = [0]](%390)\n",
      "  %395 = Concat[axis = 0](%391, %392, %393, %394)\n",
      "  %396 = Reshape(%353, %395)\n",
      "  %397 = Transpose[perm = [0, 2, 1, 3]](%396)\n",
      "  %398 = Transpose[perm = [0, 2, 3, 1]](%382)\n",
      "  %399 = MatMul(%368, %398)\n",
      "  %400 = Constant[value = <Scalar Tensor []>]()\n",
      "  %401 = Div(%399, %400)\n",
      "  %402 = Add(%401, %209)\n",
      "  %403 = Softmax[axis = 3](%402)\n",
      "  %404 = MatMul(%403, %397)\n",
      "  %405 = Transpose[perm = [0, 2, 1, 3]](%404)\n",
      "  %406 = Constant[value = <Scalar Tensor []>]()\n",
      "  %407 = Shape(%405)\n",
      "  %408 = Gather[axis = 0](%407, %406)\n",
      "  %409 = Constant[value = <Scalar Tensor []>]()\n",
      "  %410 = Shape(%405)\n",
      "  %411 = Gather[axis = 0](%410, %409)\n",
      "  %412 = Constant[value = <Scalar Tensor []>]()\n",
      "  %413 = Unsqueeze[axes = [0]](%408)\n",
      "  %414 = Unsqueeze[axes = [0]](%411)\n",
      "  %415 = Unsqueeze[axes = [0]](%412)\n",
      "  %416 = Concat[axis = 0](%413, %414, %415)\n",
      "  %417 = Reshape(%405, %416)\n",
      "  %418 = Transpose[perm = [1, 0]](%encoder.layer.1.attention.output.dense.weight)\n",
      "  %419 = MatMul(%417, %418)\n",
      "  %420 = Add(%419, %encoder.layer.1.attention.output.dense.bias)\n",
      "  %421 = Add(%420, %344)\n",
      "  %422 = ReduceMean[axes = [-1]](%421)\n",
      "  %423 = Sub(%421, %422)\n",
      "  %424 = Constant[value = <Scalar Tensor []>]()\n",
      "  %425 = Pow(%423, %424)\n",
      "  %426 = ReduceMean[axes = [-1]](%425)\n",
      "  %427 = Constant[value = <Scalar Tensor []>]()\n",
      "  %428 = Add(%426, %427)\n",
      "  %429 = Sqrt(%428)\n",
      "  %430 = Div(%423, %429)\n",
      "  %431 = Mul(%430, %encoder.layer.1.attention.output.LayerNorm.weight)\n",
      "  %432 = Add(%431, %encoder.layer.1.attention.output.LayerNorm.bias)\n",
      "  %433 = Transpose[perm = [1, 0]](%encoder.layer.1.intermediate.dense.weight)\n",
      "  %434 = MatMul(%432, %433)\n",
      "  %435 = Add(%434, %encoder.layer.1.intermediate.dense.bias)\n",
      "  %436 = Constant[value = <Scalar Tensor []>]()\n",
      "  %437 = Mul(%435, %436)\n",
      "  %438 = Constant[value = <Scalar Tensor []>]()\n",
      "  %439 = Div(%435, %438)\n",
      "  %440 = Erf(%439)\n",
      "  %441 = Constant[value = <Scalar Tensor []>]()\n",
      "  %442 = Add(%440, %441)\n",
      "  %443 = Mul(%437, %442)\n",
      "  %444 = Transpose[perm = [1, 0]](%encoder.layer.1.output.dense.weight)\n",
      "  %445 = MatMul(%443, %444)\n",
      "  %446 = Add(%445, %encoder.layer.1.output.dense.bias)\n",
      "  %447 = Add(%446, %432)\n",
      "  %448 = ReduceMean[axes = [-1]](%447)\n",
      "  %449 = Sub(%447, %448)\n",
      "  %450 = Constant[value = <Scalar Tensor []>]()\n",
      "  %451 = Pow(%449, %450)\n",
      "  %452 = ReduceMean[axes = [-1]](%451)\n",
      "  %453 = Constant[value = <Scalar Tensor []>]()\n",
      "  %454 = Add(%452, %453)\n",
      "  %455 = Sqrt(%454)\n",
      "  %456 = Div(%449, %455)\n",
      "  %457 = Mul(%456, %encoder.layer.1.output.LayerNorm.weight)\n",
      "  %458 = Add(%457, %encoder.layer.1.output.LayerNorm.bias)\n",
      "  %459 = Transpose[perm = [1, 0]](%encoder.layer.2.attention.self.query.weight)\n",
      "  %460 = MatMul(%458, %459)\n",
      "  %461 = Add(%460, %encoder.layer.2.attention.self.query.bias)\n",
      "  %462 = Transpose[perm = [1, 0]](%encoder.layer.2.attention.self.key.weight)\n",
      "  %463 = MatMul(%458, %462)\n",
      "  %464 = Add(%463, %encoder.layer.2.attention.self.key.bias)\n",
      "  %465 = Transpose[perm = [1, 0]](%encoder.layer.2.attention.self.value.weight)\n",
      "  %466 = MatMul(%458, %465)\n",
      "  %467 = Add(%466, %encoder.layer.2.attention.self.value.bias)\n",
      "  %468 = Constant[value = <Scalar Tensor []>]()\n",
      "  %469 = Shape(%461)\n",
      "  %470 = Gather[axis = 0](%469, %468)\n",
      "  %471 = Constant[value = <Scalar Tensor []>]()\n",
      "  %472 = Shape(%461)\n",
      "  %473 = Gather[axis = 0](%472, %471)\n",
      "  %474 = Constant[value = <Scalar Tensor []>]()\n",
      "  %475 = Constant[value = <Scalar Tensor []>]()\n",
      "  %476 = Unsqueeze[axes = [0]](%470)\n",
      "  %477 = Unsqueeze[axes = [0]](%473)\n",
      "  %478 = Unsqueeze[axes = [0]](%474)\n",
      "  %479 = Unsqueeze[axes = [0]](%475)\n",
      "  %480 = Concat[axis = 0](%476, %477, %478, %479)\n",
      "  %481 = Reshape(%461, %480)\n",
      "  %482 = Transpose[perm = [0, 2, 1, 3]](%481)\n",
      "  %483 = Constant[value = <Scalar Tensor []>]()\n",
      "  %484 = Shape(%464)\n",
      "  %485 = Gather[axis = 0](%484, %483)\n",
      "  %486 = Constant[value = <Scalar Tensor []>]()\n",
      "  %487 = Shape(%464)\n",
      "  %488 = Gather[axis = 0](%487, %486)\n",
      "  %489 = Constant[value = <Scalar Tensor []>]()\n",
      "  %490 = Constant[value = <Scalar Tensor []>]()\n",
      "  %491 = Unsqueeze[axes = [0]](%485)\n",
      "  %492 = Unsqueeze[axes = [0]](%488)\n",
      "  %493 = Unsqueeze[axes = [0]](%489)\n",
      "  %494 = Unsqueeze[axes = [0]](%490)\n",
      "  %495 = Concat[axis = 0](%491, %492, %493, %494)\n",
      "  %496 = Reshape(%464, %495)\n",
      "  %497 = Constant[value = <Scalar Tensor []>]()\n",
      "  %498 = Shape(%467)\n",
      "  %499 = Gather[axis = 0](%498, %497)\n",
      "  %500 = Constant[value = <Scalar Tensor []>]()\n",
      "  %501 = Shape(%467)\n",
      "  %502 = Gather[axis = 0](%501, %500)\n",
      "  %503 = Constant[value = <Scalar Tensor []>]()\n",
      "  %504 = Constant[value = <Scalar Tensor []>]()\n",
      "  %505 = Unsqueeze[axes = [0]](%499)\n",
      "  %506 = Unsqueeze[axes = [0]](%502)\n",
      "  %507 = Unsqueeze[axes = [0]](%503)\n",
      "  %508 = Unsqueeze[axes = [0]](%504)\n",
      "  %509 = Concat[axis = 0](%505, %506, %507, %508)\n",
      "  %510 = Reshape(%467, %509)\n",
      "  %511 = Transpose[perm = [0, 2, 1, 3]](%510)\n",
      "  %512 = Transpose[perm = [0, 2, 3, 1]](%496)\n",
      "  %513 = MatMul(%482, %512)\n",
      "  %514 = Constant[value = <Scalar Tensor []>]()\n",
      "  %515 = Div(%513, %514)\n",
      "  %516 = Add(%515, %209)\n",
      "  %517 = Softmax[axis = 3](%516)\n",
      "  %518 = MatMul(%517, %511)\n",
      "  %519 = Transpose[perm = [0, 2, 1, 3]](%518)\n",
      "  %520 = Constant[value = <Scalar Tensor []>]()\n",
      "  %521 = Shape(%519)\n",
      "  %522 = Gather[axis = 0](%521, %520)\n",
      "  %523 = Constant[value = <Scalar Tensor []>]()\n",
      "  %524 = Shape(%519)\n",
      "  %525 = Gather[axis = 0](%524, %523)\n",
      "  %526 = Constant[value = <Scalar Tensor []>]()\n",
      "  %527 = Unsqueeze[axes = [0]](%522)\n",
      "  %528 = Unsqueeze[axes = [0]](%525)\n",
      "  %529 = Unsqueeze[axes = [0]](%526)\n",
      "  %530 = Concat[axis = 0](%527, %528, %529)\n",
      "  %531 = Reshape(%519, %530)\n",
      "  %532 = Transpose[perm = [1, 0]](%encoder.layer.2.attention.output.dense.weight)\n",
      "  %533 = MatMul(%531, %532)\n",
      "  %534 = Add(%533, %encoder.layer.2.attention.output.dense.bias)\n",
      "  %535 = Add(%534, %458)\n",
      "  %536 = ReduceMean[axes = [-1]](%535)\n",
      "  %537 = Sub(%535, %536)\n",
      "  %538 = Constant[value = <Scalar Tensor []>]()\n",
      "  %539 = Pow(%537, %538)\n",
      "  %540 = ReduceMean[axes = [-1]](%539)\n",
      "  %541 = Constant[value = <Scalar Tensor []>]()\n",
      "  %542 = Add(%540, %541)\n",
      "  %543 = Sqrt(%542)\n",
      "  %544 = Div(%537, %543)\n",
      "  %545 = Mul(%544, %encoder.layer.2.attention.output.LayerNorm.weight)\n",
      "  %546 = Add(%545, %encoder.layer.2.attention.output.LayerNorm.bias)\n",
      "  %547 = Transpose[perm = [1, 0]](%encoder.layer.2.intermediate.dense.weight)\n",
      "  %548 = MatMul(%546, %547)\n",
      "  %549 = Add(%548, %encoder.layer.2.intermediate.dense.bias)\n",
      "  %550 = Constant[value = <Scalar Tensor []>]()\n",
      "  %551 = Mul(%549, %550)\n",
      "  %552 = Constant[value = <Scalar Tensor []>]()\n",
      "  %553 = Div(%549, %552)\n",
      "  %554 = Erf(%553)\n",
      "  %555 = Constant[value = <Scalar Tensor []>]()\n",
      "  %556 = Add(%554, %555)\n",
      "  %557 = Mul(%551, %556)\n",
      "  %558 = Transpose[perm = [1, 0]](%encoder.layer.2.output.dense.weight)\n",
      "  %559 = MatMul(%557, %558)\n",
      "  %560 = Add(%559, %encoder.layer.2.output.dense.bias)\n",
      "  %561 = Add(%560, %546)\n",
      "  %562 = ReduceMean[axes = [-1]](%561)\n",
      "  %563 = Sub(%561, %562)\n",
      "  %564 = Constant[value = <Scalar Tensor []>]()\n",
      "  %565 = Pow(%563, %564)\n",
      "  %566 = ReduceMean[axes = [-1]](%565)\n",
      "  %567 = Constant[value = <Scalar Tensor []>]()\n",
      "  %568 = Add(%566, %567)\n",
      "  %569 = Sqrt(%568)\n",
      "  %570 = Div(%563, %569)\n",
      "  %571 = Mul(%570, %encoder.layer.2.output.LayerNorm.weight)\n",
      "  %572 = Add(%571, %encoder.layer.2.output.LayerNorm.bias)\n",
      "  %573 = Transpose[perm = [1, 0]](%encoder.layer.3.attention.self.query.weight)\n",
      "  %574 = MatMul(%572, %573)\n",
      "  %575 = Add(%574, %encoder.layer.3.attention.self.query.bias)\n",
      "  %576 = Transpose[perm = [1, 0]](%encoder.layer.3.attention.self.key.weight)\n",
      "  %577 = MatMul(%572, %576)\n",
      "  %578 = Add(%577, %encoder.layer.3.attention.self.key.bias)\n",
      "  %579 = Transpose[perm = [1, 0]](%encoder.layer.3.attention.self.value.weight)\n",
      "  %580 = MatMul(%572, %579)\n",
      "  %581 = Add(%580, %encoder.layer.3.attention.self.value.bias)\n",
      "  %582 = Constant[value = <Scalar Tensor []>]()\n",
      "  %583 = Shape(%575)\n",
      "  %584 = Gather[axis = 0](%583, %582)\n",
      "  %585 = Constant[value = <Scalar Tensor []>]()\n",
      "  %586 = Shape(%575)\n",
      "  %587 = Gather[axis = 0](%586, %585)\n",
      "  %588 = Constant[value = <Scalar Tensor []>]()\n",
      "  %589 = Constant[value = <Scalar Tensor []>]()\n",
      "  %590 = Unsqueeze[axes = [0]](%584)\n",
      "  %591 = Unsqueeze[axes = [0]](%587)\n",
      "  %592 = Unsqueeze[axes = [0]](%588)\n",
      "  %593 = Unsqueeze[axes = [0]](%589)\n",
      "  %594 = Concat[axis = 0](%590, %591, %592, %593)\n",
      "  %595 = Reshape(%575, %594)\n",
      "  %596 = Transpose[perm = [0, 2, 1, 3]](%595)\n",
      "  %597 = Constant[value = <Scalar Tensor []>]()\n",
      "  %598 = Shape(%578)\n",
      "  %599 = Gather[axis = 0](%598, %597)\n",
      "  %600 = Constant[value = <Scalar Tensor []>]()\n",
      "  %601 = Shape(%578)\n",
      "  %602 = Gather[axis = 0](%601, %600)\n",
      "  %603 = Constant[value = <Scalar Tensor []>]()\n",
      "  %604 = Constant[value = <Scalar Tensor []>]()\n",
      "  %605 = Unsqueeze[axes = [0]](%599)\n",
      "  %606 = Unsqueeze[axes = [0]](%602)\n",
      "  %607 = Unsqueeze[axes = [0]](%603)\n",
      "  %608 = Unsqueeze[axes = [0]](%604)\n",
      "  %609 = Concat[axis = 0](%605, %606, %607, %608)\n",
      "  %610 = Reshape(%578, %609)\n",
      "  %611 = Constant[value = <Scalar Tensor []>]()\n",
      "  %612 = Shape(%581)\n",
      "  %613 = Gather[axis = 0](%612, %611)\n",
      "  %614 = Constant[value = <Scalar Tensor []>]()\n",
      "  %615 = Shape(%581)\n",
      "  %616 = Gather[axis = 0](%615, %614)\n",
      "  %617 = Constant[value = <Scalar Tensor []>]()\n",
      "  %618 = Constant[value = <Scalar Tensor []>]()\n",
      "  %619 = Unsqueeze[axes = [0]](%613)\n",
      "  %620 = Unsqueeze[axes = [0]](%616)\n",
      "  %621 = Unsqueeze[axes = [0]](%617)\n",
      "  %622 = Unsqueeze[axes = [0]](%618)\n",
      "  %623 = Concat[axis = 0](%619, %620, %621, %622)\n",
      "  %624 = Reshape(%581, %623)\n",
      "  %625 = Transpose[perm = [0, 2, 1, 3]](%624)\n",
      "  %626 = Transpose[perm = [0, 2, 3, 1]](%610)\n",
      "  %627 = MatMul(%596, %626)\n",
      "  %628 = Constant[value = <Scalar Tensor []>]()\n",
      "  %629 = Div(%627, %628)\n",
      "  %630 = Add(%629, %209)\n",
      "  %631 = Softmax[axis = 3](%630)\n",
      "  %632 = MatMul(%631, %625)\n",
      "  %633 = Transpose[perm = [0, 2, 1, 3]](%632)\n",
      "  %634 = Constant[value = <Scalar Tensor []>]()\n",
      "  %635 = Shape(%633)\n",
      "  %636 = Gather[axis = 0](%635, %634)\n",
      "  %637 = Constant[value = <Scalar Tensor []>]()\n",
      "  %638 = Shape(%633)\n",
      "  %639 = Gather[axis = 0](%638, %637)\n",
      "  %640 = Constant[value = <Scalar Tensor []>]()\n",
      "  %641 = Unsqueeze[axes = [0]](%636)\n",
      "  %642 = Unsqueeze[axes = [0]](%639)\n",
      "  %643 = Unsqueeze[axes = [0]](%640)\n",
      "  %644 = Concat[axis = 0](%641, %642, %643)\n",
      "  %645 = Reshape(%633, %644)\n",
      "  %646 = Transpose[perm = [1, 0]](%encoder.layer.3.attention.output.dense.weight)\n",
      "  %647 = MatMul(%645, %646)\n",
      "  %648 = Add(%647, %encoder.layer.3.attention.output.dense.bias)\n",
      "  %649 = Add(%648, %572)\n",
      "  %650 = ReduceMean[axes = [-1]](%649)\n",
      "  %651 = Sub(%649, %650)\n",
      "  %652 = Constant[value = <Scalar Tensor []>]()\n",
      "  %653 = Pow(%651, %652)\n",
      "  %654 = ReduceMean[axes = [-1]](%653)\n",
      "  %655 = Constant[value = <Scalar Tensor []>]()\n",
      "  %656 = Add(%654, %655)\n",
      "  %657 = Sqrt(%656)\n",
      "  %658 = Div(%651, %657)\n",
      "  %659 = Mul(%658, %encoder.layer.3.attention.output.LayerNorm.weight)\n",
      "  %660 = Add(%659, %encoder.layer.3.attention.output.LayerNorm.bias)\n",
      "  %661 = Transpose[perm = [1, 0]](%encoder.layer.3.intermediate.dense.weight)\n",
      "  %662 = MatMul(%660, %661)\n",
      "  %663 = Add(%662, %encoder.layer.3.intermediate.dense.bias)\n",
      "  %664 = Constant[value = <Scalar Tensor []>]()\n",
      "  %665 = Mul(%663, %664)\n",
      "  %666 = Constant[value = <Scalar Tensor []>]()\n",
      "  %667 = Div(%663, %666)\n",
      "  %668 = Erf(%667)\n",
      "  %669 = Constant[value = <Scalar Tensor []>]()\n",
      "  %670 = Add(%668, %669)\n",
      "  %671 = Mul(%665, %670)\n",
      "  %672 = Transpose[perm = [1, 0]](%encoder.layer.3.output.dense.weight)\n",
      "  %673 = MatMul(%671, %672)\n",
      "  %674 = Add(%673, %encoder.layer.3.output.dense.bias)\n",
      "  %675 = Add(%674, %660)\n",
      "  %676 = ReduceMean[axes = [-1]](%675)\n",
      "  %677 = Sub(%675, %676)\n",
      "  %678 = Constant[value = <Scalar Tensor []>]()\n",
      "  %679 = Pow(%677, %678)\n",
      "  %680 = ReduceMean[axes = [-1]](%679)\n",
      "  %681 = Constant[value = <Scalar Tensor []>]()\n",
      "  %682 = Add(%680, %681)\n",
      "  %683 = Sqrt(%682)\n",
      "  %684 = Div(%677, %683)\n",
      "  %685 = Mul(%684, %encoder.layer.3.output.LayerNorm.weight)\n",
      "  %686 = Add(%685, %encoder.layer.3.output.LayerNorm.bias)\n",
      "  %687 = Transpose[perm = [1, 0]](%encoder.layer.4.attention.self.query.weight)\n",
      "  %688 = MatMul(%686, %687)\n",
      "  %689 = Add(%688, %encoder.layer.4.attention.self.query.bias)\n",
      "  %690 = Transpose[perm = [1, 0]](%encoder.layer.4.attention.self.key.weight)\n",
      "  %691 = MatMul(%686, %690)\n",
      "  %692 = Add(%691, %encoder.layer.4.attention.self.key.bias)\n",
      "  %693 = Transpose[perm = [1, 0]](%encoder.layer.4.attention.self.value.weight)\n",
      "  %694 = MatMul(%686, %693)\n",
      "  %695 = Add(%694, %encoder.layer.4.attention.self.value.bias)\n",
      "  %696 = Constant[value = <Scalar Tensor []>]()\n",
      "  %697 = Shape(%689)\n",
      "  %698 = Gather[axis = 0](%697, %696)\n",
      "  %699 = Constant[value = <Scalar Tensor []>]()\n",
      "  %700 = Shape(%689)\n",
      "  %701 = Gather[axis = 0](%700, %699)\n",
      "  %702 = Constant[value = <Scalar Tensor []>]()\n",
      "  %703 = Constant[value = <Scalar Tensor []>]()\n",
      "  %704 = Unsqueeze[axes = [0]](%698)\n",
      "  %705 = Unsqueeze[axes = [0]](%701)\n",
      "  %706 = Unsqueeze[axes = [0]](%702)\n",
      "  %707 = Unsqueeze[axes = [0]](%703)\n",
      "  %708 = Concat[axis = 0](%704, %705, %706, %707)\n",
      "  %709 = Reshape(%689, %708)\n",
      "  %710 = Transpose[perm = [0, 2, 1, 3]](%709)\n",
      "  %711 = Constant[value = <Scalar Tensor []>]()\n",
      "  %712 = Shape(%692)\n",
      "  %713 = Gather[axis = 0](%712, %711)\n",
      "  %714 = Constant[value = <Scalar Tensor []>]()\n",
      "  %715 = Shape(%692)\n",
      "  %716 = Gather[axis = 0](%715, %714)\n",
      "  %717 = Constant[value = <Scalar Tensor []>]()\n",
      "  %718 = Constant[value = <Scalar Tensor []>]()\n",
      "  %719 = Unsqueeze[axes = [0]](%713)\n",
      "  %720 = Unsqueeze[axes = [0]](%716)\n",
      "  %721 = Unsqueeze[axes = [0]](%717)\n",
      "  %722 = Unsqueeze[axes = [0]](%718)\n",
      "  %723 = Concat[axis = 0](%719, %720, %721, %722)\n",
      "  %724 = Reshape(%692, %723)\n",
      "  %725 = Constant[value = <Scalar Tensor []>]()\n",
      "  %726 = Shape(%695)\n",
      "  %727 = Gather[axis = 0](%726, %725)\n",
      "  %728 = Constant[value = <Scalar Tensor []>]()\n",
      "  %729 = Shape(%695)\n",
      "  %730 = Gather[axis = 0](%729, %728)\n",
      "  %731 = Constant[value = <Scalar Tensor []>]()\n",
      "  %732 = Constant[value = <Scalar Tensor []>]()\n",
      "  %733 = Unsqueeze[axes = [0]](%727)\n",
      "  %734 = Unsqueeze[axes = [0]](%730)\n",
      "  %735 = Unsqueeze[axes = [0]](%731)\n",
      "  %736 = Unsqueeze[axes = [0]](%732)\n",
      "  %737 = Concat[axis = 0](%733, %734, %735, %736)\n",
      "  %738 = Reshape(%695, %737)\n",
      "  %739 = Transpose[perm = [0, 2, 1, 3]](%738)\n",
      "  %740 = Transpose[perm = [0, 2, 3, 1]](%724)\n",
      "  %741 = MatMul(%710, %740)\n",
      "  %742 = Constant[value = <Scalar Tensor []>]()\n",
      "  %743 = Div(%741, %742)\n",
      "  %744 = Add(%743, %209)\n",
      "  %745 = Softmax[axis = 3](%744)\n",
      "  %746 = MatMul(%745, %739)\n",
      "  %747 = Transpose[perm = [0, 2, 1, 3]](%746)\n",
      "  %748 = Constant[value = <Scalar Tensor []>]()\n",
      "  %749 = Shape(%747)\n",
      "  %750 = Gather[axis = 0](%749, %748)\n",
      "  %751 = Constant[value = <Scalar Tensor []>]()\n",
      "  %752 = Shape(%747)\n",
      "  %753 = Gather[axis = 0](%752, %751)\n",
      "  %754 = Constant[value = <Scalar Tensor []>]()\n",
      "  %755 = Unsqueeze[axes = [0]](%750)\n",
      "  %756 = Unsqueeze[axes = [0]](%753)\n",
      "  %757 = Unsqueeze[axes = [0]](%754)\n",
      "  %758 = Concat[axis = 0](%755, %756, %757)\n",
      "  %759 = Reshape(%747, %758)\n",
      "  %760 = Transpose[perm = [1, 0]](%encoder.layer.4.attention.output.dense.weight)\n",
      "  %761 = MatMul(%759, %760)\n",
      "  %762 = Add(%761, %encoder.layer.4.attention.output.dense.bias)\n",
      "  %763 = Add(%762, %686)\n",
      "  %764 = ReduceMean[axes = [-1]](%763)\n",
      "  %765 = Sub(%763, %764)\n",
      "  %766 = Constant[value = <Scalar Tensor []>]()\n",
      "  %767 = Pow(%765, %766)\n",
      "  %768 = ReduceMean[axes = [-1]](%767)\n",
      "  %769 = Constant[value = <Scalar Tensor []>]()\n",
      "  %770 = Add(%768, %769)\n",
      "  %771 = Sqrt(%770)\n",
      "  %772 = Div(%765, %771)\n",
      "  %773 = Mul(%772, %encoder.layer.4.attention.output.LayerNorm.weight)\n",
      "  %774 = Add(%773, %encoder.layer.4.attention.output.LayerNorm.bias)\n",
      "  %775 = Transpose[perm = [1, 0]](%encoder.layer.4.intermediate.dense.weight)\n",
      "  %776 = MatMul(%774, %775)\n",
      "  %777 = Add(%776, %encoder.layer.4.intermediate.dense.bias)\n",
      "  %778 = Constant[value = <Scalar Tensor []>]()\n",
      "  %779 = Mul(%777, %778)\n",
      "  %780 = Constant[value = <Scalar Tensor []>]()\n",
      "  %781 = Div(%777, %780)\n",
      "  %782 = Erf(%781)\n",
      "  %783 = Constant[value = <Scalar Tensor []>]()\n",
      "  %784 = Add(%782, %783)\n",
      "  %785 = Mul(%779, %784)\n",
      "  %786 = Transpose[perm = [1, 0]](%encoder.layer.4.output.dense.weight)\n",
      "  %787 = MatMul(%785, %786)\n",
      "  %788 = Add(%787, %encoder.layer.4.output.dense.bias)\n",
      "  %789 = Add(%788, %774)\n",
      "  %790 = ReduceMean[axes = [-1]](%789)\n",
      "  %791 = Sub(%789, %790)\n",
      "  %792 = Constant[value = <Scalar Tensor []>]()\n",
      "  %793 = Pow(%791, %792)\n",
      "  %794 = ReduceMean[axes = [-1]](%793)\n",
      "  %795 = Constant[value = <Scalar Tensor []>]()\n",
      "  %796 = Add(%794, %795)\n",
      "  %797 = Sqrt(%796)\n",
      "  %798 = Div(%791, %797)\n",
      "  %799 = Mul(%798, %encoder.layer.4.output.LayerNorm.weight)\n",
      "  %800 = Add(%799, %encoder.layer.4.output.LayerNorm.bias)\n",
      "  %801 = Transpose[perm = [1, 0]](%encoder.layer.5.attention.self.query.weight)\n",
      "  %802 = MatMul(%800, %801)\n",
      "  %803 = Add(%802, %encoder.layer.5.attention.self.query.bias)\n",
      "  %804 = Transpose[perm = [1, 0]](%encoder.layer.5.attention.self.key.weight)\n",
      "  %805 = MatMul(%800, %804)\n",
      "  %806 = Add(%805, %encoder.layer.5.attention.self.key.bias)\n",
      "  %807 = Transpose[perm = [1, 0]](%encoder.layer.5.attention.self.value.weight)\n",
      "  %808 = MatMul(%800, %807)\n",
      "  %809 = Add(%808, %encoder.layer.5.attention.self.value.bias)\n",
      "  %810 = Constant[value = <Scalar Tensor []>]()\n",
      "  %811 = Shape(%803)\n",
      "  %812 = Gather[axis = 0](%811, %810)\n",
      "  %813 = Constant[value = <Scalar Tensor []>]()\n",
      "  %814 = Shape(%803)\n",
      "  %815 = Gather[axis = 0](%814, %813)\n",
      "  %816 = Constant[value = <Scalar Tensor []>]()\n",
      "  %817 = Constant[value = <Scalar Tensor []>]()\n",
      "  %818 = Unsqueeze[axes = [0]](%812)\n",
      "  %819 = Unsqueeze[axes = [0]](%815)\n",
      "  %820 = Unsqueeze[axes = [0]](%816)\n",
      "  %821 = Unsqueeze[axes = [0]](%817)\n",
      "  %822 = Concat[axis = 0](%818, %819, %820, %821)\n",
      "  %823 = Reshape(%803, %822)\n",
      "  %824 = Transpose[perm = [0, 2, 1, 3]](%823)\n",
      "  %825 = Constant[value = <Scalar Tensor []>]()\n",
      "  %826 = Shape(%806)\n",
      "  %827 = Gather[axis = 0](%826, %825)\n",
      "  %828 = Constant[value = <Scalar Tensor []>]()\n",
      "  %829 = Shape(%806)\n",
      "  %830 = Gather[axis = 0](%829, %828)\n",
      "  %831 = Constant[value = <Scalar Tensor []>]()\n",
      "  %832 = Constant[value = <Scalar Tensor []>]()\n",
      "  %833 = Unsqueeze[axes = [0]](%827)\n",
      "  %834 = Unsqueeze[axes = [0]](%830)\n",
      "  %835 = Unsqueeze[axes = [0]](%831)\n",
      "  %836 = Unsqueeze[axes = [0]](%832)\n",
      "  %837 = Concat[axis = 0](%833, %834, %835, %836)\n",
      "  %838 = Reshape(%806, %837)\n",
      "  %839 = Constant[value = <Scalar Tensor []>]()\n",
      "  %840 = Shape(%809)\n",
      "  %841 = Gather[axis = 0](%840, %839)\n",
      "  %842 = Constant[value = <Scalar Tensor []>]()\n",
      "  %843 = Shape(%809)\n",
      "  %844 = Gather[axis = 0](%843, %842)\n",
      "  %845 = Constant[value = <Scalar Tensor []>]()\n",
      "  %846 = Constant[value = <Scalar Tensor []>]()\n",
      "  %847 = Unsqueeze[axes = [0]](%841)\n",
      "  %848 = Unsqueeze[axes = [0]](%844)\n",
      "  %849 = Unsqueeze[axes = [0]](%845)\n",
      "  %850 = Unsqueeze[axes = [0]](%846)\n",
      "  %851 = Concat[axis = 0](%847, %848, %849, %850)\n",
      "  %852 = Reshape(%809, %851)\n",
      "  %853 = Transpose[perm = [0, 2, 1, 3]](%852)\n",
      "  %854 = Transpose[perm = [0, 2, 3, 1]](%838)\n",
      "  %855 = MatMul(%824, %854)\n",
      "  %856 = Constant[value = <Scalar Tensor []>]()\n",
      "  %857 = Div(%855, %856)\n",
      "  %858 = Add(%857, %209)\n",
      "  %859 = Softmax[axis = 3](%858)\n",
      "  %860 = MatMul(%859, %853)\n",
      "  %861 = Transpose[perm = [0, 2, 1, 3]](%860)\n",
      "  %862 = Constant[value = <Scalar Tensor []>]()\n",
      "  %863 = Shape(%861)\n",
      "  %864 = Gather[axis = 0](%863, %862)\n",
      "  %865 = Constant[value = <Scalar Tensor []>]()\n",
      "  %866 = Shape(%861)\n",
      "  %867 = Gather[axis = 0](%866, %865)\n",
      "  %868 = Constant[value = <Scalar Tensor []>]()\n",
      "  %869 = Unsqueeze[axes = [0]](%864)\n",
      "  %870 = Unsqueeze[axes = [0]](%867)\n",
      "  %871 = Unsqueeze[axes = [0]](%868)\n",
      "  %872 = Concat[axis = 0](%869, %870, %871)\n",
      "  %873 = Reshape(%861, %872)\n",
      "  %874 = Transpose[perm = [1, 0]](%encoder.layer.5.attention.output.dense.weight)\n",
      "  %875 = MatMul(%873, %874)\n",
      "  %876 = Add(%875, %encoder.layer.5.attention.output.dense.bias)\n",
      "  %877 = Add(%876, %800)\n",
      "  %878 = ReduceMean[axes = [-1]](%877)\n",
      "  %879 = Sub(%877, %878)\n",
      "  %880 = Constant[value = <Scalar Tensor []>]()\n",
      "  %881 = Pow(%879, %880)\n",
      "  %882 = ReduceMean[axes = [-1]](%881)\n",
      "  %883 = Constant[value = <Scalar Tensor []>]()\n",
      "  %884 = Add(%882, %883)\n",
      "  %885 = Sqrt(%884)\n",
      "  %886 = Div(%879, %885)\n",
      "  %887 = Mul(%886, %encoder.layer.5.attention.output.LayerNorm.weight)\n",
      "  %888 = Add(%887, %encoder.layer.5.attention.output.LayerNorm.bias)\n",
      "  %889 = Transpose[perm = [1, 0]](%encoder.layer.5.intermediate.dense.weight)\n",
      "  %890 = MatMul(%888, %889)\n",
      "  %891 = Add(%890, %encoder.layer.5.intermediate.dense.bias)\n",
      "  %892 = Constant[value = <Scalar Tensor []>]()\n",
      "  %893 = Mul(%891, %892)\n",
      "  %894 = Constant[value = <Scalar Tensor []>]()\n",
      "  %895 = Div(%891, %894)\n",
      "  %896 = Erf(%895)\n",
      "  %897 = Constant[value = <Scalar Tensor []>]()\n",
      "  %898 = Add(%896, %897)\n",
      "  %899 = Mul(%893, %898)\n",
      "  %900 = Transpose[perm = [1, 0]](%encoder.layer.5.output.dense.weight)\n",
      "  %901 = MatMul(%899, %900)\n",
      "  %902 = Add(%901, %encoder.layer.5.output.dense.bias)\n",
      "  %903 = Add(%902, %888)\n",
      "  %904 = ReduceMean[axes = [-1]](%903)\n",
      "  %905 = Sub(%903, %904)\n",
      "  %906 = Constant[value = <Scalar Tensor []>]()\n",
      "  %907 = Pow(%905, %906)\n",
      "  %908 = ReduceMean[axes = [-1]](%907)\n",
      "  %909 = Constant[value = <Scalar Tensor []>]()\n",
      "  %910 = Add(%908, %909)\n",
      "  %911 = Sqrt(%910)\n",
      "  %912 = Div(%905, %911)\n",
      "  %913 = Mul(%912, %encoder.layer.5.output.LayerNorm.weight)\n",
      "  %914 = Add(%913, %encoder.layer.5.output.LayerNorm.bias)\n",
      "  %915 = Transpose[perm = [1, 0]](%encoder.layer.6.attention.self.query.weight)\n",
      "  %916 = MatMul(%914, %915)\n",
      "  %917 = Add(%916, %encoder.layer.6.attention.self.query.bias)\n",
      "  %918 = Transpose[perm = [1, 0]](%encoder.layer.6.attention.self.key.weight)\n",
      "  %919 = MatMul(%914, %918)\n",
      "  %920 = Add(%919, %encoder.layer.6.attention.self.key.bias)\n",
      "  %921 = Transpose[perm = [1, 0]](%encoder.layer.6.attention.self.value.weight)\n",
      "  %922 = MatMul(%914, %921)\n",
      "  %923 = Add(%922, %encoder.layer.6.attention.self.value.bias)\n",
      "  %924 = Constant[value = <Scalar Tensor []>]()\n",
      "  %925 = Shape(%917)\n",
      "  %926 = Gather[axis = 0](%925, %924)\n",
      "  %927 = Constant[value = <Scalar Tensor []>]()\n",
      "  %928 = Shape(%917)\n",
      "  %929 = Gather[axis = 0](%928, %927)\n",
      "  %930 = Constant[value = <Scalar Tensor []>]()\n",
      "  %931 = Constant[value = <Scalar Tensor []>]()\n",
      "  %932 = Unsqueeze[axes = [0]](%926)\n",
      "  %933 = Unsqueeze[axes = [0]](%929)\n",
      "  %934 = Unsqueeze[axes = [0]](%930)\n",
      "  %935 = Unsqueeze[axes = [0]](%931)\n",
      "  %936 = Concat[axis = 0](%932, %933, %934, %935)\n",
      "  %937 = Reshape(%917, %936)\n",
      "  %938 = Transpose[perm = [0, 2, 1, 3]](%937)\n",
      "  %939 = Constant[value = <Scalar Tensor []>]()\n",
      "  %940 = Shape(%920)\n",
      "  %941 = Gather[axis = 0](%940, %939)\n",
      "  %942 = Constant[value = <Scalar Tensor []>]()\n",
      "  %943 = Shape(%920)\n",
      "  %944 = Gather[axis = 0](%943, %942)\n",
      "  %945 = Constant[value = <Scalar Tensor []>]()\n",
      "  %946 = Constant[value = <Scalar Tensor []>]()\n",
      "  %947 = Unsqueeze[axes = [0]](%941)\n",
      "  %948 = Unsqueeze[axes = [0]](%944)\n",
      "  %949 = Unsqueeze[axes = [0]](%945)\n",
      "  %950 = Unsqueeze[axes = [0]](%946)\n",
      "  %951 = Concat[axis = 0](%947, %948, %949, %950)\n",
      "  %952 = Reshape(%920, %951)\n",
      "  %953 = Constant[value = <Scalar Tensor []>]()\n",
      "  %954 = Shape(%923)\n",
      "  %955 = Gather[axis = 0](%954, %953)\n",
      "  %956 = Constant[value = <Scalar Tensor []>]()\n",
      "  %957 = Shape(%923)\n",
      "  %958 = Gather[axis = 0](%957, %956)\n",
      "  %959 = Constant[value = <Scalar Tensor []>]()\n",
      "  %960 = Constant[value = <Scalar Tensor []>]()\n",
      "  %961 = Unsqueeze[axes = [0]](%955)\n",
      "  %962 = Unsqueeze[axes = [0]](%958)\n",
      "  %963 = Unsqueeze[axes = [0]](%959)\n",
      "  %964 = Unsqueeze[axes = [0]](%960)\n",
      "  %965 = Concat[axis = 0](%961, %962, %963, %964)\n",
      "  %966 = Reshape(%923, %965)\n",
      "  %967 = Transpose[perm = [0, 2, 1, 3]](%966)\n",
      "  %968 = Transpose[perm = [0, 2, 3, 1]](%952)\n",
      "  %969 = MatMul(%938, %968)\n",
      "  %970 = Constant[value = <Scalar Tensor []>]()\n",
      "  %971 = Div(%969, %970)\n",
      "  %972 = Add(%971, %209)\n",
      "  %973 = Softmax[axis = 3](%972)\n",
      "  %974 = MatMul(%973, %967)\n",
      "  %975 = Transpose[perm = [0, 2, 1, 3]](%974)\n",
      "  %976 = Constant[value = <Scalar Tensor []>]()\n",
      "  %977 = Shape(%975)\n",
      "  %978 = Gather[axis = 0](%977, %976)\n",
      "  %979 = Constant[value = <Scalar Tensor []>]()\n",
      "  %980 = Shape(%975)\n",
      "  %981 = Gather[axis = 0](%980, %979)\n",
      "  %982 = Constant[value = <Scalar Tensor []>]()\n",
      "  %983 = Unsqueeze[axes = [0]](%978)\n",
      "  %984 = Unsqueeze[axes = [0]](%981)\n",
      "  %985 = Unsqueeze[axes = [0]](%982)\n",
      "  %986 = Concat[axis = 0](%983, %984, %985)\n",
      "  %987 = Reshape(%975, %986)\n",
      "  %988 = Transpose[perm = [1, 0]](%encoder.layer.6.attention.output.dense.weight)\n",
      "  %989 = MatMul(%987, %988)\n",
      "  %990 = Add(%989, %encoder.layer.6.attention.output.dense.bias)\n",
      "  %991 = Add(%990, %914)\n",
      "  %992 = ReduceMean[axes = [-1]](%991)\n",
      "  %993 = Sub(%991, %992)\n",
      "  %994 = Constant[value = <Scalar Tensor []>]()\n",
      "  %995 = Pow(%993, %994)\n",
      "  %996 = ReduceMean[axes = [-1]](%995)\n",
      "  %997 = Constant[value = <Scalar Tensor []>]()\n",
      "  %998 = Add(%996, %997)\n",
      "  %999 = Sqrt(%998)\n",
      "  %1000 = Div(%993, %999)\n",
      "  %1001 = Mul(%1000, %encoder.layer.6.attention.output.LayerNorm.weight)\n",
      "  %1002 = Add(%1001, %encoder.layer.6.attention.output.LayerNorm.bias)\n",
      "  %1003 = Transpose[perm = [1, 0]](%encoder.layer.6.intermediate.dense.weight)\n",
      "  %1004 = MatMul(%1002, %1003)\n",
      "  %1005 = Add(%1004, %encoder.layer.6.intermediate.dense.bias)\n",
      "  %1006 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1007 = Mul(%1005, %1006)\n",
      "  %1008 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1009 = Div(%1005, %1008)\n",
      "  %1010 = Erf(%1009)\n",
      "  %1011 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1012 = Add(%1010, %1011)\n",
      "  %1013 = Mul(%1007, %1012)\n",
      "  %1014 = Transpose[perm = [1, 0]](%encoder.layer.6.output.dense.weight)\n",
      "  %1015 = MatMul(%1013, %1014)\n",
      "  %1016 = Add(%1015, %encoder.layer.6.output.dense.bias)\n",
      "  %1017 = Add(%1016, %1002)\n",
      "  %1018 = ReduceMean[axes = [-1]](%1017)\n",
      "  %1019 = Sub(%1017, %1018)\n",
      "  %1020 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1021 = Pow(%1019, %1020)\n",
      "  %1022 = ReduceMean[axes = [-1]](%1021)\n",
      "  %1023 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1024 = Add(%1022, %1023)\n",
      "  %1025 = Sqrt(%1024)\n",
      "  %1026 = Div(%1019, %1025)\n",
      "  %1027 = Mul(%1026, %encoder.layer.6.output.LayerNorm.weight)\n",
      "  %1028 = Add(%1027, %encoder.layer.6.output.LayerNorm.bias)\n",
      "  %1029 = Transpose[perm = [1, 0]](%encoder.layer.7.attention.self.query.weight)\n",
      "  %1030 = MatMul(%1028, %1029)\n",
      "  %1031 = Add(%1030, %encoder.layer.7.attention.self.query.bias)\n",
      "  %1032 = Transpose[perm = [1, 0]](%encoder.layer.7.attention.self.key.weight)\n",
      "  %1033 = MatMul(%1028, %1032)\n",
      "  %1034 = Add(%1033, %encoder.layer.7.attention.self.key.bias)\n",
      "  %1035 = Transpose[perm = [1, 0]](%encoder.layer.7.attention.self.value.weight)\n",
      "  %1036 = MatMul(%1028, %1035)\n",
      "  %1037 = Add(%1036, %encoder.layer.7.attention.self.value.bias)\n",
      "  %1038 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1039 = Shape(%1031)\n",
      "  %1040 = Gather[axis = 0](%1039, %1038)\n",
      "  %1041 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1042 = Shape(%1031)\n",
      "  %1043 = Gather[axis = 0](%1042, %1041)\n",
      "  %1044 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1045 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1046 = Unsqueeze[axes = [0]](%1040)\n",
      "  %1047 = Unsqueeze[axes = [0]](%1043)\n",
      "  %1048 = Unsqueeze[axes = [0]](%1044)\n",
      "  %1049 = Unsqueeze[axes = [0]](%1045)\n",
      "  %1050 = Concat[axis = 0](%1046, %1047, %1048, %1049)\n",
      "  %1051 = Reshape(%1031, %1050)\n",
      "  %1052 = Transpose[perm = [0, 2, 1, 3]](%1051)\n",
      "  %1053 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1054 = Shape(%1034)\n",
      "  %1055 = Gather[axis = 0](%1054, %1053)\n",
      "  %1056 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1057 = Shape(%1034)\n",
      "  %1058 = Gather[axis = 0](%1057, %1056)\n",
      "  %1059 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1060 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1061 = Unsqueeze[axes = [0]](%1055)\n",
      "  %1062 = Unsqueeze[axes = [0]](%1058)\n",
      "  %1063 = Unsqueeze[axes = [0]](%1059)\n",
      "  %1064 = Unsqueeze[axes = [0]](%1060)\n",
      "  %1065 = Concat[axis = 0](%1061, %1062, %1063, %1064)\n",
      "  %1066 = Reshape(%1034, %1065)\n",
      "  %1067 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1068 = Shape(%1037)\n",
      "  %1069 = Gather[axis = 0](%1068, %1067)\n",
      "  %1070 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1071 = Shape(%1037)\n",
      "  %1072 = Gather[axis = 0](%1071, %1070)\n",
      "  %1073 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1074 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1075 = Unsqueeze[axes = [0]](%1069)\n",
      "  %1076 = Unsqueeze[axes = [0]](%1072)\n",
      "  %1077 = Unsqueeze[axes = [0]](%1073)\n",
      "  %1078 = Unsqueeze[axes = [0]](%1074)\n",
      "  %1079 = Concat[axis = 0](%1075, %1076, %1077, %1078)\n",
      "  %1080 = Reshape(%1037, %1079)\n",
      "  %1081 = Transpose[perm = [0, 2, 1, 3]](%1080)\n",
      "  %1082 = Transpose[perm = [0, 2, 3, 1]](%1066)\n",
      "  %1083 = MatMul(%1052, %1082)\n",
      "  %1084 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1085 = Div(%1083, %1084)\n",
      "  %1086 = Add(%1085, %209)\n",
      "  %1087 = Softmax[axis = 3](%1086)\n",
      "  %1088 = MatMul(%1087, %1081)\n",
      "  %1089 = Transpose[perm = [0, 2, 1, 3]](%1088)\n",
      "  %1090 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1091 = Shape(%1089)\n",
      "  %1092 = Gather[axis = 0](%1091, %1090)\n",
      "  %1093 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1094 = Shape(%1089)\n",
      "  %1095 = Gather[axis = 0](%1094, %1093)\n",
      "  %1096 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1097 = Unsqueeze[axes = [0]](%1092)\n",
      "  %1098 = Unsqueeze[axes = [0]](%1095)\n",
      "  %1099 = Unsqueeze[axes = [0]](%1096)\n",
      "  %1100 = Concat[axis = 0](%1097, %1098, %1099)\n",
      "  %1101 = Reshape(%1089, %1100)\n",
      "  %1102 = Transpose[perm = [1, 0]](%encoder.layer.7.attention.output.dense.weight)\n",
      "  %1103 = MatMul(%1101, %1102)\n",
      "  %1104 = Add(%1103, %encoder.layer.7.attention.output.dense.bias)\n",
      "  %1105 = Add(%1104, %1028)\n",
      "  %1106 = ReduceMean[axes = [-1]](%1105)\n",
      "  %1107 = Sub(%1105, %1106)\n",
      "  %1108 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1109 = Pow(%1107, %1108)\n",
      "  %1110 = ReduceMean[axes = [-1]](%1109)\n",
      "  %1111 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1112 = Add(%1110, %1111)\n",
      "  %1113 = Sqrt(%1112)\n",
      "  %1114 = Div(%1107, %1113)\n",
      "  %1115 = Mul(%1114, %encoder.layer.7.attention.output.LayerNorm.weight)\n",
      "  %1116 = Add(%1115, %encoder.layer.7.attention.output.LayerNorm.bias)\n",
      "  %1117 = Transpose[perm = [1, 0]](%encoder.layer.7.intermediate.dense.weight)\n",
      "  %1118 = MatMul(%1116, %1117)\n",
      "  %1119 = Add(%1118, %encoder.layer.7.intermediate.dense.bias)\n",
      "  %1120 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1121 = Mul(%1119, %1120)\n",
      "  %1122 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1123 = Div(%1119, %1122)\n",
      "  %1124 = Erf(%1123)\n",
      "  %1125 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1126 = Add(%1124, %1125)\n",
      "  %1127 = Mul(%1121, %1126)\n",
      "  %1128 = Transpose[perm = [1, 0]](%encoder.layer.7.output.dense.weight)\n",
      "  %1129 = MatMul(%1127, %1128)\n",
      "  %1130 = Add(%1129, %encoder.layer.7.output.dense.bias)\n",
      "  %1131 = Add(%1130, %1116)\n",
      "  %1132 = ReduceMean[axes = [-1]](%1131)\n",
      "  %1133 = Sub(%1131, %1132)\n",
      "  %1134 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1135 = Pow(%1133, %1134)\n",
      "  %1136 = ReduceMean[axes = [-1]](%1135)\n",
      "  %1137 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1138 = Add(%1136, %1137)\n",
      "  %1139 = Sqrt(%1138)\n",
      "  %1140 = Div(%1133, %1139)\n",
      "  %1141 = Mul(%1140, %encoder.layer.7.output.LayerNorm.weight)\n",
      "  %1142 = Add(%1141, %encoder.layer.7.output.LayerNorm.bias)\n",
      "  %1143 = Transpose[perm = [1, 0]](%encoder.layer.8.attention.self.query.weight)\n",
      "  %1144 = MatMul(%1142, %1143)\n",
      "  %1145 = Add(%1144, %encoder.layer.8.attention.self.query.bias)\n",
      "  %1146 = Transpose[perm = [1, 0]](%encoder.layer.8.attention.self.key.weight)\n",
      "  %1147 = MatMul(%1142, %1146)\n",
      "  %1148 = Add(%1147, %encoder.layer.8.attention.self.key.bias)\n",
      "  %1149 = Transpose[perm = [1, 0]](%encoder.layer.8.attention.self.value.weight)\n",
      "  %1150 = MatMul(%1142, %1149)\n",
      "  %1151 = Add(%1150, %encoder.layer.8.attention.self.value.bias)\n",
      "  %1152 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1153 = Shape(%1145)\n",
      "  %1154 = Gather[axis = 0](%1153, %1152)\n",
      "  %1155 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1156 = Shape(%1145)\n",
      "  %1157 = Gather[axis = 0](%1156, %1155)\n",
      "  %1158 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1159 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1160 = Unsqueeze[axes = [0]](%1154)\n",
      "  %1161 = Unsqueeze[axes = [0]](%1157)\n",
      "  %1162 = Unsqueeze[axes = [0]](%1158)\n",
      "  %1163 = Unsqueeze[axes = [0]](%1159)\n",
      "  %1164 = Concat[axis = 0](%1160, %1161, %1162, %1163)\n",
      "  %1165 = Reshape(%1145, %1164)\n",
      "  %1166 = Transpose[perm = [0, 2, 1, 3]](%1165)\n",
      "  %1167 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1168 = Shape(%1148)\n",
      "  %1169 = Gather[axis = 0](%1168, %1167)\n",
      "  %1170 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1171 = Shape(%1148)\n",
      "  %1172 = Gather[axis = 0](%1171, %1170)\n",
      "  %1173 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1174 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1175 = Unsqueeze[axes = [0]](%1169)\n",
      "  %1176 = Unsqueeze[axes = [0]](%1172)\n",
      "  %1177 = Unsqueeze[axes = [0]](%1173)\n",
      "  %1178 = Unsqueeze[axes = [0]](%1174)\n",
      "  %1179 = Concat[axis = 0](%1175, %1176, %1177, %1178)\n",
      "  %1180 = Reshape(%1148, %1179)\n",
      "  %1181 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1182 = Shape(%1151)\n",
      "  %1183 = Gather[axis = 0](%1182, %1181)\n",
      "  %1184 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1185 = Shape(%1151)\n",
      "  %1186 = Gather[axis = 0](%1185, %1184)\n",
      "  %1187 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1188 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1189 = Unsqueeze[axes = [0]](%1183)\n",
      "  %1190 = Unsqueeze[axes = [0]](%1186)\n",
      "  %1191 = Unsqueeze[axes = [0]](%1187)\n",
      "  %1192 = Unsqueeze[axes = [0]](%1188)\n",
      "  %1193 = Concat[axis = 0](%1189, %1190, %1191, %1192)\n",
      "  %1194 = Reshape(%1151, %1193)\n",
      "  %1195 = Transpose[perm = [0, 2, 1, 3]](%1194)\n",
      "  %1196 = Transpose[perm = [0, 2, 3, 1]](%1180)\n",
      "  %1197 = MatMul(%1166, %1196)\n",
      "  %1198 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1199 = Div(%1197, %1198)\n",
      "  %1200 = Add(%1199, %209)\n",
      "  %1201 = Softmax[axis = 3](%1200)\n",
      "  %1202 = MatMul(%1201, %1195)\n",
      "  %1203 = Transpose[perm = [0, 2, 1, 3]](%1202)\n",
      "  %1204 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1205 = Shape(%1203)\n",
      "  %1206 = Gather[axis = 0](%1205, %1204)\n",
      "  %1207 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1208 = Shape(%1203)\n",
      "  %1209 = Gather[axis = 0](%1208, %1207)\n",
      "  %1210 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1211 = Unsqueeze[axes = [0]](%1206)\n",
      "  %1212 = Unsqueeze[axes = [0]](%1209)\n",
      "  %1213 = Unsqueeze[axes = [0]](%1210)\n",
      "  %1214 = Concat[axis = 0](%1211, %1212, %1213)\n",
      "  %1215 = Reshape(%1203, %1214)\n",
      "  %1216 = Transpose[perm = [1, 0]](%encoder.layer.8.attention.output.dense.weight)\n",
      "  %1217 = MatMul(%1215, %1216)\n",
      "  %1218 = Add(%1217, %encoder.layer.8.attention.output.dense.bias)\n",
      "  %1219 = Add(%1218, %1142)\n",
      "  %1220 = ReduceMean[axes = [-1]](%1219)\n",
      "  %1221 = Sub(%1219, %1220)\n",
      "  %1222 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1223 = Pow(%1221, %1222)\n",
      "  %1224 = ReduceMean[axes = [-1]](%1223)\n",
      "  %1225 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1226 = Add(%1224, %1225)\n",
      "  %1227 = Sqrt(%1226)\n",
      "  %1228 = Div(%1221, %1227)\n",
      "  %1229 = Mul(%1228, %encoder.layer.8.attention.output.LayerNorm.weight)\n",
      "  %1230 = Add(%1229, %encoder.layer.8.attention.output.LayerNorm.bias)\n",
      "  %1231 = Transpose[perm = [1, 0]](%encoder.layer.8.intermediate.dense.weight)\n",
      "  %1232 = MatMul(%1230, %1231)\n",
      "  %1233 = Add(%1232, %encoder.layer.8.intermediate.dense.bias)\n",
      "  %1234 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1235 = Mul(%1233, %1234)\n",
      "  %1236 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1237 = Div(%1233, %1236)\n",
      "  %1238 = Erf(%1237)\n",
      "  %1239 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1240 = Add(%1238, %1239)\n",
      "  %1241 = Mul(%1235, %1240)\n",
      "  %1242 = Transpose[perm = [1, 0]](%encoder.layer.8.output.dense.weight)\n",
      "  %1243 = MatMul(%1241, %1242)\n",
      "  %1244 = Add(%1243, %encoder.layer.8.output.dense.bias)\n",
      "  %1245 = Add(%1244, %1230)\n",
      "  %1246 = ReduceMean[axes = [-1]](%1245)\n",
      "  %1247 = Sub(%1245, %1246)\n",
      "  %1248 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1249 = Pow(%1247, %1248)\n",
      "  %1250 = ReduceMean[axes = [-1]](%1249)\n",
      "  %1251 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1252 = Add(%1250, %1251)\n",
      "  %1253 = Sqrt(%1252)\n",
      "  %1254 = Div(%1247, %1253)\n",
      "  %1255 = Mul(%1254, %encoder.layer.8.output.LayerNorm.weight)\n",
      "  %1256 = Add(%1255, %encoder.layer.8.output.LayerNorm.bias)\n",
      "  %1257 = Transpose[perm = [1, 0]](%encoder.layer.9.attention.self.query.weight)\n",
      "  %1258 = MatMul(%1256, %1257)\n",
      "  %1259 = Add(%1258, %encoder.layer.9.attention.self.query.bias)\n",
      "  %1260 = Transpose[perm = [1, 0]](%encoder.layer.9.attention.self.key.weight)\n",
      "  %1261 = MatMul(%1256, %1260)\n",
      "  %1262 = Add(%1261, %encoder.layer.9.attention.self.key.bias)\n",
      "  %1263 = Transpose[perm = [1, 0]](%encoder.layer.9.attention.self.value.weight)\n",
      "  %1264 = MatMul(%1256, %1263)\n",
      "  %1265 = Add(%1264, %encoder.layer.9.attention.self.value.bias)\n",
      "  %1266 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1267 = Shape(%1259)\n",
      "  %1268 = Gather[axis = 0](%1267, %1266)\n",
      "  %1269 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1270 = Shape(%1259)\n",
      "  %1271 = Gather[axis = 0](%1270, %1269)\n",
      "  %1272 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1273 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1274 = Unsqueeze[axes = [0]](%1268)\n",
      "  %1275 = Unsqueeze[axes = [0]](%1271)\n",
      "  %1276 = Unsqueeze[axes = [0]](%1272)\n",
      "  %1277 = Unsqueeze[axes = [0]](%1273)\n",
      "  %1278 = Concat[axis = 0](%1274, %1275, %1276, %1277)\n",
      "  %1279 = Reshape(%1259, %1278)\n",
      "  %1280 = Transpose[perm = [0, 2, 1, 3]](%1279)\n",
      "  %1281 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1282 = Shape(%1262)\n",
      "  %1283 = Gather[axis = 0](%1282, %1281)\n",
      "  %1284 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1285 = Shape(%1262)\n",
      "  %1286 = Gather[axis = 0](%1285, %1284)\n",
      "  %1287 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1288 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1289 = Unsqueeze[axes = [0]](%1283)\n",
      "  %1290 = Unsqueeze[axes = [0]](%1286)\n",
      "  %1291 = Unsqueeze[axes = [0]](%1287)\n",
      "  %1292 = Unsqueeze[axes = [0]](%1288)\n",
      "  %1293 = Concat[axis = 0](%1289, %1290, %1291, %1292)\n",
      "  %1294 = Reshape(%1262, %1293)\n",
      "  %1295 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1296 = Shape(%1265)\n",
      "  %1297 = Gather[axis = 0](%1296, %1295)\n",
      "  %1298 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1299 = Shape(%1265)\n",
      "  %1300 = Gather[axis = 0](%1299, %1298)\n",
      "  %1301 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1302 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1303 = Unsqueeze[axes = [0]](%1297)\n",
      "  %1304 = Unsqueeze[axes = [0]](%1300)\n",
      "  %1305 = Unsqueeze[axes = [0]](%1301)\n",
      "  %1306 = Unsqueeze[axes = [0]](%1302)\n",
      "  %1307 = Concat[axis = 0](%1303, %1304, %1305, %1306)\n",
      "  %1308 = Reshape(%1265, %1307)\n",
      "  %1309 = Transpose[perm = [0, 2, 1, 3]](%1308)\n",
      "  %1310 = Transpose[perm = [0, 2, 3, 1]](%1294)\n",
      "  %1311 = MatMul(%1280, %1310)\n",
      "  %1312 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1313 = Div(%1311, %1312)\n",
      "  %1314 = Add(%1313, %209)\n",
      "  %1315 = Softmax[axis = 3](%1314)\n",
      "  %1316 = MatMul(%1315, %1309)\n",
      "  %1317 = Transpose[perm = [0, 2, 1, 3]](%1316)\n",
      "  %1318 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1319 = Shape(%1317)\n",
      "  %1320 = Gather[axis = 0](%1319, %1318)\n",
      "  %1321 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1322 = Shape(%1317)\n",
      "  %1323 = Gather[axis = 0](%1322, %1321)\n",
      "  %1324 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1325 = Unsqueeze[axes = [0]](%1320)\n",
      "  %1326 = Unsqueeze[axes = [0]](%1323)\n",
      "  %1327 = Unsqueeze[axes = [0]](%1324)\n",
      "  %1328 = Concat[axis = 0](%1325, %1326, %1327)\n",
      "  %1329 = Reshape(%1317, %1328)\n",
      "  %1330 = Transpose[perm = [1, 0]](%encoder.layer.9.attention.output.dense.weight)\n",
      "  %1331 = MatMul(%1329, %1330)\n",
      "  %1332 = Add(%1331, %encoder.layer.9.attention.output.dense.bias)\n",
      "  %1333 = Add(%1332, %1256)\n",
      "  %1334 = ReduceMean[axes = [-1]](%1333)\n",
      "  %1335 = Sub(%1333, %1334)\n",
      "  %1336 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1337 = Pow(%1335, %1336)\n",
      "  %1338 = ReduceMean[axes = [-1]](%1337)\n",
      "  %1339 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1340 = Add(%1338, %1339)\n",
      "  %1341 = Sqrt(%1340)\n",
      "  %1342 = Div(%1335, %1341)\n",
      "  %1343 = Mul(%1342, %encoder.layer.9.attention.output.LayerNorm.weight)\n",
      "  %1344 = Add(%1343, %encoder.layer.9.attention.output.LayerNorm.bias)\n",
      "  %1345 = Transpose[perm = [1, 0]](%encoder.layer.9.intermediate.dense.weight)\n",
      "  %1346 = MatMul(%1344, %1345)\n",
      "  %1347 = Add(%1346, %encoder.layer.9.intermediate.dense.bias)\n",
      "  %1348 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1349 = Mul(%1347, %1348)\n",
      "  %1350 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1351 = Div(%1347, %1350)\n",
      "  %1352 = Erf(%1351)\n",
      "  %1353 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1354 = Add(%1352, %1353)\n",
      "  %1355 = Mul(%1349, %1354)\n",
      "  %1356 = Transpose[perm = [1, 0]](%encoder.layer.9.output.dense.weight)\n",
      "  %1357 = MatMul(%1355, %1356)\n",
      "  %1358 = Add(%1357, %encoder.layer.9.output.dense.bias)\n",
      "  %1359 = Add(%1358, %1344)\n",
      "  %1360 = ReduceMean[axes = [-1]](%1359)\n",
      "  %1361 = Sub(%1359, %1360)\n",
      "  %1362 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1363 = Pow(%1361, %1362)\n",
      "  %1364 = ReduceMean[axes = [-1]](%1363)\n",
      "  %1365 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1366 = Add(%1364, %1365)\n",
      "  %1367 = Sqrt(%1366)\n",
      "  %1368 = Div(%1361, %1367)\n",
      "  %1369 = Mul(%1368, %encoder.layer.9.output.LayerNorm.weight)\n",
      "  %1370 = Add(%1369, %encoder.layer.9.output.LayerNorm.bias)\n",
      "  %1371 = Transpose[perm = [1, 0]](%encoder.layer.10.attention.self.query.weight)\n",
      "  %1372 = MatMul(%1370, %1371)\n",
      "  %1373 = Add(%1372, %encoder.layer.10.attention.self.query.bias)\n",
      "  %1374 = Transpose[perm = [1, 0]](%encoder.layer.10.attention.self.key.weight)\n",
      "  %1375 = MatMul(%1370, %1374)\n",
      "  %1376 = Add(%1375, %encoder.layer.10.attention.self.key.bias)\n",
      "  %1377 = Transpose[perm = [1, 0]](%encoder.layer.10.attention.self.value.weight)\n",
      "  %1378 = MatMul(%1370, %1377)\n",
      "  %1379 = Add(%1378, %encoder.layer.10.attention.self.value.bias)\n",
      "  %1380 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1381 = Shape(%1373)\n",
      "  %1382 = Gather[axis = 0](%1381, %1380)\n",
      "  %1383 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1384 = Shape(%1373)\n",
      "  %1385 = Gather[axis = 0](%1384, %1383)\n",
      "  %1386 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1387 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1388 = Unsqueeze[axes = [0]](%1382)\n",
      "  %1389 = Unsqueeze[axes = [0]](%1385)\n",
      "  %1390 = Unsqueeze[axes = [0]](%1386)\n",
      "  %1391 = Unsqueeze[axes = [0]](%1387)\n",
      "  %1392 = Concat[axis = 0](%1388, %1389, %1390, %1391)\n",
      "  %1393 = Reshape(%1373, %1392)\n",
      "  %1394 = Transpose[perm = [0, 2, 1, 3]](%1393)\n",
      "  %1395 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1396 = Shape(%1376)\n",
      "  %1397 = Gather[axis = 0](%1396, %1395)\n",
      "  %1398 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1399 = Shape(%1376)\n",
      "  %1400 = Gather[axis = 0](%1399, %1398)\n",
      "  %1401 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1402 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1403 = Unsqueeze[axes = [0]](%1397)\n",
      "  %1404 = Unsqueeze[axes = [0]](%1400)\n",
      "  %1405 = Unsqueeze[axes = [0]](%1401)\n",
      "  %1406 = Unsqueeze[axes = [0]](%1402)\n",
      "  %1407 = Concat[axis = 0](%1403, %1404, %1405, %1406)\n",
      "  %1408 = Reshape(%1376, %1407)\n",
      "  %1409 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1410 = Shape(%1379)\n",
      "  %1411 = Gather[axis = 0](%1410, %1409)\n",
      "  %1412 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1413 = Shape(%1379)\n",
      "  %1414 = Gather[axis = 0](%1413, %1412)\n",
      "  %1415 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1416 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1417 = Unsqueeze[axes = [0]](%1411)\n",
      "  %1418 = Unsqueeze[axes = [0]](%1414)\n",
      "  %1419 = Unsqueeze[axes = [0]](%1415)\n",
      "  %1420 = Unsqueeze[axes = [0]](%1416)\n",
      "  %1421 = Concat[axis = 0](%1417, %1418, %1419, %1420)\n",
      "  %1422 = Reshape(%1379, %1421)\n",
      "  %1423 = Transpose[perm = [0, 2, 1, 3]](%1422)\n",
      "  %1424 = Transpose[perm = [0, 2, 3, 1]](%1408)\n",
      "  %1425 = MatMul(%1394, %1424)\n",
      "  %1426 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1427 = Div(%1425, %1426)\n",
      "  %1428 = Add(%1427, %209)\n",
      "  %1429 = Softmax[axis = 3](%1428)\n",
      "  %1430 = MatMul(%1429, %1423)\n",
      "  %1431 = Transpose[perm = [0, 2, 1, 3]](%1430)\n",
      "  %1432 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1433 = Shape(%1431)\n",
      "  %1434 = Gather[axis = 0](%1433, %1432)\n",
      "  %1435 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1436 = Shape(%1431)\n",
      "  %1437 = Gather[axis = 0](%1436, %1435)\n",
      "  %1438 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1439 = Unsqueeze[axes = [0]](%1434)\n",
      "  %1440 = Unsqueeze[axes = [0]](%1437)\n",
      "  %1441 = Unsqueeze[axes = [0]](%1438)\n",
      "  %1442 = Concat[axis = 0](%1439, %1440, %1441)\n",
      "  %1443 = Reshape(%1431, %1442)\n",
      "  %1444 = Transpose[perm = [1, 0]](%encoder.layer.10.attention.output.dense.weight)\n",
      "  %1445 = MatMul(%1443, %1444)\n",
      "  %1446 = Add(%1445, %encoder.layer.10.attention.output.dense.bias)\n",
      "  %1447 = Add(%1446, %1370)\n",
      "  %1448 = ReduceMean[axes = [-1]](%1447)\n",
      "  %1449 = Sub(%1447, %1448)\n",
      "  %1450 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1451 = Pow(%1449, %1450)\n",
      "  %1452 = ReduceMean[axes = [-1]](%1451)\n",
      "  %1453 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1454 = Add(%1452, %1453)\n",
      "  %1455 = Sqrt(%1454)\n",
      "  %1456 = Div(%1449, %1455)\n",
      "  %1457 = Mul(%1456, %encoder.layer.10.attention.output.LayerNorm.weight)\n",
      "  %1458 = Add(%1457, %encoder.layer.10.attention.output.LayerNorm.bias)\n",
      "  %1459 = Transpose[perm = [1, 0]](%encoder.layer.10.intermediate.dense.weight)\n",
      "  %1460 = MatMul(%1458, %1459)\n",
      "  %1461 = Add(%1460, %encoder.layer.10.intermediate.dense.bias)\n",
      "  %1462 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1463 = Mul(%1461, %1462)\n",
      "  %1464 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1465 = Div(%1461, %1464)\n",
      "  %1466 = Erf(%1465)\n",
      "  %1467 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1468 = Add(%1466, %1467)\n",
      "  %1469 = Mul(%1463, %1468)\n",
      "  %1470 = Transpose[perm = [1, 0]](%encoder.layer.10.output.dense.weight)\n",
      "  %1471 = MatMul(%1469, %1470)\n",
      "  %1472 = Add(%1471, %encoder.layer.10.output.dense.bias)\n",
      "  %1473 = Add(%1472, %1458)\n",
      "  %1474 = ReduceMean[axes = [-1]](%1473)\n",
      "  %1475 = Sub(%1473, %1474)\n",
      "  %1476 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1477 = Pow(%1475, %1476)\n",
      "  %1478 = ReduceMean[axes = [-1]](%1477)\n",
      "  %1479 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1480 = Add(%1478, %1479)\n",
      "  %1481 = Sqrt(%1480)\n",
      "  %1482 = Div(%1475, %1481)\n",
      "  %1483 = Mul(%1482, %encoder.layer.10.output.LayerNorm.weight)\n",
      "  %1484 = Add(%1483, %encoder.layer.10.output.LayerNorm.bias)\n",
      "  %1485 = Transpose[perm = [1, 0]](%encoder.layer.11.attention.self.query.weight)\n",
      "  %1486 = MatMul(%1484, %1485)\n",
      "  %1487 = Add(%1486, %encoder.layer.11.attention.self.query.bias)\n",
      "  %1488 = Transpose[perm = [1, 0]](%encoder.layer.11.attention.self.key.weight)\n",
      "  %1489 = MatMul(%1484, %1488)\n",
      "  %1490 = Add(%1489, %encoder.layer.11.attention.self.key.bias)\n",
      "  %1491 = Transpose[perm = [1, 0]](%encoder.layer.11.attention.self.value.weight)\n",
      "  %1492 = MatMul(%1484, %1491)\n",
      "  %1493 = Add(%1492, %encoder.layer.11.attention.self.value.bias)\n",
      "  %1494 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1495 = Shape(%1487)\n",
      "  %1496 = Gather[axis = 0](%1495, %1494)\n",
      "  %1497 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1498 = Shape(%1487)\n",
      "  %1499 = Gather[axis = 0](%1498, %1497)\n",
      "  %1500 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1501 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1502 = Unsqueeze[axes = [0]](%1496)\n",
      "  %1503 = Unsqueeze[axes = [0]](%1499)\n",
      "  %1504 = Unsqueeze[axes = [0]](%1500)\n",
      "  %1505 = Unsqueeze[axes = [0]](%1501)\n",
      "  %1506 = Concat[axis = 0](%1502, %1503, %1504, %1505)\n",
      "  %1507 = Reshape(%1487, %1506)\n",
      "  %1508 = Transpose[perm = [0, 2, 1, 3]](%1507)\n",
      "  %1509 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1510 = Shape(%1490)\n",
      "  %1511 = Gather[axis = 0](%1510, %1509)\n",
      "  %1512 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1513 = Shape(%1490)\n",
      "  %1514 = Gather[axis = 0](%1513, %1512)\n",
      "  %1515 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1516 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1517 = Unsqueeze[axes = [0]](%1511)\n",
      "  %1518 = Unsqueeze[axes = [0]](%1514)\n",
      "  %1519 = Unsqueeze[axes = [0]](%1515)\n",
      "  %1520 = Unsqueeze[axes = [0]](%1516)\n",
      "  %1521 = Concat[axis = 0](%1517, %1518, %1519, %1520)\n",
      "  %1522 = Reshape(%1490, %1521)\n",
      "  %1523 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1524 = Shape(%1493)\n",
      "  %1525 = Gather[axis = 0](%1524, %1523)\n",
      "  %1526 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1527 = Shape(%1493)\n",
      "  %1528 = Gather[axis = 0](%1527, %1526)\n",
      "  %1529 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1530 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1531 = Unsqueeze[axes = [0]](%1525)\n",
      "  %1532 = Unsqueeze[axes = [0]](%1528)\n",
      "  %1533 = Unsqueeze[axes = [0]](%1529)\n",
      "  %1534 = Unsqueeze[axes = [0]](%1530)\n",
      "  %1535 = Concat[axis = 0](%1531, %1532, %1533, %1534)\n",
      "  %1536 = Reshape(%1493, %1535)\n",
      "  %1537 = Transpose[perm = [0, 2, 1, 3]](%1536)\n",
      "  %1538 = Transpose[perm = [0, 2, 3, 1]](%1522)\n",
      "  %1539 = MatMul(%1508, %1538)\n",
      "  %1540 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1541 = Div(%1539, %1540)\n",
      "  %1542 = Add(%1541, %209)\n",
      "  %1543 = Softmax[axis = 3](%1542)\n",
      "  %1544 = MatMul(%1543, %1537)\n",
      "  %1545 = Transpose[perm = [0, 2, 1, 3]](%1544)\n",
      "  %1546 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1547 = Shape(%1545)\n",
      "  %1548 = Gather[axis = 0](%1547, %1546)\n",
      "  %1549 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1550 = Shape(%1545)\n",
      "  %1551 = Gather[axis = 0](%1550, %1549)\n",
      "  %1552 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1553 = Unsqueeze[axes = [0]](%1548)\n",
      "  %1554 = Unsqueeze[axes = [0]](%1551)\n",
      "  %1555 = Unsqueeze[axes = [0]](%1552)\n",
      "  %1556 = Concat[axis = 0](%1553, %1554, %1555)\n",
      "  %1557 = Reshape(%1545, %1556)\n",
      "  %1558 = Transpose[perm = [1, 0]](%encoder.layer.11.attention.output.dense.weight)\n",
      "  %1559 = MatMul(%1557, %1558)\n",
      "  %1560 = Add(%1559, %encoder.layer.11.attention.output.dense.bias)\n",
      "  %1561 = Add(%1560, %1484)\n",
      "  %1562 = ReduceMean[axes = [-1]](%1561)\n",
      "  %1563 = Sub(%1561, %1562)\n",
      "  %1564 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1565 = Pow(%1563, %1564)\n",
      "  %1566 = ReduceMean[axes = [-1]](%1565)\n",
      "  %1567 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1568 = Add(%1566, %1567)\n",
      "  %1569 = Sqrt(%1568)\n",
      "  %1570 = Div(%1563, %1569)\n",
      "  %1571 = Mul(%1570, %encoder.layer.11.attention.output.LayerNorm.weight)\n",
      "  %1572 = Add(%1571, %encoder.layer.11.attention.output.LayerNorm.bias)\n",
      "  %1573 = Transpose[perm = [1, 0]](%encoder.layer.11.intermediate.dense.weight)\n",
      "  %1574 = MatMul(%1572, %1573)\n",
      "  %1575 = Add(%1574, %encoder.layer.11.intermediate.dense.bias)\n",
      "  %1576 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1577 = Mul(%1575, %1576)\n",
      "  %1578 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1579 = Div(%1575, %1578)\n",
      "  %1580 = Erf(%1579)\n",
      "  %1581 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1582 = Add(%1580, %1581)\n",
      "  %1583 = Mul(%1577, %1582)\n",
      "  %1584 = Transpose[perm = [1, 0]](%encoder.layer.11.output.dense.weight)\n",
      "  %1585 = MatMul(%1583, %1584)\n",
      "  %1586 = Add(%1585, %encoder.layer.11.output.dense.bias)\n",
      "  %1587 = Add(%1586, %1572)\n",
      "  %1588 = ReduceMean[axes = [-1]](%1587)\n",
      "  %1589 = Sub(%1587, %1588)\n",
      "  %1590 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1591 = Pow(%1589, %1590)\n",
      "  %1592 = ReduceMean[axes = [-1]](%1591)\n",
      "  %1593 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1594 = Add(%1592, %1593)\n",
      "  %1595 = Sqrt(%1594)\n",
      "  %1596 = Div(%1589, %1595)\n",
      "  %1597 = Mul(%1596, %encoder.layer.11.output.LayerNorm.weight)\n",
      "  %1598 = Add(%1597, %encoder.layer.11.output.LayerNorm.bias)\n",
      "  %1599 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1600 = Gather[axis = 1](%1598, %1599)\n",
      "  %1601 = Gemm[alpha = 1, beta = 1, transB = 1](%1600, %pooler.dense.weight, %pooler.dense.bias)\n",
      "  %1602 = Tanh(%1601)\n",
      "  return %1598, %1602\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model2 = onnx.load(\"roberta.onnx\")\n",
    "# 检查模型格式是否完整及正确\n",
    "onnx.checker.check_model(model2)\n",
    "\n",
    "print(onnx.helper.printable_graph(model2.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"1598\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: 1\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 1\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 15\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 768\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", name: \"1602\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: 1\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 1\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 768\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获取输出层，包含层名称、维度信息\n",
    "model2.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = rt.InferenceSession(\"roberta.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7efcb3949538>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7efcb39495e0>,\n",
       " <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x7efcb3949490>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('input.1', 'attention_mask', 'input.3', 'input.3')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(session.get_inputs()[0].name, session.get_inputs()[1].name, session.get_inputs()[2].name, session.get_inputs()[-1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "?session.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = session.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'attention_mask'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2 = session.get_inputs()[1].name\n",
    "name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input.3 for the following indices\n index: 1 Got: 24 Expected: 15\n Please fix either the inputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-485b3959a3b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname2\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input.3 for the following indices\n index: 1 Got: 24 Expected: 15\n Please fix either the inputs or the model."
     ]
    }
   ],
   "source": [
    "out = session.run(None, {name1: input_ids.cpu().numpy(), session.get_inputs()[2].name: token_type_ids.cpu().numpy(), name2:  attention_mask.cpu().numpy() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.00217071,  0.39623275, -0.40544528, ...,  0.39019328,\n",
       "         -0.1599319 ,  0.04569437],\n",
       "        [ 0.25887132, -0.5536411 , -0.24241525, ..., -0.58426225,\n",
       "         -0.9316153 , -0.03258407],\n",
       "        [ 0.5397451 , -1.2938117 , -0.96167237, ...,  0.8387685 ,\n",
       "          0.27140135,  0.05966763],\n",
       "        ...,\n",
       "        [-0.58584267,  0.4624487 ,  0.87729377, ...,  0.54620314,\n",
       "         -0.6653838 ,  0.13872091],\n",
       "        [ 0.44499832,  0.00427569, -0.5730417 , ...,  0.80946803,\n",
       "         -0.10727846, -0.30272254],\n",
       "        [-0.7771462 ,  0.02932469, -0.1939237 , ..., -0.14846408,\n",
       "         -0.30965   , -0.4417867 ]]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[-0.0022,  0.3962, -0.4054,  ...,  0.3902, -0.1599,  0.0457]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "?torch.onnx.export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
