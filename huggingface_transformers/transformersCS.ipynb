{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import transformers\n",
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置日志模块，这样在代码运行的时候，可以看一下日志信息，知道代码在进行哪些步骤\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:Model name 'voidful/albert_chinese_large' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming 'voidful/albert_chinese_large' is a path or url to a directory containing tokenizer files.\n",
      "INFO:transformers.tokenization_utils:Didn't find file voidful/albert_chinese_large/added_tokens.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils:Didn't find file voidful/albert_chinese_large/special_tokens_map.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils:Didn't find file voidful/albert_chinese_large/tokenizer_config.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/voidful/albert_chinese_large/vocab.txt from cache at /home/dc/.cache/torch/transformers/945e2c696baf28a905aaa48fc472ed0425dfa802b83e189f96b451b182713b0c.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
      "INFO:transformers.tokenization_utils:loading file None\n",
      "INFO:transformers.tokenization_utils:loading file None\n",
      "INFO:transformers.tokenization_utils:loading file None\n"
     ]
    }
   ],
   "source": [
    "pretrained = 'voidful/albert_chinese_large'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/voidful/albert_chinese_large/config.json from cache at /home/dc/.cache/torch/transformers/ca8c4e677cd21cb170541f19c89240631c314be98183c248bbc66adc3cad8ff6.9de7bff39da5b665550e7b5edfc1d1be50e549e233628604890aaec9084403fd\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"relu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"layers_to_keep\": [],\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/voidful/albert_chinese_large/pytorch_model.bin from cache at /home/dc/.cache/torch/transformers/2697e35def8411044ff244b0a40dceaa0ec433d4ace686a8be1c6f096b7c2f27.ff89c08e02a9de50311cfc1dc8fbbf87d22d779309094e227986d2ea49d07db1\n"
     ]
    }
   ],
   "source": [
    "model = AlbertForMaskedLM.from_pretrained(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputtext = \"今天[MASK]情很好\"\n",
    "\n",
    "maskpos = tokenizer.encode(inputtext, add_special_tokens=True).index(103)\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(inputtext, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids, masked_lm_labels=input_ids)\n",
    "loss, prediction_scores = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "心 0.9560801386833191\n"
     ]
    }
   ],
   "source": [
    "logit_prob = F.softmax(prediction_scores[0, maskpos], dim=-1).data.tolist()\n",
    "predicted_index = torch.argmax(prediction_scores[0, maskpos]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "print(predicted_token,logit_prob[predicted_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://s3.amazonaws.com/models.huggingface.co/bert/voidful/albert_chinese_large/vocab.txt\n",
    "https://s3.amazonaws.com/models.huggingface.co/bert/voidful/albert_chinese_large/config.json\n",
    "https://s3.amazonaws.com/models.huggingface.co/bert/voidful/albert_chinese_large/pytorch_model.bin\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/home/dc/liuyouyuan/workspace/TextClassificationBertPytorch/albert_pretrain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file /home/dc/liuyouyuan/workspace/TextClassificationBertPytorch/albert_pretrain/config.json\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"relu\",\n",
      "  \"hidden_dropout_prob\": 0,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"layers_to_keep\": [],\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file /home/dc/liuyouyuan/workspace/TextClassificationBertPytorch/albert_pretrain/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "albert = AlbertModel.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "?albert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101,  791, 1921,  103, 2658, 2523, 1962,  102]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2085,  0.1634,  0.5647,  ..., -0.7243,  0.3099, -0.2300],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:2][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = albert(input_ids, attention_mask=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pooled = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 1024])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlbertTokenizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
