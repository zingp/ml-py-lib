{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_rand_seed(seed=1):\n",
    "    print(\"Random Seed: \", seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # torch.backends.cudnn.enabled = False       \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  1\n"
     ]
    }
   ],
   "source": [
    "set_rand_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义LSTM\n",
    "- 输入\n",
    "- output保存了最后一层，每个time step的输出h，如果是双向LSTM，每个time step的输出h = [h正向, h逆向] (同一个time step的正向和逆向的h连接起来)。\n",
    "- h_n保存了每一层，最后一个time step的输出h，如果是双向LSTM，单独保存前向和后向的最后一个time step的输出h。\n",
    "- c_n与h_n一致，只是它保存的是c的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 12\n",
    "hidden_size = 5\n",
    "n_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(embed_size, hidden_size, n_layer, batch_first=True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in lstm.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4350,  0.3496,  0.4341, -0.0203,  0.0736, -0.1049, -0.2831, -0.2023,\n",
      "         -0.0297, -0.3659, -0.3614,  0.0491],\n",
      "        [-0.2910, -0.2433, -0.0039, -0.2357,  0.4140, -0.1614, -0.2487, -0.1191,\n",
      "         -0.3649,  0.2304,  0.3842, -0.2579],\n",
      "        [-0.1662,  0.4174, -0.3235,  0.1211, -0.3644, -0.3980,  0.0007, -0.2552,\n",
      "          0.2422, -0.1383,  0.0044, -0.2335],\n",
      "        [ 0.1838,  0.4144, -0.0672, -0.2760, -0.4362,  0.4285,  0.1885,  0.1847,\n",
      "          0.0761,  0.2244,  0.1588,  0.2184],\n",
      "        [ 0.2797,  0.0634,  0.3852,  0.2781, -0.0137, -0.1997,  0.0296,  0.3483,\n",
      "          0.2833, -0.1812, -0.0934,  0.1776],\n",
      "        [ 0.1685,  0.4259,  0.2172,  0.1425,  0.1034, -0.4203, -0.1648,  0.0473,\n",
      "         -0.3111, -0.3918,  0.3018,  0.1521],\n",
      "        [-0.3609,  0.0265,  0.2634,  0.2576,  0.4084, -0.1768,  0.1991, -0.3628,\n",
      "         -0.0552, -0.2844, -0.0852,  0.2546],\n",
      "        [ 0.2229, -0.2352, -0.1109, -0.0895, -0.1701, -0.2450,  0.3284,  0.3091,\n",
      "          0.3733, -0.2456,  0.3275, -0.1356],\n",
      "        [-0.1051, -0.1204, -0.0217, -0.1958,  0.0612, -0.2882,  0.1839, -0.3750,\n",
      "         -0.1621, -0.3124,  0.3017,  0.3073],\n",
      "        [-0.3557, -0.2440,  0.4002,  0.1303,  0.3079, -0.3429,  0.2018,  0.2847,\n",
      "         -0.1038, -0.0206,  0.3261,  0.1219],\n",
      "        [ 0.1283,  0.0014, -0.1867, -0.2737,  0.4463, -0.0353,  0.3969,  0.3659,\n",
      "         -0.2339,  0.0304, -0.1144, -0.0081],\n",
      "        [ 0.2947,  0.2463, -0.2540, -0.2213, -0.3177, -0.3797,  0.2869, -0.2763,\n",
      "          0.0058, -0.0006,  0.0765, -0.0262],\n",
      "        [ 0.2321,  0.0614,  0.3207,  0.0965, -0.0056,  0.0634,  0.2981,  0.0675,\n",
      "          0.3151, -0.0424,  0.0039,  0.3757],\n",
      "        [-0.4222,  0.0446,  0.4085, -0.2244, -0.0825, -0.0269,  0.1473,  0.1690,\n",
      "          0.1013,  0.1764, -0.1919,  0.1881],\n",
      "        [-0.1418,  0.2810, -0.1313, -0.3808,  0.0319,  0.2327, -0.0175,  0.0058,\n",
      "          0.0016,  0.2374,  0.0350, -0.3995],\n",
      "        [-0.3189,  0.0264, -0.0359,  0.4275, -0.1051,  0.3423, -0.3772, -0.4250,\n",
      "         -0.0411, -0.2832, -0.1304,  0.0504],\n",
      "        [-0.3879,  0.3073, -0.2714,  0.3431,  0.1462, -0.0839, -0.3914,  0.0740,\n",
      "         -0.2498,  0.3865, -0.3762, -0.1181],\n",
      "        [-0.2465, -0.2876, -0.2333, -0.0443,  0.0303,  0.0758,  0.2285, -0.1827,\n",
      "         -0.2775, -0.0942,  0.4214, -0.0546],\n",
      "        [-0.3765,  0.3509,  0.1088,  0.0776,  0.0768,  0.3120, -0.2036,  0.3259,\n",
      "          0.4300, -0.1153,  0.2823,  0.2467],\n",
      "        [ 0.4188, -0.1041, -0.2660, -0.1660, -0.3043,  0.0153,  0.4312,  0.4339,\n",
      "          0.3378,  0.0443,  0.0097,  0.2961]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2655, -0.0444, -0.1131,  0.1768, -0.0155],\n",
      "        [-0.3142, -0.2104,  0.3627,  0.3724, -0.1743],\n",
      "        [-0.0960, -0.2216, -0.1460,  0.4077, -0.3978],\n",
      "        [ 0.2134, -0.4020, -0.2134, -0.0911,  0.0310],\n",
      "        [-0.0726, -0.2044, -0.1995, -0.2720, -0.3122],\n",
      "        [-0.2786,  0.4288, -0.2107, -0.3719,  0.3074],\n",
      "        [ 0.1735,  0.3076, -0.4448, -0.4257, -0.3174],\n",
      "        [-0.2356, -0.0010,  0.1934,  0.2618, -0.3847],\n",
      "        [ 0.1784, -0.2586,  0.1028,  0.1404,  0.0716],\n",
      "        [ 0.1582, -0.0223,  0.2952,  0.0933,  0.3918],\n",
      "        [ 0.0969, -0.2367,  0.2872,  0.0242,  0.4322],\n",
      "        [-0.0495,  0.4425, -0.2611,  0.2248, -0.3336],\n",
      "        [ 0.3070,  0.0812,  0.2539, -0.3851, -0.4449],\n",
      "        [ 0.2155, -0.1840,  0.1771, -0.2653, -0.1382],\n",
      "        [ 0.0020,  0.2693,  0.2525, -0.0399, -0.1265],\n",
      "        [-0.0078,  0.2305, -0.3790, -0.1367, -0.4311],\n",
      "        [ 0.0646, -0.0529,  0.2533,  0.3573, -0.3824],\n",
      "        [-0.1979, -0.0719, -0.0045, -0.1021, -0.2812],\n",
      "        [-0.1728, -0.0115,  0.3596, -0.1140,  0.2953],\n",
      "        [-0.3615,  0.0200, -0.3490, -0.4197,  0.0443]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2048,  0.3292,  0.3532, -0.4451, -0.0312, -0.0764, -0.2549, -0.3122,\n",
      "        -0.1893,  0.1974,  0.1063,  0.2692, -0.0267,  0.2323,  0.0865, -0.0975,\n",
      "        -0.0261, -0.4067, -0.0103, -0.1469], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1497, -0.1796, -0.0978, -0.3302,  0.0262, -0.0182, -0.1178,  0.3882,\n",
      "         0.3001,  0.1263, -0.1647,  0.0570, -0.3077,  0.3116,  0.4177, -0.0668,\n",
      "         0.3449,  0.4197, -0.0269, -0.1661], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0226,  0.0739, -0.4140, -0.0279, -0.1617,  0.2984, -0.0128,  0.2942,\n",
      "          0.3978, -0.1402,  0.0963, -0.0383],\n",
      "        [-0.1949, -0.2481,  0.0103,  0.1359, -0.0787,  0.0759,  0.2795,  0.1864,\n",
      "          0.1844,  0.1257, -0.3438, -0.2706],\n",
      "        [-0.3316,  0.2939, -0.3939, -0.3339,  0.2945,  0.2644, -0.4228,  0.2584,\n",
      "         -0.1020,  0.0964, -0.2802, -0.0679],\n",
      "        [ 0.0994,  0.3410,  0.2712, -0.2432, -0.2933, -0.0272,  0.1404,  0.2452,\n",
      "         -0.4456, -0.0365,  0.0158, -0.2089],\n",
      "        [ 0.3527, -0.1187, -0.4264, -0.2670,  0.0143, -0.3328,  0.1021,  0.4351,\n",
      "          0.0183, -0.1102,  0.4213,  0.3302],\n",
      "        [ 0.2972,  0.0339,  0.0204, -0.3468,  0.0455,  0.4350,  0.0236, -0.3991,\n",
      "          0.2455,  0.4014,  0.3749,  0.0211],\n",
      "        [ 0.0840,  0.0724, -0.1833, -0.0653,  0.3648,  0.0456,  0.4215, -0.2970,\n",
      "         -0.0654,  0.0052, -0.2662,  0.3453],\n",
      "        [ 0.3123, -0.2412,  0.3940,  0.4170, -0.2630, -0.0154,  0.4457, -0.2903,\n",
      "         -0.0701, -0.3069,  0.3227,  0.0725],\n",
      "        [ 0.1862,  0.3209, -0.0710, -0.4470,  0.0219, -0.0346,  0.1622,  0.2088,\n",
      "         -0.2224, -0.1762,  0.2819,  0.1273],\n",
      "        [ 0.1024,  0.1991,  0.2080, -0.3231,  0.0357,  0.0428, -0.4320,  0.0949,\n",
      "         -0.0060,  0.3469, -0.4269,  0.4207],\n",
      "        [-0.2189,  0.2635,  0.3304, -0.0555, -0.2288, -0.0742, -0.2789,  0.0553,\n",
      "          0.1880,  0.0924, -0.2575,  0.2444],\n",
      "        [ 0.4104, -0.1361,  0.2322, -0.0295,  0.1803, -0.3189, -0.3819, -0.0127,\n",
      "         -0.3768,  0.1611,  0.4187, -0.0877],\n",
      "        [ 0.0043,  0.0680, -0.2161, -0.0229,  0.1152,  0.3617, -0.3710, -0.0089,\n",
      "         -0.3649, -0.0396, -0.0118, -0.1865],\n",
      "        [ 0.2743,  0.3068, -0.1735, -0.0623, -0.1371,  0.0120,  0.1474,  0.4135,\n",
      "         -0.4102,  0.1816, -0.2693, -0.3652],\n",
      "        [ 0.3444, -0.1332, -0.2508,  0.1227, -0.0931, -0.4093, -0.2333, -0.1889,\n",
      "         -0.0349, -0.2952, -0.4307,  0.2487],\n",
      "        [-0.3840, -0.0541,  0.3839, -0.1646, -0.2957,  0.1194,  0.3903, -0.0493,\n",
      "         -0.0264,  0.2090,  0.0560,  0.0857],\n",
      "        [ 0.2367,  0.2033, -0.3203, -0.1766,  0.3055,  0.0690,  0.1042,  0.4296,\n",
      "          0.2768,  0.1785,  0.4279, -0.3934],\n",
      "        [ 0.0694,  0.1168, -0.0778, -0.2100,  0.0825, -0.3697, -0.1905,  0.3396,\n",
      "         -0.1643, -0.1288,  0.2006, -0.1131],\n",
      "        [ 0.0657, -0.4470,  0.2546, -0.3979,  0.0596, -0.4437, -0.3838,  0.3598,\n",
      "         -0.2463, -0.0154,  0.0199,  0.4115],\n",
      "        [ 0.1428,  0.2183, -0.1913, -0.1533,  0.3253,  0.1639,  0.1122, -0.3372,\n",
      "         -0.3569,  0.0903, -0.3356,  0.3136]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.3726, -0.1852, -0.2882,  0.4329, -0.2386],\n",
      "        [-0.3564, -0.3246,  0.0777,  0.0868,  0.2888],\n",
      "        [ 0.3601,  0.1907,  0.0638,  0.4039, -0.1846],\n",
      "        [-0.0784,  0.3787, -0.1505,  0.2398,  0.0959],\n",
      "        [ 0.1579, -0.1023, -0.3809,  0.3207,  0.3682],\n",
      "        [-0.3551, -0.2093,  0.0190,  0.2216, -0.0633],\n",
      "        [-0.1961,  0.3480, -0.2245,  0.4064,  0.0076],\n",
      "        [ 0.2348,  0.1051,  0.0787,  0.3291, -0.0224],\n",
      "        [ 0.3155,  0.1476, -0.2496,  0.2931, -0.3177],\n",
      "        [ 0.2328, -0.0958,  0.1388, -0.0535,  0.0884],\n",
      "        [-0.1351,  0.1853,  0.2088, -0.4091,  0.3943],\n",
      "        [-0.3606, -0.1996,  0.1761,  0.4122,  0.1454],\n",
      "        [-0.2496,  0.0787, -0.2684,  0.2104,  0.0229],\n",
      "        [ 0.0436, -0.3430,  0.2387,  0.4249, -0.3102],\n",
      "        [ 0.1521, -0.1972, -0.1199,  0.3959, -0.4186],\n",
      "        [-0.0844,  0.1608,  0.2031, -0.1748, -0.2441],\n",
      "        [ 0.0902, -0.4071,  0.0594, -0.2829, -0.0817],\n",
      "        [ 0.4026, -0.3714, -0.2212, -0.3441,  0.2666],\n",
      "        [ 0.3694, -0.2892,  0.2822,  0.2865, -0.3842],\n",
      "        [ 0.1526,  0.2033, -0.0798,  0.3008, -0.0278]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0581,  0.2509, -0.4089, -0.4392,  0.0831,  0.0493,  0.0317, -0.2740,\n",
      "         0.3564, -0.2765, -0.1978, -0.3775, -0.4454,  0.1082, -0.1802,  0.2737,\n",
      "         0.4317,  0.1453,  0.3910, -0.3113], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2356,  0.2431, -0.1790, -0.0317, -0.2684,  0.0431, -0.4272, -0.2670,\n",
      "        -0.3855, -0.0564,  0.0456, -0.3596, -0.1643,  0.2685,  0.0217,  0.0784,\n",
      "        -0.1975, -0.1315, -0.3965,  0.4166], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in lstm.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((12+5)*5 + 5)*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "?lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 12])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 5, 12)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, hidden = lstm(x)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.randn(2, 4, 5)\n",
    "state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2, hidden2 = lstm(x, (state, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 5, 10]), tuple, torch.Size([2, 4, 5]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.size(), type(hidden2), hidden2[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(embed_size, hidden_size, n_layer, batch_first=True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0286,  0.0102,  0.0196,  ...,  0.0140, -0.0306,  0.0162],\n",
       "         [ 0.0073,  0.0275, -0.0246,  ..., -0.0119,  0.0383,  0.0296],\n",
       "         [-0.0230, -0.0301, -0.0402,  ..., -0.0140,  0.0097,  0.0410],\n",
       "         ...,\n",
       "         [ 0.0088,  0.0129,  0.0204,  ...,  0.0042, -0.0166,  0.0139],\n",
       "         [ 0.0035,  0.0292, -0.0052,  ..., -0.0033, -0.0247, -0.0149],\n",
       "         [ 0.0304, -0.0205, -0.0235,  ..., -0.0435, -0.0082,  0.0070]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0332,  0.0117, -0.0223,  ..., -0.0188, -0.0090,  0.0232],\n",
       "         [-0.0044,  0.0032,  0.0183,  ..., -0.0309, -0.0030,  0.0329],\n",
       "         [-0.0231, -0.0378,  0.0360,  ..., -0.0179, -0.0228, -0.0330],\n",
       "         ...,\n",
       "         [-0.0014, -0.0154, -0.0263,  ..., -0.0001, -0.0220, -0.0228],\n",
       "         [ 0.0007,  0.0211,  0.0364,  ..., -0.0040, -0.0417, -0.0221],\n",
       "         [ 0.0077, -0.0442,  0.0341,  ...,  0.0277, -0.0085,  0.0205]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0049,  0.0080,  0.0051,  ...,  0.0374, -0.0187, -0.0251],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0053, -0.0392,  0.0417,  ..., -0.0322, -0.0347,  0.0204],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.all_weights[1] # 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3, 1000, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1000, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0253, -0.0033,  0.0074, -0.0321,  0.0448,  0.0364,  0.0274, -0.0126,\n",
       "        -0.0314, -0.0074,  0.0296,  0.0046, -0.0231, -0.0112,  0.0002,  0.0588,\n",
       "         0.0282,  0.0186, -0.0107,  0.0064], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0, -1, :512][:20]   # 1.前向传播时，output中最后一个time step的前512个与hn最后一层前向传播的输出应该一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0253, -0.0033,  0.0074, -0.0321,  0.0448,  0.0364,  0.0274, -0.0126,\n",
       "        -0.0314, -0.0074,  0.0296,  0.0046, -0.0231, -0.0112,  0.0002,  0.0588,\n",
       "         0.0282,  0.0186, -0.0107,  0.0064], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn[2, 0][:20]  # 最后一层 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0496, -0.0064,  0.0153, -0.0658,  0.0887,  0.0693,  0.0537, -0.0262,\n",
       "        -0.0664, -0.0149,  0.0573,  0.0095, -0.0491, -0.0215,  0.0003,  0.1142,\n",
       "         0.0567,  0.0350, -0.0211,  0.0126], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn[2, 0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0067,  0.0291,  0.0195, -0.0040,  0.0222, -0.0016,  0.0204,  0.0483,\n",
       "         0.0391, -0.0150, -0.0355,  0.0069, -0.0433,  0.0397, -0.0110, -0.0593,\n",
       "         0.0156, -0.0023,  0.0674, -0.0159], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0, 0, 512:][:20]   # 2.后向传播时，output中最后一个time step的后20个与hn最后一层后向传播的输出应该一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0067,  0.0291,  0.0195, -0.0040,  0.0222, -0.0016,  0.0204,  0.0483,\n",
       "         0.0391, -0.0150, -0.0355,  0.0069, -0.0433,  0.0397, -0.0110, -0.0593,\n",
       "         0.0156, -0.0023,  0.0674, -0.0159], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn[3, 0][:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2000, 640])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.cat((x, output), 2)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2000, 1152])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = F.relu(out)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1152, 2000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = out.permute(0, 2, 1).contiguous()\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool = nn.MaxPool1d(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1152])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = maxpool(out).squeeze()\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(512 * 2 + 128, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2000, 1024])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0890,  0.0503, -0.1258,  0.0348,  0.0773,  0.0296,  0.0683, -0.1334,\n",
       "        -0.0785,  0.1435], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 512])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2 = nn.LSTM(embed_size, hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, (h, c) = lstm2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.0007e-02,  1.1504e-01, -8.0164e-03, -2.8628e-02,  4.3624e-02,\n",
       "          -4.8098e-02, -8.9852e-02, -2.0751e-02, -1.4995e-02,  2.1779e-02,\n",
       "           1.4510e-01,  3.7402e-02, -2.4306e-02,  8.3935e-02,  1.3019e-01,\n",
       "           5.2696e-02,  5.8331e-03,  2.3580e-02,  5.0516e-03, -1.6813e-01,\n",
       "           2.0978e-02,  7.0036e-02,  2.5464e-02, -8.2757e-03, -8.2930e-02,\n",
       "          -2.4754e-01,  3.6266e-02, -8.9510e-02,  1.0058e-01, -3.9296e-02,\n",
       "          -3.2925e-02, -3.0055e-02, -1.1519e-01,  1.6550e-02, -1.0098e-01,\n",
       "           2.4721e-02, -4.6358e-02,  1.4646e-01,  6.0281e-02, -3.3340e-02,\n",
       "          -1.5491e-01, -1.3073e-01, -1.1565e-01,  4.8550e-02, -5.9586e-02,\n",
       "          -1.9076e-01, -1.0272e-01, -8.1003e-02,  7.1642e-02, -7.8382e-02,\n",
       "          -6.5359e-02,  1.9230e-03,  1.1971e-01,  1.7767e-01,  3.5265e-02,\n",
       "           4.9145e-02, -9.9055e-02,  3.6508e-02,  1.4252e-01, -1.0448e-01,\n",
       "           2.6643e-02, -1.9212e-02,  2.4304e-02, -1.3443e-01, -9.2144e-02,\n",
       "           5.3559e-02, -4.2672e-03, -2.4218e-02, -8.0495e-02,  1.7242e-02,\n",
       "          -4.9427e-02,  4.4240e-02,  6.4881e-02, -3.1927e-02, -4.1174e-03,\n",
       "           5.2553e-02,  8.1592e-03, -5.2709e-02, -1.2864e-01,  9.6175e-02,\n",
       "          -2.6540e-02,  9.0228e-02,  9.6619e-02, -2.0535e-02, -1.2025e-01,\n",
       "          -4.9674e-03,  4.3318e-03,  1.3496e-02, -7.9542e-02,  1.0453e-01,\n",
       "           7.4923e-02,  7.3094e-02, -1.3057e-01,  5.6533e-02,  8.3401e-02,\n",
       "           7.6128e-02,  1.1206e-01,  1.7906e-01,  1.1440e-02,  1.1590e-01,\n",
       "           1.2442e-01,  2.5395e-03,  1.4239e-01, -6.4536e-02, -1.9207e-02,\n",
       "          -1.2009e-01, -7.5115e-02, -7.7218e-02,  3.5519e-02,  1.0052e-02,\n",
       "          -4.9675e-02, -2.2063e-02, -3.1460e-02,  5.1231e-02, -6.0980e-02,\n",
       "           1.8450e-01, -1.6191e-01, -6.9094e-02, -4.9068e-02, -1.0726e-01,\n",
       "           3.3687e-02,  9.3223e-02, -6.6715e-02, -1.3075e-01,  1.1311e-01,\n",
       "           2.4749e-02, -1.7373e-02, -2.6334e-02,  1.2021e-01,  5.8809e-02,\n",
       "          -4.6516e-02,  6.0294e-02,  4.1677e-02,  6.3027e-02, -8.5039e-02,\n",
       "          -7.4168e-03,  1.1598e-01,  8.1214e-02,  3.3738e-03,  1.3753e-01,\n",
       "           9.1974e-02,  5.6764e-02,  2.9198e-02,  3.8549e-02, -7.2533e-02,\n",
       "           2.1009e-02, -9.9600e-02, -5.1247e-02,  7.3684e-02, -7.1883e-02,\n",
       "           8.8858e-02,  7.5018e-03, -9.0764e-02,  1.2080e-01,  2.6287e-02,\n",
       "           6.1706e-02,  2.4663e-02, -4.5133e-02,  1.0267e-02, -8.7190e-03,\n",
       "          -9.2371e-02, -7.1891e-02,  7.3779e-02,  2.1139e-02, -5.3997e-02,\n",
       "          -1.1839e-02,  1.9527e-01,  4.6460e-02, -4.8582e-02,  5.4783e-02,\n",
       "          -7.9759e-02,  5.5878e-02, -8.3230e-03, -2.4682e-02,  3.1222e-02,\n",
       "           2.0790e-02,  1.1892e-01, -2.7601e-02,  3.1272e-02,  1.5495e-01,\n",
       "           4.6384e-02,  1.2260e-02, -4.6263e-02, -7.3618e-02, -7.3262e-02,\n",
       "          -7.2013e-02,  8.7175e-02, -8.2905e-02,  1.6098e-03, -3.3826e-02,\n",
       "          -6.7936e-02, -7.4959e-02,  1.4208e-01,  2.2465e-02, -4.1599e-02,\n",
       "          -8.7325e-05,  9.6541e-02,  3.6704e-02, -8.7334e-02,  3.9839e-03,\n",
       "          -5.5148e-05, -2.5399e-03,  7.9434e-02,  1.4847e-01,  1.2688e-01,\n",
       "           4.2336e-02, -3.0932e-02,  5.9719e-02, -9.1597e-03,  4.8454e-02,\n",
       "          -8.8072e-02,  2.1168e-02,  1.0777e-01,  8.9300e-02,  1.6464e-01,\n",
       "           7.0005e-02, -6.7566e-02,  4.7737e-02,  7.2435e-03, -7.5129e-02,\n",
       "          -4.1154e-03, -7.1230e-02,  4.3497e-02,  6.4884e-02, -1.7183e-01,\n",
       "          -5.5204e-02,  5.0132e-02,  9.9359e-03,  2.8914e-02,  1.1788e-01,\n",
       "           1.0588e-01,  9.1369e-02,  4.0419e-02, -7.1695e-02,  3.2513e-02,\n",
       "          -3.4417e-02,  1.9835e-03,  1.2939e-01, -2.4173e-02, -5.6249e-02,\n",
       "          -2.1764e-02, -7.7636e-02,  2.5183e-03, -1.8103e-02, -6.3961e-02,\n",
       "           4.5948e-02,  4.7846e-02,  9.2244e-02, -5.8319e-02,  1.3101e-01,\n",
       "          -4.7180e-02,  8.6131e-02, -6.8465e-02, -4.9132e-02,  7.9576e-02,\n",
       "           1.2572e-01,  2.3092e-02,  2.0651e-01,  1.9158e-02,  3.3626e-02,\n",
       "          -1.0379e-01, -2.5270e-02, -3.9977e-02,  3.7557e-02, -5.2042e-02,\n",
       "          -1.2674e-02,  8.4779e-02, -1.0253e-01, -8.4361e-02,  3.9801e-02,\n",
       "           7.7904e-03,  3.4904e-02, -7.3395e-02,  6.1938e-02, -8.7102e-02,\n",
       "           1.2131e-01, -3.2865e-02,  5.8395e-02,  4.1787e-02, -6.0713e-02,\n",
       "           1.3129e-01, -8.0174e-02, -7.8174e-02,  1.9304e-02,  1.0547e-03,\n",
       "          -5.9805e-02,  7.3314e-02,  2.2737e-03,  1.0695e-01,  1.8958e-02,\n",
       "          -1.0446e-01,  7.7246e-02,  5.5245e-02, -1.2542e-01,  6.1454e-02,\n",
       "           8.2037e-02,  7.1692e-03, -1.4673e-01, -1.3004e-01,  9.6617e-02,\n",
       "           7.3185e-02, -1.9859e-02,  7.0476e-02,  4.7470e-02,  7.7025e-02,\n",
       "           6.0563e-02, -1.6325e-01, -1.1168e-01, -3.8108e-02,  4.4020e-02,\n",
       "           6.7287e-02,  3.0478e-03,  1.1467e-01, -1.3846e-03,  6.0040e-02,\n",
       "           6.8949e-02,  2.7259e-02, -1.9478e-01, -1.2187e-01,  4.2804e-02,\n",
       "          -5.7329e-02, -1.6599e-01, -5.3577e-02, -2.0049e-02, -4.8839e-02,\n",
       "          -9.9543e-02,  7.7328e-02, -2.0579e-02, -7.3275e-03,  8.7166e-02,\n",
       "          -9.3984e-02, -7.4863e-02,  5.6580e-03, -1.5165e-03, -3.3237e-02,\n",
       "          -8.4217e-02,  9.8262e-02,  1.2676e-02, -5.3364e-02,  3.2813e-02,\n",
       "          -1.4311e-03, -4.9402e-02, -4.7880e-02,  1.0401e-01,  1.1836e-01,\n",
       "           6.3220e-03, -1.2924e-01, -5.7734e-02, -1.1121e-01,  2.1814e-02,\n",
       "           9.7104e-02, -3.8375e-02,  8.2540e-02, -2.7004e-02, -9.2509e-02,\n",
       "          -1.5423e-01,  5.9958e-02, -1.0215e-01, -1.1876e-02,  8.4755e-02,\n",
       "           8.8929e-02,  1.6585e-01,  2.3106e-02,  8.8826e-02,  3.4110e-02,\n",
       "           2.2352e-02,  9.3554e-02, -8.8438e-03, -5.3645e-02,  2.5369e-02,\n",
       "          -1.8348e-02,  6.6177e-02,  1.5492e-02, -2.5195e-01, -3.5408e-02,\n",
       "           1.4265e-02, -1.4987e-01, -1.4694e-01, -6.8817e-02,  6.1603e-02,\n",
       "          -5.9731e-02,  9.3735e-02,  7.1699e-02,  8.2016e-02, -2.2490e-02,\n",
       "           8.7528e-02,  1.1886e-01, -1.6249e-02, -4.8423e-02,  9.3531e-03,\n",
       "          -2.7489e-02,  1.0292e-01, -9.2805e-03, -1.4857e-02,  5.9970e-02,\n",
       "          -3.7858e-02,  1.7255e-02, -2.9969e-02, -3.1358e-02, -5.9895e-02,\n",
       "           2.1142e-01,  2.8900e-02,  3.1919e-02, -1.5263e-01, -2.6323e-02,\n",
       "           6.1877e-02, -6.0062e-02, -7.6739e-02, -1.8323e-02,  4.7158e-03,\n",
       "           1.0200e-01,  4.3625e-02, -4.9267e-02, -7.2887e-02, -8.2461e-02,\n",
       "           5.0962e-02, -1.9889e-02,  2.7327e-02, -1.0888e-02,  9.9848e-02,\n",
       "          -3.6195e-02,  3.4013e-02,  3.6188e-02,  8.7347e-02,  4.2373e-02,\n",
       "           9.5448e-02,  1.4470e-01, -3.1801e-03,  8.1629e-02,  3.8269e-02,\n",
       "          -7.1590e-02, -3.1468e-02, -8.8048e-02, -1.1218e-03, -2.6504e-02,\n",
       "          -7.0530e-02, -1.0202e-01, -7.2242e-03,  1.3694e-01,  3.3778e-02,\n",
       "          -3.1687e-02,  6.2253e-02, -1.2886e-02,  1.0813e-01, -5.0981e-02,\n",
       "           1.4208e-01, -7.1248e-02,  7.4595e-02, -1.3704e-01, -1.5447e-01,\n",
       "           4.3769e-02,  1.1151e-01,  1.4091e-02,  1.6656e-01,  5.3290e-02,\n",
       "          -5.8412e-02,  4.0668e-02,  2.8279e-02,  3.1146e-02, -3.8950e-02,\n",
       "           1.1634e-01, -1.2056e-01,  6.2236e-02, -6.5030e-02,  1.3279e-01,\n",
       "          -4.7331e-02,  1.0110e-01,  7.7953e-02,  1.3866e-01,  4.9400e-02,\n",
       "           5.3632e-02, -1.6437e-01,  8.5948e-02, -2.3794e-02, -3.8561e-02,\n",
       "          -5.6773e-02, -6.8619e-02, -1.4354e-01,  2.8074e-02,  3.9166e-03,\n",
       "          -2.0849e-01, -6.4102e-02, -1.3628e-01,  2.1684e-02,  2.1554e-02,\n",
       "          -1.6689e-01,  1.6240e-02, -8.0030e-02, -1.8164e-02, -1.0486e-01,\n",
       "           1.9342e-01,  5.4230e-02,  8.4926e-03, -2.5813e-02,  1.4346e-02,\n",
       "           7.0630e-02,  7.0765e-02,  1.1736e-01, -6.4259e-02,  4.2817e-02,\n",
       "          -1.9960e-01,  8.4633e-02, -9.7665e-02,  1.8205e-02,  6.6480e-02,\n",
       "          -1.4824e-01, -3.4187e-02, -1.1912e-01, -5.4016e-03,  1.6288e-01,\n",
       "          -4.1519e-02,  8.3689e-02]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2492]],\n",
       "\n",
       "        [[-0.5608]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 1, 1)#为1可以扩展为3和3 \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(2, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3034,  0.2991, -0.4937],\n",
       "         [-0.8327,  1.0045,  0.2131],\n",
       "         [-0.8213,  0.3709, -0.2830]],\n",
       "\n",
       "        [[ 0.8204, -2.0705,  0.1645],\n",
       "         [ 1.8283,  0.9639, -0.8203],\n",
       "         [-0.1718,  0.4644, -1.1035]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2631, -2.2631, -2.2631],\n",
       "         [-2.2631, -2.2631, -2.2631],\n",
       "         [-2.2631, -2.2631, -2.2631]],\n",
       "\n",
       "        [[ 1.2091,  1.2091,  1.2091],\n",
       "         [ 1.2091,  1.2091,  1.2091],\n",
       "         [ 1.2091,  1.2091,  1.2091]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.expand_as(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.expand_as(y).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2492,  0.2492,  0.2492],\n",
       "         [ 0.2492,  0.2492,  0.2492],\n",
       "         [ 0.2492,  0.2492,  0.2492]],\n",
       "\n",
       "        [[-0.5608, -0.5608, -0.5608],\n",
       "         [-0.5608, -0.5608, -0.5608],\n",
       "         [-0.5608, -0.5608, -0.5608]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
