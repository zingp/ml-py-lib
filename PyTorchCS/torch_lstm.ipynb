{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_rand_seed(seed=1):\n",
    "    print(\"Random Seed: \", seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # torch.backends.cudnn.enabled = False       \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  1\n"
     ]
    }
   ],
   "source": [
    "set_rand_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "hidden_size = 512\n",
    "n_layer = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义LSTM\n",
    "- 输入\n",
    "- output保存了最后一层，每个time step的输出h，如果是双向LSTM，每个time step的输出h = [h正向, h逆向] (同一个time step的正向和逆向的h连接起来)。\n",
    "- h_n保存了每一层，最后一个time step的输出h，如果是双向LSTM，单独保存前向和后向的最后一个time step的输出h。\n",
    "- c_n与h_n一致，只是它保存的是c的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(embed_size, hidden_size, n_layer, batch_first=True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0286,  0.0102,  0.0196,  ...,  0.0140, -0.0306,  0.0162],\n",
       "         [ 0.0073,  0.0275, -0.0246,  ..., -0.0119,  0.0383,  0.0296],\n",
       "         [-0.0230, -0.0301, -0.0402,  ..., -0.0140,  0.0097,  0.0410],\n",
       "         ...,\n",
       "         [ 0.0088,  0.0129,  0.0204,  ...,  0.0042, -0.0166,  0.0139],\n",
       "         [ 0.0035,  0.0292, -0.0052,  ..., -0.0033, -0.0247, -0.0149],\n",
       "         [ 0.0304, -0.0205, -0.0235,  ..., -0.0435, -0.0082,  0.0070]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0332,  0.0117, -0.0223,  ..., -0.0188, -0.0090,  0.0232],\n",
       "         [-0.0044,  0.0032,  0.0183,  ..., -0.0309, -0.0030,  0.0329],\n",
       "         [-0.0231, -0.0378,  0.0360,  ..., -0.0179, -0.0228, -0.0330],\n",
       "         ...,\n",
       "         [-0.0014, -0.0154, -0.0263,  ..., -0.0001, -0.0220, -0.0228],\n",
       "         [ 0.0007,  0.0211,  0.0364,  ..., -0.0040, -0.0417, -0.0221],\n",
       "         [ 0.0077, -0.0442,  0.0341,  ...,  0.0277, -0.0085,  0.0205]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0049,  0.0080,  0.0051,  ...,  0.0374, -0.0187, -0.0251],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0053, -0.0392,  0.0417,  ..., -0.0322, -0.0347,  0.0204],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.all_weights[1] # 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3, 1000, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1000, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0253, -0.0033,  0.0074, -0.0321,  0.0448,  0.0364,  0.0274, -0.0126,\n",
       "        -0.0314, -0.0074,  0.0296,  0.0046, -0.0231, -0.0112,  0.0002,  0.0588,\n",
       "         0.0282,  0.0186, -0.0107,  0.0064], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0, -1, :512][:20]   # 1.前向传播时，output中最后一个time step的前512个与hn最后一层前向传播的输出应该一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0253, -0.0033,  0.0074, -0.0321,  0.0448,  0.0364,  0.0274, -0.0126,\n",
       "        -0.0314, -0.0074,  0.0296,  0.0046, -0.0231, -0.0112,  0.0002,  0.0588,\n",
       "         0.0282,  0.0186, -0.0107,  0.0064], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn[2, 0][:20]  # 最后一层 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0496, -0.0064,  0.0153, -0.0658,  0.0887,  0.0693,  0.0537, -0.0262,\n",
       "        -0.0664, -0.0149,  0.0573,  0.0095, -0.0491, -0.0215,  0.0003,  0.1142,\n",
       "         0.0567,  0.0350, -0.0211,  0.0126], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn[2, 0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0067,  0.0291,  0.0195, -0.0040,  0.0222, -0.0016,  0.0204,  0.0483,\n",
       "         0.0391, -0.0150, -0.0355,  0.0069, -0.0433,  0.0397, -0.0110, -0.0593,\n",
       "         0.0156, -0.0023,  0.0674, -0.0159], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0, 0, 512:][:20]   # 2.后向传播时，output中最后一个time step的后20个与hn最后一层后向传播的输出应该一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0067,  0.0291,  0.0195, -0.0040,  0.0222, -0.0016,  0.0204,  0.0483,\n",
       "         0.0391, -0.0150, -0.0355,  0.0069, -0.0433,  0.0397, -0.0110, -0.0593,\n",
       "         0.0156, -0.0023,  0.0674, -0.0159], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn[3, 0][:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2000, 640])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.cat((x, output), 2)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2000, 1152])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = F.relu(out)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1152, 2000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = out.permute(0, 2, 1).contiguous()\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool = nn.MaxPool1d(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1152])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = maxpool(out).squeeze()\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(512 * 2 + 128, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2000, 1024])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0890,  0.0503, -0.1258,  0.0348,  0.0773,  0.0296,  0.0683, -0.1334,\n",
       "        -0.0785,  0.1435], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 512])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2 = nn.LSTM(embed_size, hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, (h, c) = lstm2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.0007e-02,  1.1504e-01, -8.0164e-03, -2.8628e-02,  4.3624e-02,\n",
       "          -4.8098e-02, -8.9852e-02, -2.0751e-02, -1.4995e-02,  2.1779e-02,\n",
       "           1.4510e-01,  3.7402e-02, -2.4306e-02,  8.3935e-02,  1.3019e-01,\n",
       "           5.2696e-02,  5.8331e-03,  2.3580e-02,  5.0516e-03, -1.6813e-01,\n",
       "           2.0978e-02,  7.0036e-02,  2.5464e-02, -8.2757e-03, -8.2930e-02,\n",
       "          -2.4754e-01,  3.6266e-02, -8.9510e-02,  1.0058e-01, -3.9296e-02,\n",
       "          -3.2925e-02, -3.0055e-02, -1.1519e-01,  1.6550e-02, -1.0098e-01,\n",
       "           2.4721e-02, -4.6358e-02,  1.4646e-01,  6.0281e-02, -3.3340e-02,\n",
       "          -1.5491e-01, -1.3073e-01, -1.1565e-01,  4.8550e-02, -5.9586e-02,\n",
       "          -1.9076e-01, -1.0272e-01, -8.1003e-02,  7.1642e-02, -7.8382e-02,\n",
       "          -6.5359e-02,  1.9230e-03,  1.1971e-01,  1.7767e-01,  3.5265e-02,\n",
       "           4.9145e-02, -9.9055e-02,  3.6508e-02,  1.4252e-01, -1.0448e-01,\n",
       "           2.6643e-02, -1.9212e-02,  2.4304e-02, -1.3443e-01, -9.2144e-02,\n",
       "           5.3559e-02, -4.2672e-03, -2.4218e-02, -8.0495e-02,  1.7242e-02,\n",
       "          -4.9427e-02,  4.4240e-02,  6.4881e-02, -3.1927e-02, -4.1174e-03,\n",
       "           5.2553e-02,  8.1592e-03, -5.2709e-02, -1.2864e-01,  9.6175e-02,\n",
       "          -2.6540e-02,  9.0228e-02,  9.6619e-02, -2.0535e-02, -1.2025e-01,\n",
       "          -4.9674e-03,  4.3318e-03,  1.3496e-02, -7.9542e-02,  1.0453e-01,\n",
       "           7.4923e-02,  7.3094e-02, -1.3057e-01,  5.6533e-02,  8.3401e-02,\n",
       "           7.6128e-02,  1.1206e-01,  1.7906e-01,  1.1440e-02,  1.1590e-01,\n",
       "           1.2442e-01,  2.5395e-03,  1.4239e-01, -6.4536e-02, -1.9207e-02,\n",
       "          -1.2009e-01, -7.5115e-02, -7.7218e-02,  3.5519e-02,  1.0052e-02,\n",
       "          -4.9675e-02, -2.2063e-02, -3.1460e-02,  5.1231e-02, -6.0980e-02,\n",
       "           1.8450e-01, -1.6191e-01, -6.9094e-02, -4.9068e-02, -1.0726e-01,\n",
       "           3.3687e-02,  9.3223e-02, -6.6715e-02, -1.3075e-01,  1.1311e-01,\n",
       "           2.4749e-02, -1.7373e-02, -2.6334e-02,  1.2021e-01,  5.8809e-02,\n",
       "          -4.6516e-02,  6.0294e-02,  4.1677e-02,  6.3027e-02, -8.5039e-02,\n",
       "          -7.4168e-03,  1.1598e-01,  8.1214e-02,  3.3738e-03,  1.3753e-01,\n",
       "           9.1974e-02,  5.6764e-02,  2.9198e-02,  3.8549e-02, -7.2533e-02,\n",
       "           2.1009e-02, -9.9600e-02, -5.1247e-02,  7.3684e-02, -7.1883e-02,\n",
       "           8.8858e-02,  7.5018e-03, -9.0764e-02,  1.2080e-01,  2.6287e-02,\n",
       "           6.1706e-02,  2.4663e-02, -4.5133e-02,  1.0267e-02, -8.7190e-03,\n",
       "          -9.2371e-02, -7.1891e-02,  7.3779e-02,  2.1139e-02, -5.3997e-02,\n",
       "          -1.1839e-02,  1.9527e-01,  4.6460e-02, -4.8582e-02,  5.4783e-02,\n",
       "          -7.9759e-02,  5.5878e-02, -8.3230e-03, -2.4682e-02,  3.1222e-02,\n",
       "           2.0790e-02,  1.1892e-01, -2.7601e-02,  3.1272e-02,  1.5495e-01,\n",
       "           4.6384e-02,  1.2260e-02, -4.6263e-02, -7.3618e-02, -7.3262e-02,\n",
       "          -7.2013e-02,  8.7175e-02, -8.2905e-02,  1.6098e-03, -3.3826e-02,\n",
       "          -6.7936e-02, -7.4959e-02,  1.4208e-01,  2.2465e-02, -4.1599e-02,\n",
       "          -8.7325e-05,  9.6541e-02,  3.6704e-02, -8.7334e-02,  3.9839e-03,\n",
       "          -5.5148e-05, -2.5399e-03,  7.9434e-02,  1.4847e-01,  1.2688e-01,\n",
       "           4.2336e-02, -3.0932e-02,  5.9719e-02, -9.1597e-03,  4.8454e-02,\n",
       "          -8.8072e-02,  2.1168e-02,  1.0777e-01,  8.9300e-02,  1.6464e-01,\n",
       "           7.0005e-02, -6.7566e-02,  4.7737e-02,  7.2435e-03, -7.5129e-02,\n",
       "          -4.1154e-03, -7.1230e-02,  4.3497e-02,  6.4884e-02, -1.7183e-01,\n",
       "          -5.5204e-02,  5.0132e-02,  9.9359e-03,  2.8914e-02,  1.1788e-01,\n",
       "           1.0588e-01,  9.1369e-02,  4.0419e-02, -7.1695e-02,  3.2513e-02,\n",
       "          -3.4417e-02,  1.9835e-03,  1.2939e-01, -2.4173e-02, -5.6249e-02,\n",
       "          -2.1764e-02, -7.7636e-02,  2.5183e-03, -1.8103e-02, -6.3961e-02,\n",
       "           4.5948e-02,  4.7846e-02,  9.2244e-02, -5.8319e-02,  1.3101e-01,\n",
       "          -4.7180e-02,  8.6131e-02, -6.8465e-02, -4.9132e-02,  7.9576e-02,\n",
       "           1.2572e-01,  2.3092e-02,  2.0651e-01,  1.9158e-02,  3.3626e-02,\n",
       "          -1.0379e-01, -2.5270e-02, -3.9977e-02,  3.7557e-02, -5.2042e-02,\n",
       "          -1.2674e-02,  8.4779e-02, -1.0253e-01, -8.4361e-02,  3.9801e-02,\n",
       "           7.7904e-03,  3.4904e-02, -7.3395e-02,  6.1938e-02, -8.7102e-02,\n",
       "           1.2131e-01, -3.2865e-02,  5.8395e-02,  4.1787e-02, -6.0713e-02,\n",
       "           1.3129e-01, -8.0174e-02, -7.8174e-02,  1.9304e-02,  1.0547e-03,\n",
       "          -5.9805e-02,  7.3314e-02,  2.2737e-03,  1.0695e-01,  1.8958e-02,\n",
       "          -1.0446e-01,  7.7246e-02,  5.5245e-02, -1.2542e-01,  6.1454e-02,\n",
       "           8.2037e-02,  7.1692e-03, -1.4673e-01, -1.3004e-01,  9.6617e-02,\n",
       "           7.3185e-02, -1.9859e-02,  7.0476e-02,  4.7470e-02,  7.7025e-02,\n",
       "           6.0563e-02, -1.6325e-01, -1.1168e-01, -3.8108e-02,  4.4020e-02,\n",
       "           6.7287e-02,  3.0478e-03,  1.1467e-01, -1.3846e-03,  6.0040e-02,\n",
       "           6.8949e-02,  2.7259e-02, -1.9478e-01, -1.2187e-01,  4.2804e-02,\n",
       "          -5.7329e-02, -1.6599e-01, -5.3577e-02, -2.0049e-02, -4.8839e-02,\n",
       "          -9.9543e-02,  7.7328e-02, -2.0579e-02, -7.3275e-03,  8.7166e-02,\n",
       "          -9.3984e-02, -7.4863e-02,  5.6580e-03, -1.5165e-03, -3.3237e-02,\n",
       "          -8.4217e-02,  9.8262e-02,  1.2676e-02, -5.3364e-02,  3.2813e-02,\n",
       "          -1.4311e-03, -4.9402e-02, -4.7880e-02,  1.0401e-01,  1.1836e-01,\n",
       "           6.3220e-03, -1.2924e-01, -5.7734e-02, -1.1121e-01,  2.1814e-02,\n",
       "           9.7104e-02, -3.8375e-02,  8.2540e-02, -2.7004e-02, -9.2509e-02,\n",
       "          -1.5423e-01,  5.9958e-02, -1.0215e-01, -1.1876e-02,  8.4755e-02,\n",
       "           8.8929e-02,  1.6585e-01,  2.3106e-02,  8.8826e-02,  3.4110e-02,\n",
       "           2.2352e-02,  9.3554e-02, -8.8438e-03, -5.3645e-02,  2.5369e-02,\n",
       "          -1.8348e-02,  6.6177e-02,  1.5492e-02, -2.5195e-01, -3.5408e-02,\n",
       "           1.4265e-02, -1.4987e-01, -1.4694e-01, -6.8817e-02,  6.1603e-02,\n",
       "          -5.9731e-02,  9.3735e-02,  7.1699e-02,  8.2016e-02, -2.2490e-02,\n",
       "           8.7528e-02,  1.1886e-01, -1.6249e-02, -4.8423e-02,  9.3531e-03,\n",
       "          -2.7489e-02,  1.0292e-01, -9.2805e-03, -1.4857e-02,  5.9970e-02,\n",
       "          -3.7858e-02,  1.7255e-02, -2.9969e-02, -3.1358e-02, -5.9895e-02,\n",
       "           2.1142e-01,  2.8900e-02,  3.1919e-02, -1.5263e-01, -2.6323e-02,\n",
       "           6.1877e-02, -6.0062e-02, -7.6739e-02, -1.8323e-02,  4.7158e-03,\n",
       "           1.0200e-01,  4.3625e-02, -4.9267e-02, -7.2887e-02, -8.2461e-02,\n",
       "           5.0962e-02, -1.9889e-02,  2.7327e-02, -1.0888e-02,  9.9848e-02,\n",
       "          -3.6195e-02,  3.4013e-02,  3.6188e-02,  8.7347e-02,  4.2373e-02,\n",
       "           9.5448e-02,  1.4470e-01, -3.1801e-03,  8.1629e-02,  3.8269e-02,\n",
       "          -7.1590e-02, -3.1468e-02, -8.8048e-02, -1.1218e-03, -2.6504e-02,\n",
       "          -7.0530e-02, -1.0202e-01, -7.2242e-03,  1.3694e-01,  3.3778e-02,\n",
       "          -3.1687e-02,  6.2253e-02, -1.2886e-02,  1.0813e-01, -5.0981e-02,\n",
       "           1.4208e-01, -7.1248e-02,  7.4595e-02, -1.3704e-01, -1.5447e-01,\n",
       "           4.3769e-02,  1.1151e-01,  1.4091e-02,  1.6656e-01,  5.3290e-02,\n",
       "          -5.8412e-02,  4.0668e-02,  2.8279e-02,  3.1146e-02, -3.8950e-02,\n",
       "           1.1634e-01, -1.2056e-01,  6.2236e-02, -6.5030e-02,  1.3279e-01,\n",
       "          -4.7331e-02,  1.0110e-01,  7.7953e-02,  1.3866e-01,  4.9400e-02,\n",
       "           5.3632e-02, -1.6437e-01,  8.5948e-02, -2.3794e-02, -3.8561e-02,\n",
       "          -5.6773e-02, -6.8619e-02, -1.4354e-01,  2.8074e-02,  3.9166e-03,\n",
       "          -2.0849e-01, -6.4102e-02, -1.3628e-01,  2.1684e-02,  2.1554e-02,\n",
       "          -1.6689e-01,  1.6240e-02, -8.0030e-02, -1.8164e-02, -1.0486e-01,\n",
       "           1.9342e-01,  5.4230e-02,  8.4926e-03, -2.5813e-02,  1.4346e-02,\n",
       "           7.0630e-02,  7.0765e-02,  1.1736e-01, -6.4259e-02,  4.2817e-02,\n",
       "          -1.9960e-01,  8.4633e-02, -9.7665e-02,  1.8205e-02,  6.6480e-02,\n",
       "          -1.4824e-01, -3.4187e-02, -1.1912e-01, -5.4016e-03,  1.6288e-01,\n",
       "          -4.1519e-02,  8.3689e-02]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2492]],\n",
       "\n",
       "        [[-0.5608]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 1, 1)#为1可以扩展为3和3 \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(2, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3034,  0.2991, -0.4937],\n",
       "         [-0.8327,  1.0045,  0.2131],\n",
       "         [-0.8213,  0.3709, -0.2830]],\n",
       "\n",
       "        [[ 0.8204, -2.0705,  0.1645],\n",
       "         [ 1.8283,  0.9639, -0.8203],\n",
       "         [-0.1718,  0.4644, -1.1035]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2631, -2.2631, -2.2631],\n",
       "         [-2.2631, -2.2631, -2.2631],\n",
       "         [-2.2631, -2.2631, -2.2631]],\n",
       "\n",
       "        [[ 1.2091,  1.2091,  1.2091],\n",
       "         [ 1.2091,  1.2091,  1.2091],\n",
       "         [ 1.2091,  1.2091,  1.2091]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.expand_as(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.expand_as(y).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2492,  0.2492,  0.2492],\n",
       "         [ 0.2492,  0.2492,  0.2492],\n",
       "         [ 0.2492,  0.2492,  0.2492]],\n",
       "\n",
       "        [[-0.5608, -0.5608, -0.5608],\n",
       "         [-0.5608, -0.5608, -0.5608],\n",
       "         [-0.5608, -0.5608, -0.5608]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
