{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, class_num):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # in=3, out=96, kernel_size=(11,11), inputs=(227,227,3),stride=4 -> (227-11+2*0)/4 +1 --> 55*55*96\n",
    "            nn.Conv2d(3, 96, (11, 11), stride=4),\n",
    "            nn.ReLU(inplace=True),  # inplace为True，将会改变输入的数据 ，否则不会改变原输入，只会产生新的输出。\n",
    "            nn.MaxPool2d((3,3), stride=2),    # (55-3)/2+1 = 27\n",
    "            # in=96, out=256, kerner=(5,5), inputs=(27,27,96) stride=1, padding=2->27*27*256\n",
    "            nn.Conv2d(96, 256, (5,5), padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((3,3), stride=2),      # (27-3)/2 +1= 13*13*256\n",
    "            # in=256,out=384,kernel=(3,3), inputs=(13,13,256),padding=1\n",
    "            nn.Conv2d(256, 384, (3,3), padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, (3,3), padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, (3,3), padding=1),  # 13*13*256\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((3,3), stride=2),  # 6*6*256 = 9216\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(6*6*256, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, class_num),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        #print(x.size())  #torch.Size([8, 256, 6, 6])  原本是[32,256, 6, 6],我这里有4个核\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(out, y):\n",
    "    _, pred = torch.max(out, 1)  # 最大概率，对应的类别\n",
    "    corr_num = pred.eq(y).sum()  # tensor 得取出结果\n",
    "    acc = corr_num.item() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "# 单epoch的训练\n",
    "def train(model, device, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)               # 各个分类的概率\n",
    "        loss = criterion(out, y)\n",
    "        train_loss += loss\n",
    "        acc = accu(out, y)\n",
    "        train_acc += acc\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss / len(train_loader), train_acc / len(train_loader) \n",
    "\n",
    "def evaluate(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(x)               \n",
    "            loss = criterion(out, y)\n",
    "            test_loss += loss\n",
    "            acc = accu(out, y)\n",
    "            test_acc += acc\n",
    "    return test_loss/len(test_loader), test_acc/len(test_loader)\n",
    "\n",
    "def modify_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(\"pre modify lr is:\", param_group[\"lr\"])\n",
    "        param_group[\"lr\"] = lr\n",
    "        print(\"after modify lr is:\", param_group[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomCrop(32,padding=3),\n",
    "    transforms.Resize(227),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768))#参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])\n",
    "\n",
    "data_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(227),\n",
    "    transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10('data', train=True, download=True, transform=data_trans)\n",
    "test_data = datasets.CIFAR10('data', train=False, download=True, transform=data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(train_data)*0.9)\n",
    "n_valid = len(train_data) - n_train\n",
    "train_datasets, valid_datasets = torch.utils.data.random_split(train_data, [n_train, n_valid])\n",
    "\n",
    "train_loader = DataLoader(train_datasets, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_datasets, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AlexNet(10)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1|Train Loss:2.264634847640991|Train Acc:0.12902007818052594|Val Loss:2.1089842319488525|Val Acc:0.2239251592356688\n",
      "Epoch:2|Train Loss:1.8944400548934937|Train Acc:0.2995735607675906|Val Loss:1.9645589590072632|Val Acc:0.27428343949044587\n",
      "Epoch:3|Train Loss:1.6413158178329468|Train Acc:0.3908359985785359|Val Loss:1.6257750988006592|Val Acc:0.4000796178343949\n",
      "Epoch:4|Train Loss:1.5002524852752686|Train Acc:0.4500710732054016|Val Loss:1.892052412033081|Val Acc:0.4052547770700637\n",
      "Epoch:5|Train Loss:1.383557915687561|Train Acc:0.4945140369580668|Val Loss:1.3451801538467407|Val Acc:0.5073646496815286\n",
      "Epoch:6|Train Loss:1.2675292491912842|Train Acc:0.5407116204690832|Val Loss:1.5601836442947388|Val Acc:0.4703423566878981\n",
      "Epoch:7|Train Loss:1.1717017889022827|Train Acc:0.5777141080312722|Val Loss:1.0991326570510864|Val Acc:0.6078821656050956\n",
      "Epoch:8|Train Loss:1.0791385173797607|Train Acc:0.6139392324093816|Val Loss:1.1225618124008179|Val Acc:0.6058917197452229\n",
      "Epoch:9|Train Loss:0.9910988807678223|Train Acc:0.6472547974413646|Val Loss:0.968218982219696|Val Acc:0.6512738853503185\n",
      "Epoch:10|Train Loss:0.9180089235305786|Train Acc:0.6735074626865671|Val Loss:0.9607487916946411|Val Acc:0.6584394904458599\n",
      "Epoch:11|Train Loss:0.8631911277770996|Train Acc:0.6942519545131486|Val Loss:0.8535736799240112|Val Acc:0.701234076433121\n",
      "Epoch:12|Train Loss:0.8061134815216064|Train Acc:0.7164623312011372|Val Loss:0.8279362916946411|Val Acc:0.7245222929936306\n",
      "Epoch:13|Train Loss:0.7621064782142639|Train Acc:0.7326314854299929|Val Loss:0.8387415409088135|Val Acc:0.7165605095541401\n",
      "Epoch:14|Train Loss:0.7237532734870911|Train Acc:0.7485341151385928|Val Loss:1.054276943206787|Val Acc:0.6626194267515924\n",
      "Epoch:15|Train Loss:0.6881958842277527|Train Acc:0.7609719260838664|Val Loss:0.7426384687423706|Val Acc:0.7496019108280255\n",
      "Epoch:16|Train Loss:0.6573681235313416|Train Acc:0.7712109097370291|Val Loss:0.6813974380493164|Val Acc:0.763734076433121\n",
      "Epoch:17|Train Loss:0.6253081560134888|Train Acc:0.7833377754086709|Val Loss:1.2346616983413696|Val Acc:0.6480891719745223\n",
      "Epoch:18|Train Loss:0.6026766300201416|Train Acc:0.7905783582089553|Val Loss:0.6141375303268433|Val Acc:0.7917993630573248\n",
      "Epoch:19|Train Loss:0.5725798606872559|Train Acc:0.8007507107320541|Val Loss:0.7232449650764465|Val Acc:0.7498009554140127\n",
      "Epoch:20|Train Loss:0.5504401922225952|Train Acc:0.8090573916133618|Val Loss:0.5980879068374634|Val Acc:0.798765923566879\n",
      "Epoch:21|Train Loss:0.5294555425643921|Train Acc:0.8155872423596304|Val Loss:0.6354716420173645|Val Acc:0.7844347133757962\n",
      "Epoch:22|Train Loss:0.507033109664917|Train Acc:0.82409381663113|Val Loss:0.5928438305854797|Val Acc:0.7977707006369427\n",
      "Epoch:23|Train Loss:0.4880746901035309|Train Acc:0.8295353589196873|Val Loss:0.5394784212112427|Val Acc:0.8107085987261147\n",
      "Epoch:24|Train Loss:0.4731108248233795|Train Acc:0.8361540511727079|Val Loss:0.5949321985244751|Val Acc:0.7914012738853503\n",
      "Epoch:25|Train Loss:0.4557587504386902|Train Acc:0.8406849680170576|Val Loss:0.5060707926750183|Val Acc:0.8304140127388535\n",
      "Epoch:26|Train Loss:0.44158944487571716|Train Acc:0.8466373489694385|Val Loss:0.5501110553741455|Val Acc:0.8095143312101911\n",
      "Epoch:27|Train Loss:0.4249754250049591|Train Acc:0.8503909026297086|Val Loss:0.49858275055885315|Val Acc:0.8314092356687898\n",
      "Epoch:28|Train Loss:0.4128949046134949|Train Acc:0.8571872778962332|Val Loss:0.5914682745933533|Val Acc:0.799562101910828\n",
      "Epoch:29|Train Loss:0.4000838100910187|Train Acc:0.8615405117270789|Val Loss:0.4875354766845703|Val Acc:0.8312101910828026\n",
      "Epoch:30|Train Loss:0.38809680938720703|Train Acc:0.8659381663113006|Val Loss:0.497256875038147|Val Acc:0.8306130573248408\n",
      "Epoch:31|Train Loss:0.36964139342308044|Train Acc:0.8711798152096659|Val Loss:0.5209100842475891|Val Acc:0.8294187898089171\n",
      "Epoch:32|Train Loss:0.35937923192977905|Train Acc:0.8747112651030562|Val Loss:0.5008537173271179|Val Acc:0.8413614649681529\n",
      "Epoch:33|Train Loss:0.3452645540237427|Train Acc:0.8801750177683013|Val Loss:0.5234976410865784|Val Acc:0.8248407643312102\n",
      "Epoch:34|Train Loss:0.3385128974914551|Train Acc:0.882640369580668|Val Loss:0.5060251951217651|Val Acc:0.8371815286624203\n",
      "Epoch:35|Train Loss:0.3235100507736206|Train Acc:0.8865271855010661|Val Loss:0.4887838661670685|Val Acc:0.847531847133758\n",
      "Epoch:36|Train Loss:0.3181484639644623|Train Acc:0.8900586353944563|Val Loss:0.4987799823284149|Val Acc:0.8421576433121019\n",
      "Epoch:37|Train Loss:0.30763140320777893|Train Acc:0.8933901918976546|Val Loss:0.5625634789466858|Val Acc:0.8238455414012739\n",
      "Epoch:38|Train Loss:0.2970809042453766|Train Acc:0.896366382373845|Val Loss:0.5092669725418091|Val Acc:0.8341958598726115\n",
      "Epoch:39|Train Loss:0.2872527837753296|Train Acc:0.8996090973702914|Val Loss:0.639742910861969|Val Acc:0.8176751592356688\n",
      "Epoch:40|Train Loss:0.2830420732498169|Train Acc:0.9010971926083866|Val Loss:0.5276840925216675|Val Acc:0.8328025477707006\n",
      "Epoch:41|Train Loss:0.27167901396751404|Train Acc:0.9059168443496801|Val Loss:0.4962840974330902|Val Acc:0.8489251592356688\n",
      "Epoch:42|Train Loss:0.2686796486377716|Train Acc:0.906227789623312|Val Loss:0.4706386923789978|Val Acc:0.8541003184713376\n",
      "Epoch:43|Train Loss:0.25534769892692566|Train Acc:0.9116693319118693|Val Loss:0.5262388586997986|Val Acc:0.8413614649681529\n",
      "Epoch:44|Train Loss:0.2521928548812866|Train Acc:0.9116915422885572|Val Loss:0.47808241844177246|Val Acc:0.848328025477707\n",
      "Epoch:45|Train Loss:0.24182485044002533|Train Acc:0.9141568941009239|Val Loss:0.5349120497703552|Val Acc:0.8411624203821656\n",
      "Epoch:46|Train Loss:0.23979084193706512|Train Acc:0.9157338308457711|Val Loss:0.5077686905860901|Val Acc:0.8435509554140127\n",
      "Epoch:47|Train Loss:0.23130926489830017|Train Acc:0.919998223169865|Val Loss:0.5240286588668823|Val Acc:0.8393710191082803\n",
      "Epoch:48|Train Loss:0.22473658621311188|Train Acc:0.9223525230987918|Val Loss:0.49552014470100403|Val Acc:0.8515127388535032\n",
      "Epoch:49|Train Loss:0.22137993574142456|Train Acc:0.9227078891257996|Val Loss:0.4915548861026764|Val Acc:0.8469347133757962\n",
      "pre modify lr is: 0.01\n",
      "after modify lr is: 0.001\n",
      "Epoch:50|Train Loss:0.21055009961128235|Train Acc:0.927683013503909|Val Loss:0.558297872543335|Val Acc:0.8326035031847133\n",
      "Epoch:51|Train Loss:0.1431024968624115|Train Acc:0.9506485429992892|Val Loss:0.4584283232688904|Val Acc:0.8678343949044586\n",
      "Epoch:52|Train Loss:0.12440971285104752|Train Acc:0.9573560767590619|Val Loss:0.467724084854126|Val Acc:0.8682324840764332\n",
      "Epoch:53|Train Loss:0.12018132954835892|Train Acc:0.9591995380241649|Val Loss:0.4647374749183655|Val Acc:0.8698248407643312\n",
      "Epoch:54|Train Loss:0.11330483108758926|Train Acc:0.9613761549395877|Val Loss:0.4570739269256592|Val Acc:0.8714171974522293\n",
      "Epoch:55|Train Loss:0.11154714226722717|Train Acc:0.9611540511727079|Val Loss:0.45786014199256897|Val Acc:0.8700238853503185\n",
      "Epoch:56|Train Loss:0.10714026540517807|Train Acc:0.9635083511016347|Val Loss:0.44329553842544556|Val Acc:0.8775875796178344\n",
      "Epoch:57|Train Loss:0.10374605655670166|Train Acc:0.9643079246624022|Val Loss:0.47618138790130615|Val Acc:0.8708200636942676\n",
      "Epoch:58|Train Loss:0.10206091403961182|Train Acc:0.9646855010660981|Val Loss:0.486155241727829|Val Acc:0.8722133757961783\n",
      "Epoch:59|Train Loss:0.10050918906927109|Train Acc:0.9655517057569296|Val Loss:0.46790382266044617|Val Acc:0.8740047770700637\n",
      "Epoch:60|Train Loss:0.09690979868173599|Train Acc:0.9658404406538735|Val Loss:0.4628724157810211|Val Acc:0.8736066878980892\n",
      "Epoch:61|Train Loss:0.09633046388626099|Train Acc:0.9661735963041933|Val Loss:0.45741546154022217|Val Acc:0.8829617834394905\n",
      "Epoch:62|Train Loss:0.09417038410902023|Train Acc:0.9674617981520967|Val Loss:0.4799015522003174|Val Acc:0.8718152866242038\n",
      "Epoch:63|Train Loss:0.0923091471195221|Train Acc:0.9679060056858564|Val Loss:0.4841877222061157|Val Acc:0.8748009554140127\n",
      "Epoch:64|Train Loss:0.09024577587842941|Train Acc:0.9695717839374556|Val Loss:0.47315922379493713|Val Acc:0.8755971337579618\n",
      "Epoch:65|Train Loss:0.08730828016996384|Train Acc:0.9692608386638237|Val Loss:0.4752708971500397|Val Acc:0.8759952229299363\n",
      "Epoch:66|Train Loss:0.08749014884233475|Train Acc:0.9691275764036958|Val Loss:0.503192663192749|Val Acc:0.8742038216560509\n",
      "Epoch:67|Train Loss:0.08774309605360031|Train Acc:0.9699937810945274|Val Loss:0.49774909019470215|Val Acc:0.8728105095541401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:68|Train Loss:0.08348118513822556|Train Acc:0.9711487206823027|Val Loss:0.49551814794540405|Val Acc:0.8748009554140127\n",
      "Epoch:69|Train Loss:0.08375323563814163|Train Acc:0.9705490405117271|Val Loss:0.5094283223152161|Val Acc:0.8690286624203821\n",
      "Epoch:70|Train Loss:0.07989396899938583|Train Acc:0.9717706112295664|Val Loss:0.49974435567855835|Val Acc:0.8708200636942676\n",
      "Epoch:71|Train Loss:0.08136758953332901|Train Acc:0.9717706112295664|Val Loss:0.4935104548931122|Val Acc:0.8765923566878981\n",
      "Epoch:72|Train Loss:0.07951906323432922|Train Acc:0.9727478678038379|Val Loss:0.5190025568008423|Val Acc:0.8734076433121019\n",
      "Epoch:73|Train Loss:0.08140485733747482|Train Acc:0.9723036602700782|Val Loss:0.49034780263900757|Val Acc:0.8722133757961783\n",
      "Epoch:74|Train Loss:0.07993623614311218|Train Acc:0.9724591329068941|Val Loss:0.5142886638641357|Val Acc:0.8680334394904459\n",
      "pre modify lr is: 0.001\n",
      "after modify lr is: 0.0001\n",
      "Epoch:75|Train Loss:0.07323487848043442|Train Acc:0.9749689054726368|Val Loss:0.507219135761261|Val Acc:0.8777866242038217\n",
      "Epoch:76|Train Loss:0.07322419434785843|Train Acc:0.974502487562189|Val Loss:0.5181991457939148|Val Acc:0.8738057324840764\n",
      "Epoch:77|Train Loss:0.06950534880161285|Train Acc:0.9768789978678039|Val Loss:0.4978712499141693|Val Acc:0.8783837579617835\n",
      "Epoch:78|Train Loss:0.0701470896601677|Train Acc:0.9756796375266524|Val Loss:0.49910297989845276|Val Acc:0.8767914012738853\n",
      "Epoch:79|Train Loss:0.06815142184495926|Train Acc:0.9773676261549396|Val Loss:0.5007402300834656|Val Acc:0.8761942675159236\n",
      "Epoch:80|Train Loss:0.06821203976869583|Train Acc:0.9769900497512438|Val Loss:0.4931299090385437|Val Acc:0.8789808917197452\n",
      "Epoch:81|Train Loss:0.07089213281869888|Train Acc:0.9756130063965884|Val Loss:0.49559828639030457|Val Acc:0.8829617834394905\n",
      "Epoch:82|Train Loss:0.06807595491409302|Train Acc:0.9773454157782516|Val Loss:0.5052281618118286|Val Acc:0.8759952229299363\n",
      "Epoch:83|Train Loss:0.07009617984294891|Train Acc:0.9756574271499645|Val Loss:0.5111454129219055|Val Acc:0.875\n",
      "Epoch:84|Train Loss:0.06761534512042999|Train Acc:0.9768345771144279|Val Loss:0.5096839666366577|Val Acc:0.8767914012738853\n",
      "Epoch:85|Train Loss:0.06830693781375885|Train Acc:0.9773232054015636|Val Loss:0.5222389101982117|Val Acc:0.8759952229299363\n",
      "Epoch:86|Train Loss:0.06723080575466156|Train Acc:0.9771233120113717|Val Loss:0.5118069648742676|Val Acc:0.8732085987261147\n",
      "Epoch:87|Train Loss:0.06926745176315308|Train Acc:0.9756130063965884|Val Loss:0.5122882127761841|Val Acc:0.8793789808917197\n",
      "Epoch:88|Train Loss:0.06633996963500977|Train Acc:0.9770566808813077|Val Loss:0.5128217935562134|Val Acc:0.875\n",
      "Epoch:89|Train Loss:0.06863448768854141|Train Acc:0.9768789978678039|Val Loss:0.5177066922187805|Val Acc:0.8789808917197452\n",
      "Epoch:90|Train Loss:0.06839265674352646|Train Acc:0.9764125799573561|Val Loss:0.4973464012145996|Val Acc:0.8803742038216561\n",
      "Epoch:91|Train Loss:0.0676867663860321|Train Acc:0.9762126865671642|Val Loss:0.5177805423736572|Val Acc:0.8757961783439491\n",
      "Epoch:92|Train Loss:0.06899720430374146|Train Acc:0.9758795309168443|Val Loss:0.5018001794815063|Val Acc:0.8821656050955414\n",
      "Epoch:93|Train Loss:0.06659415364265442|Train Acc:0.9771677327647477|Val Loss:0.5177774429321289|Val Acc:0.8724124203821656\n",
      "Epoch:94|Train Loss:0.06657042354345322|Train Acc:0.9769012082444918|Val Loss:0.5249897837638855|Val Acc:0.8744028662420382\n",
      "Epoch:95|Train Loss:0.06720314174890518|Train Acc:0.9769900497512438|Val Loss:0.5169684886932373|Val Acc:0.8736066878980892\n",
      "Epoch:96|Train Loss:0.06634841859340668|Train Acc:0.9769234186211798|Val Loss:0.5217441320419312|Val Acc:0.8730095541401274\n",
      "Epoch:97|Train Loss:0.0664309486746788|Train Acc:0.9776563610518835|Val Loss:0.5103419423103333|Val Acc:0.878781847133758\n",
      "Epoch:98|Train Loss:0.0676133930683136|Train Acc:0.9767901563610519|Val Loss:0.5052236914634705|Val Acc:0.8789808917197452\n",
      "Epoch:99|Train Loss:0.06786539405584335|Train Acc:0.9758573205401564|Val Loss:0.5154849886894226|Val Acc:0.8761942675159236\n",
      "Epoch:100|Train Loss:0.0683429166674614|Train Acc:0.9767457356076759|Val Loss:0.5033324360847473|Val Acc:0.8775875796178344\n"
     ]
    }
   ],
   "source": [
    "model_path = './models/alexnet-sifar10.pth'\n",
    "best_valid_loss = float(\"inf\")\n",
    "info = 'Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model, device, train_loader, criterion, optimizer)\n",
    "    valid_loss, valid_acc = evaluate(model, device, valid_loader, criterion)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    if epoch+1 == 50:\n",
    "        modify_lr(optimizer, lr=1e-3)\n",
    "    if epoch+1 == 75:\n",
    "        modify_lr(optimizer, lr=1e-4)\n",
    "    print(info.format(epoch+1, train_loss, train_acc, valid_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像增强\n",
    "### torchvision.transforms 包括所有图像增强的方法 。\n",
    "- Scale，对图片的尺度进行缩小和放大;\n",
    "- RandomRotation 对图片随机旋转；\n",
    "- CenterCrop，对图像正中心进行给定大小的裁剪;\n",
    "- RandomCrop，对图片进行给定大小的随机裁剪;\n",
    "- RandomHorizaontalFlip，对图片进行概率为0.5的随机水平翻转;\n",
    "- RandomSizedCrop，首先对图片进行随机尺寸的裁剪，然后对裁剪的图片进行一个随机比例的缩放，最后将图片变成给定的大小，这在Inception Net 中比较流行;\n",
    "- 最后一个是Pad，对图片进行边界零填充。\n",
    "\n",
    "上面介绍了 PyTorch 内置的一些图像增强的方法，还有更多的增强方法见[transforms的二十二个方法](https://zhuanlan.zhihu.com/p/53367135)，可以使用OpenCV或者PIL等第二方图形库实现。在网络的训练中图像增强是一种常见、默认的做法，对多任务进行图像增强之后都能够在一定程度上提升任务的准确率。\n",
    "\n",
    "- 本篇幅参考[经典CNN网络 - AlexNet总结](https://juejin.im/post/5ad173b651882555731c8f9b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet优点/AlexNet高性能的解释\n",
    "- 非线性激活函数：ReLU\n",
    "- 防止过拟合的方法：Dropout，Data augmentation\n",
    "- 大数据训练：百万级ImageNet图像数据\n",
    "- 其他：GPU实现，LRN归一化层的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD与Adam\n",
    "- 有时候Adam不收敛，效果很差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
