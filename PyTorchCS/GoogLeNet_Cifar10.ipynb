{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self,in_planes,n1x1,n3x3red,n3x3,n5x5red,n5x5,pool_planes):\n",
    "        super(Inception,self).__init__()\n",
    "        self.b1=nn.Sequential(\n",
    "            nn.Conv2d(in_planes,n1x1,kernel_size=1),\n",
    "            nn.BatchNorm2d(n1x1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.b2=nn.Sequential(\n",
    "            nn.Conv2d(in_planes,n3x3red,kernel_size=1),\n",
    "            nn.BatchNorm2d(n3x3red),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(n3x3red,n3x3,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(n3x3),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.b3=nn.Sequential(\n",
    "            nn.Conv2d(in_planes,n5x5red,kernel_size=1),\n",
    "            nn.BatchNorm2d(n5x5red),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(n5x5red,n5x5,kernel_size=5,padding=2),\n",
    "            nn.BatchNorm2d(n5x5),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.b4=nn.Sequential(\n",
    "            nn.MaxPool2d(3,stride=1,padding=1),\n",
    "            nn.Conv2d(in_planes,pool_planes,kernel_size=1),\n",
    "            nn.BatchNorm2d(pool_planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x1=self.b1(x)\n",
    "        x2=self.b2(x)\n",
    "        x3=self.b3(x)\n",
    "        x4=self.b4(x)\n",
    "        #concat4层输入在一起\n",
    "        return torch.cat([x1,x2,x3,x4],1)\n",
    "    \n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, class_num):\n",
    "        super(GoogLeNet,self).__init__()\n",
    "        self.feature_block=nn.Sequential(\n",
    "            nn.Conv2d(3,192,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.a3=Inception(192,64,96,128,16,32,32)\n",
    "        self.b3=Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool=nn.MaxPool2d(3,stride=2,padding=1)\n",
    "        self.a4 = Inception(480, 192,  96, 208, 16,  48,  64)\n",
    "        self.b4 = Inception(512, 160, 112, 224, 24,  64,  64)\n",
    "        self.c4 = Inception(512, 128, 128, 256, 24,  64,  64)\n",
    "        self.d4 = Inception(512, 112, 144, 288, 32,  64,  64)\n",
    "        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "        self.avgpool=nn.AvgPool2d(8,stride=1)\n",
    "        self.linear=nn.Linear(1024,class_num)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.feature_block(x)\n",
    "        out = self.a3(out)\n",
    "        out = self.b3(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.a4(out)\n",
    "        out = self.b4(out)\n",
    "        out = self.c4(out)\n",
    "        out = self.d4(out)\n",
    "        out = self.e4(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.a5(out)\n",
    "        out = self.b5(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(out, y):\n",
    "    _, pred = torch.max(out, 1)  # 最大概率，对应的类别\n",
    "    corr_num = pred.eq(y).sum()  # tensor 得取出结果\n",
    "    acc = corr_num.item() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def train(model, device, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)               # 各个分类的概率\n",
    "        loss = criterion(out, y)\n",
    "        train_loss += loss.item()\n",
    "        acc = accu(out, y)\n",
    "        train_acc += acc\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss / len(train_loader), train_acc / len(train_loader) \n",
    "\n",
    "def test(model, device, test_loader, criterion, optimizer):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(x) \n",
    "            loss = criterion(out, y)\n",
    "            test_loss += loss.item()\n",
    "            acc = accu(out, y)\n",
    "            test_acc += acc\n",
    "    return test_loss/len(test_loader), test_acc/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channel, n1_1, n3x3red, n3x3, n5x5red, n5x5, pool_plane):\n",
    "        super(Inception, self).__init__()\n",
    "        # first line\n",
    "        self.branch1x1 = BasicConv2d(in_channel, n1_1, kernel_size=1)\n",
    "\n",
    "        # second line\n",
    "        self.branch3x3 = nn.Sequential(\n",
    "            BasicConv2d(in_channel, n3x3red, kernel_size=1),\n",
    "            BasicConv2d(n3x3red, n3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        # third line\n",
    "        self.branch5x5 = nn.Sequential(\n",
    "            BasicConv2d(in_channel, n5x5red, kernel_size=1),\n",
    "            BasicConv2d(n5x5red, n5x5, kernel_size=5, padding=2)\n",
    "        )\n",
    "\n",
    "        # fourth line\n",
    "        self.branch_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(3, stride=1, padding=1),\n",
    "            BasicConv2d(in_channel, pool_plane, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.branch1x1(x)\n",
    "        y2 = self.branch3x3(x)\n",
    "        y3 = self.branch5x5(x)\n",
    "        y4 = self.branch_pool(x)\n",
    "        output = torch.cat([y1, y2, y3, y4], 1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "\n",
    "        self.conv1 = BasicConv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "\n",
    "        self.max_pool1 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "        self.conv2 = BasicConv2d(64, 192, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.max_pool2 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "        self.a3 = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "        self.max_pool3 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "        self.a4 = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.b4 = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.c4 = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.d4 = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "\n",
    "        self.max_pool4 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(7)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "        self.classifier = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = self.a3(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.max_pool3(x)\n",
    "        x = self.a4(x)\n",
    "        x = self.b4(x)\n",
    "        x = self.c4(x)\n",
    "        x = self.d4(x)\n",
    "        x = self.e4(x)\n",
    "        x = self.max_pool4(x)\n",
    "        x = self.a5(x)\n",
    "        x = self.b5(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomCrop(32,padding=3),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768))#参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])\n",
    "\n",
    "data_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10('data', train=True, download=True, transform=data_trans)\n",
    "test_data = datasets.CIFAR10('data', train=False, download=True, transform=data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(train_data)*0.9)\n",
    "n_valid = len(train_data) - n_train\n",
    "train_datasets, valid_datasets = torch.utils.data.random_split(train_data, [n_train, n_valid])\n",
    "\n",
    "train_loader = DataLoader(train_datasets, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_datasets, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GoogLeNet(10)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the best models to ./models/googlenet-sifar10.pth\n",
      "Epoch:1|Train Loss:1.7199868538232246|Train Acc:0.36436122956645345|Val Loss:1.3914980364453262|Val Acc:0.4902468152866242\n"
     ]
    }
   ],
   "source": [
    "model_path = './models/googlenet-sifar10.pth'\n",
    "info = 'Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model, device, train_loader, criterion, optimizer)\n",
    "    valid_loss, valid_acc = test(model, device, valid_loader, criterion, optimizer)\n",
    "    if valid_loss < float(\"inf\"):\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"Save the best models to {}\".format(model_path))\n",
    "    print(info.format(epoch+1, train_loss, train_acc, valid_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
