{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyANNNet(nn.Module):\n",
    "    def __init__(self, inputs, out1, out2, class_num):\n",
    "        super(MyANNNet, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(inputs, out1),\n",
    "            nn.BatchNorm1d(out1),   # 添加批标准化\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(out1, out2),\n",
    "            nn.BatchNorm1d(out2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(out2, class_num)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "def accu(out, y):\n",
    "    _, pred = torch.max(out, 1)  # 最大概率，对应的类别\n",
    "    corr_num = pred.eq(y).sum()  # tensor 得取出结果\n",
    "    acc = corr_num.item() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "\n",
    "# 单epoch的训练\n",
    "def train(model, device, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for x, y in train_loader:\n",
    "        x = x.view(x.size(0), -1)    # reshape(x.size(0), 该维度压平)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)               # 各个分类的概率\n",
    "        loss = criterion(out, y)\n",
    "        train_loss += loss\n",
    "        acc = accu(out, y)\n",
    "        train_acc += acc\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss / len(train_loader), train_acc / len(train_loader) \n",
    "\n",
    "# 测试\n",
    "def test(model, device, test_loader, criterion, optimizer):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    for x, y in test_loader:\n",
    "        x = x.view(x.size(0), -1)    # reshape(x.size(0), 该维度压平)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = model(x)               # 各个分类的概率\n",
    "        loss = criterion(out, y)\n",
    "        test_loss += loss\n",
    "        acc = accu(out, y)\n",
    "        test_acc += acc\n",
    "        loss.backward()\n",
    "    return test_loss/len(test_loader), test_acc/len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接下来做什么？\n",
    "- 数据标准化：torchvision.transforms 它提供了很多处理图像的方法：\n",
    "    - transforms.ToTensor()将图片对象转换成pytorch中的Tensor，转换过程中自动标准化，即Tensor的范围为[0,1];\n",
    "    - transforms.Normalize()需要传入两个数，第一个是均值，第二个是方差。公式：减均值，除方差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data = transforms.Compose([  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- transforms.Compose([])    将各种操作组在一起\n",
    "- 三通道transforms.Normalize([a,b,c], [d,e,f])  应该把3个通道的均值方差填入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载并读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = datasets.MNIST(root='./data', train=True, transform=trans_data, download=True)\n",
    "test_datasets = datasets.MNIST(root='./data', train=False, transform=trans_data, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(train_datasets)*0.9)\n",
    "n_valid = len(train_datasets) - n_train\n",
    "train_datasets, valid_datasets = torch.utils.data.random_split(train_datasets, [n_train, n_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成迭代器，传入数据集，batch size，是否shuffle\n",
    "train_loader = DataLoader(train_datasets, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_datasets, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_datasets, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MyANNNet(28*28, 300, 50, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the best models to ./models/ann-minst.pth\n",
      "Epoch:1|Train Loss:0.036617957055568695|Train Acc:0.9900770142180095|Val Loss:0.06657259166240692|Val Acc:0.9793882978723404\n",
      "Save the best models to ./models/ann-minst.pth\n",
      "Epoch:2|Train Loss:0.03458032384514809|Train Acc:0.9908360485781991|Val Loss:0.06505784392356873|Val Acc:0.980219414893617\n",
      "Save the best models to ./models/ann-minst.pth\n",
      "Epoch:3|Train Loss:0.03030979260802269|Train Acc:0.9918542654028436|Val Loss:0.0708872526884079|Val Acc:0.9782247340425532\n",
      "Save the best models to ./models/ann-minst.pth\n",
      "Epoch:4|Train Loss:0.02756541781127453|Train Acc:0.9928354561611374|Val Loss:0.06922823190689087|Val Acc:0.980219414893617\n",
      "Save the best models to ./models/ann-minst.pth\n",
      "Epoch:5|Train Loss:0.02680644951760769|Train Acc:0.9929650473933649|Val Loss:0.06804633140563965|Val Acc:0.9793882978723404\n",
      "Save the best models to ./models/ann-minst.pth\n",
      "Epoch:6|Train Loss:0.02279539406299591|Train Acc:0.993853672985782|Val Loss:0.0657816082239151|Val Acc:0.980718085106383\n",
      "Save the best models to ./models/ann-minst.pth\n",
      "Epoch:7|Train Loss:0.022419258952140808|Train Acc:0.9939647511848341|Val Loss:0.0678880363702774|Val Acc:0.9810505319148937\n",
      "Save the best models to ./models/ann-minst.pth\n",
      "Epoch:8|Train Loss:0.01984686218202114|Train Acc:0.9948718898104265|Val Loss:0.06676784157752991|Val Acc:0.9815492021276596\n",
      "Save the best models to ./models/ann-minst.pth\n",
      "Epoch:9|Train Loss:0.01988568902015686|Train Acc:0.9945386552132701|Val Loss:0.07408735156059265|Val Acc:0.9782247340425532\n",
      "Save the best models to ./models/ann-minst.pth\n",
      "Epoch:10|Train Loss:0.01790195144712925|Train Acc:0.9957049763033176|Val Loss:0.06358423829078674|Val Acc:0.9803856382978723\n"
     ]
    }
   ],
   "source": [
    "model_path = './models/ann-minst.pth'\n",
    "info = 'Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model, device, train_loader, criterion, optimizer)\n",
    "    valid_loss, valid_acc = test(model, device, valid_loader, criterion, optimizer)\n",
    "    if valid_loss < float(\"inf\"):\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"Save the best models to {}\".format(model_path))\n",
    "    print(info.format(epoch+1, train_loss, train_acc, valid_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>), 0.9819289137380192)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, device, test_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
